{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jRXtGmEHcnsy",
        "outputId": "ca8453b8-961d-4d63-f5eb-9c3ec0b15569",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.13.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-t2h5pyar\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-t2h5pyar\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit d25d902a6de54931a329adc38a2663e8f576adc4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.8)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-la5imdr4/elegantrl_77351db037974af78d208c532bdf8f5e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-la5imdr4/elegantrl_77351db037974af78d208c532bdf8f5e\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 5e828af1503098f4da046c0f12432dbd4ef8bd97\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alpaca-py<0.38,>=0.37 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (0.37.0)\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (3.1.60)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (1.9.7)\n",
            "Requirement already satisfied: pyfolio-reloaded<0.10,>=0.9 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (0.9.8)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (1.5.6)\n",
            "Requirement already satisfied: ray<3,>=2 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.44.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (1.6.1)\n",
            "Requirement already satisfied: selenium<5,>=4 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (4.31.0)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.0)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (0.5.4)\n",
            "Requirement already satisfied: webdriver-manager<5,>=4 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (4.0.2)\n",
            "Requirement already satisfied: wrds<4,>=3 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (3.3.0)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /usr/local/lib/python3.11/dist-packages (from finrl==0.3.8) (0.2.55)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.32.3)\n",
            "Requirement already satisfied: sseclient-py<2.0.0,>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (10.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (2.0.2)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.26.20)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (3.11.15)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.8) (24.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.11/dist-packages (from ccxt<4,>=3->finrl==0.3.8) (75.2.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.11/dist-packages (from ccxt<4,>=3->finrl==0.3.8) (2025.1.31)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ccxt<4,>=3->finrl==0.3.8) (43.0.3)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from ccxt<4,>=3->finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ccxt<4,>=3->finrl==0.3.8) (1.19.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.17.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.11/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (2.0.40)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.11/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.1.1)\n",
            "Requirement already satisfied: thriftpy2!=0.5.1,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (0.5.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.11/dist-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.11/dist-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2025.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.14.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.13.2)\n",
            "Requirement already satisfied: empyrical-reloaded>=0.5.9 in /usr/local/lib/python3.11/dist-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.5.11)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.11/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (1.6.4)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /usr/local/lib/python3.11/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (2.0.14)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (5.24.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (5.29.4)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.5.0)\n",
            "Requirement already satisfied: aiohttp_cors in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.8.1)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (1.71.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.11.4)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.21.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (20.30.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (18.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2025.3.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->finrl==0.3.8) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->finrl==0.3.8) (3.6.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium<5,>=4->finrl==0.3.8) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium<5,>=4->finrl==0.3.8) (0.12.2)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium<5,>=4->finrl==0.3.8) (4.13.1)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.1.1)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (11.1.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from webdriver-manager<5,>=4->finrl==0.3.8) (1.1.0)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.11/dist-packages (from wrds<4,>=3->finrl==0.3.8) (2.9.10)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (4.3.7)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (4.13.3)\n",
            "Requirement already satisfied: th in /usr/local/lib/python3.11/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (0.4.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.8) (4.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (2.6.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (0.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.8) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (1.17.1)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (3.2.7.post2)\n",
            "Requirement already satisfied: bottleneck>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from empyrical-reloaded>=0.5.9->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.4.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.8) (9.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.8) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.3)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.11/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.0.12)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.11/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.8) (1.7.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.8) (0.3.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.24.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.24.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open->ray[default,tune]<3,>=2->finrl==0.3.8) (1.17.2)\n",
            "Requirement already satisfied: niltype<2.0,>=0.3 in /usr/local/lib/python3.11/dist-packages (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (1.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.69.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.38.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (0.14.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4kWflLAYd48E",
        "outputId": "ca25b362-7d46-48f6-930f-62f0b681364e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_market_calendars in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.11/dist-packages (from pandas_market_calendars) (2.2.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from pandas_market_calendars) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from pandas_market_calendars) (2.8.2)\n",
            "Requirement already satisfied: exchange-calendars>=3.3 in /usr/local/lib/python3.11/dist-packages (from pandas_market_calendars) (4.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (2.0.2)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (2.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.12.1)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1->pandas_market_calendars) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->pandas_market_calendars) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas_market_calendars"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Bh9JfaVskvwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "86e35967-3992-4d24-e135-adac48f37890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9uFGzjHmgxbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i2rpEcBKgxzG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "rKl59YrpG67o",
        "outputId": "a4fa8af5-eb01-42df-81c8-649ee961ed2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (37116, 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (4238, 8)\n",
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date        close         high          low         open  \\\n",
              "0      2007-09-17    25.666590    31.950186    30.367620    30.501736   \n",
              "1      2007-09-17   107.898865   124.889999   121.504997   121.820000   \n",
              "2      2007-09-17   130.203522   166.000000   161.981812   165.090912   \n",
              "3      2007-09-17   156.991608   231.862503   224.062500   231.750000   \n",
              "4      2007-09-17   217.758408   235.372101   230.983307   232.011932   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "33899  2024-12-31  1880.000000  1897.000000  1845.050049  1892.300049   \n",
              "33900  2024-12-31  1215.449951  1219.099976  1206.150024  1208.000000   \n",
              "33901  2024-12-31   794.950012   799.200012   786.000000   786.950012   \n",
              "33902  2024-12-31   740.150024   743.400024   732.750000   733.650024   \n",
              "33903  2024-12-31  4030.549561  4139.950195  4032.050049  4135.000000   \n",
              "\n",
              "         volume            tic  day  close_benchmark       macd      boll_ub  \\\n",
              "0       7182786    ADANIENT.NS    0      4494.649902   0.000000    31.622972   \n",
              "1       2402430    HDFCBANK.NS    0      4494.649902   0.000000    31.622972   \n",
              "2       6581168   ICICIBANK.NS    0      4494.649902   0.000000    31.622972   \n",
              "3      11030912        INFY.NS    0      4494.649902   0.000000    31.622972   \n",
              "4      12641000    RELIANCE.NS    0      4494.649902   0.000000    31.622972   \n",
              "...         ...            ...  ...              ...        ...          ...   \n",
              "33899   3613063        INFY.NS    1     23644.800781   4.411242  2007.867612   \n",
              "33900   6405475    RELIANCE.NS    1     23644.800781 -23.591851  1338.100577   \n",
              "33901   9086044        SBIN.NS    1     23644.800781  -9.756879   891.827804   \n",
              "33902   7092699  TATAMOTORS.NS    1     23644.800781 -20.582196   829.802881   \n",
              "33903   1555429         TCS.NS    1     23644.800781 -31.898075  4503.024345   \n",
              "\n",
              "           boll_lb      rsi_30      cci_30       dx_30  close_30_sma  \\\n",
              "0        22.821868  100.000000   66.666667  100.000000     25.666590   \n",
              "1        22.821868  100.000000   66.666667  100.000000    107.898865   \n",
              "2        22.821868  100.000000   66.666667  100.000000    130.203522   \n",
              "3        22.821868  100.000000   66.666667  100.000000    156.991608   \n",
              "4        22.821868  100.000000   66.666667  100.000000    217.758408   \n",
              "...            ...         ...         ...         ...           ...   \n",
              "33899  1864.062405   49.105650  -71.778724   33.575345   1914.148340   \n",
              "33900  1179.019443   38.586709 -114.046122   53.610083   1263.668339   \n",
              "33901   784.987204   44.432995 -130.224513   45.370115    833.813336   \n",
              "33902   708.682110   37.044401 -118.127262   28.801320    774.143331   \n",
              "33903  3988.296529   43.479408 -119.641150   38.093474   4214.026416   \n",
              "\n",
              "       close_60_sma  turbulence  \n",
              "0         25.666590    0.000000  \n",
              "1        107.898865    0.000000  \n",
              "2        130.203522    0.000000  \n",
              "3        156.991608    0.000000  \n",
              "4        217.758408    0.000000  \n",
              "...             ...         ...  \n",
              "33899   1885.287345    5.434698  \n",
              "33900   1299.420422    5.434698  \n",
              "33901    823.040005    5.434698  \n",
              "33902    821.236666    5.434698  \n",
              "33903   4131.775309    5.434698  \n",
              "\n",
              "[33904 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa63ee3e-a232-4b76-bab6-b6c1341fbefb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>close_benchmark</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-09-17</td>\n",
              "      <td>25.666590</td>\n",
              "      <td>31.950186</td>\n",
              "      <td>30.367620</td>\n",
              "      <td>30.501736</td>\n",
              "      <td>7182786</td>\n",
              "      <td>ADANIENT.NS</td>\n",
              "      <td>0</td>\n",
              "      <td>4494.649902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.622972</td>\n",
              "      <td>22.821868</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>25.666590</td>\n",
              "      <td>25.666590</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-09-17</td>\n",
              "      <td>107.898865</td>\n",
              "      <td>124.889999</td>\n",
              "      <td>121.504997</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>2402430</td>\n",
              "      <td>HDFCBANK.NS</td>\n",
              "      <td>0</td>\n",
              "      <td>4494.649902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.622972</td>\n",
              "      <td>22.821868</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>107.898865</td>\n",
              "      <td>107.898865</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-09-17</td>\n",
              "      <td>130.203522</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>161.981812</td>\n",
              "      <td>165.090912</td>\n",
              "      <td>6581168</td>\n",
              "      <td>ICICIBANK.NS</td>\n",
              "      <td>0</td>\n",
              "      <td>4494.649902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.622972</td>\n",
              "      <td>22.821868</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>130.203522</td>\n",
              "      <td>130.203522</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-09-17</td>\n",
              "      <td>156.991608</td>\n",
              "      <td>231.862503</td>\n",
              "      <td>224.062500</td>\n",
              "      <td>231.750000</td>\n",
              "      <td>11030912</td>\n",
              "      <td>INFY.NS</td>\n",
              "      <td>0</td>\n",
              "      <td>4494.649902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.622972</td>\n",
              "      <td>22.821868</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>156.991608</td>\n",
              "      <td>156.991608</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-09-17</td>\n",
              "      <td>217.758408</td>\n",
              "      <td>235.372101</td>\n",
              "      <td>230.983307</td>\n",
              "      <td>232.011932</td>\n",
              "      <td>12641000</td>\n",
              "      <td>RELIANCE.NS</td>\n",
              "      <td>0</td>\n",
              "      <td>4494.649902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.622972</td>\n",
              "      <td>22.821868</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>217.758408</td>\n",
              "      <td>217.758408</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33899</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>1880.000000</td>\n",
              "      <td>1897.000000</td>\n",
              "      <td>1845.050049</td>\n",
              "      <td>1892.300049</td>\n",
              "      <td>3613063</td>\n",
              "      <td>INFY.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>23644.800781</td>\n",
              "      <td>4.411242</td>\n",
              "      <td>2007.867612</td>\n",
              "      <td>1864.062405</td>\n",
              "      <td>49.105650</td>\n",
              "      <td>-71.778724</td>\n",
              "      <td>33.575345</td>\n",
              "      <td>1914.148340</td>\n",
              "      <td>1885.287345</td>\n",
              "      <td>5.434698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33900</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>1215.449951</td>\n",
              "      <td>1219.099976</td>\n",
              "      <td>1206.150024</td>\n",
              "      <td>1208.000000</td>\n",
              "      <td>6405475</td>\n",
              "      <td>RELIANCE.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>23644.800781</td>\n",
              "      <td>-23.591851</td>\n",
              "      <td>1338.100577</td>\n",
              "      <td>1179.019443</td>\n",
              "      <td>38.586709</td>\n",
              "      <td>-114.046122</td>\n",
              "      <td>53.610083</td>\n",
              "      <td>1263.668339</td>\n",
              "      <td>1299.420422</td>\n",
              "      <td>5.434698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33901</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>794.950012</td>\n",
              "      <td>799.200012</td>\n",
              "      <td>786.000000</td>\n",
              "      <td>786.950012</td>\n",
              "      <td>9086044</td>\n",
              "      <td>SBIN.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>23644.800781</td>\n",
              "      <td>-9.756879</td>\n",
              "      <td>891.827804</td>\n",
              "      <td>784.987204</td>\n",
              "      <td>44.432995</td>\n",
              "      <td>-130.224513</td>\n",
              "      <td>45.370115</td>\n",
              "      <td>833.813336</td>\n",
              "      <td>823.040005</td>\n",
              "      <td>5.434698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33902</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>740.150024</td>\n",
              "      <td>743.400024</td>\n",
              "      <td>732.750000</td>\n",
              "      <td>733.650024</td>\n",
              "      <td>7092699</td>\n",
              "      <td>TATAMOTORS.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>23644.800781</td>\n",
              "      <td>-20.582196</td>\n",
              "      <td>829.802881</td>\n",
              "      <td>708.682110</td>\n",
              "      <td>37.044401</td>\n",
              "      <td>-118.127262</td>\n",
              "      <td>28.801320</td>\n",
              "      <td>774.143331</td>\n",
              "      <td>821.236666</td>\n",
              "      <td>5.434698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33903</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>4030.549561</td>\n",
              "      <td>4139.950195</td>\n",
              "      <td>4032.050049</td>\n",
              "      <td>4135.000000</td>\n",
              "      <td>1555429</td>\n",
              "      <td>TCS.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>23644.800781</td>\n",
              "      <td>-31.898075</td>\n",
              "      <td>4503.024345</td>\n",
              "      <td>3988.296529</td>\n",
              "      <td>43.479408</td>\n",
              "      <td>-119.641150</td>\n",
              "      <td>38.093474</td>\n",
              "      <td>4214.026416</td>\n",
              "      <td>4131.775309</td>\n",
              "      <td>5.434698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33904 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa63ee3e-a232-4b76-bab6-b6c1341fbefb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa63ee3e-a232-4b76-bab6-b6c1341fbefb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa63ee3e-a232-4b76-bab6-b6c1341fbefb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f511450-4eb2-49ba-b6f7-718e12cc98e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f511450-4eb2-49ba-b6f7-718e12cc98e0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f511450-4eb2-49ba-b6f7-718e12cc98e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a48cf6e0-447e-49f5-aef6-401387be8831\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a48cf6e0-447e-49f5-aef6-401387be8831 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 33904,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4238,\n        \"samples\": [\n          \"2020-09-30\",\n          \"2010-10-28\",\n          \"2021-01-20\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 742.5556817365588,\n        \"min\": 15.269890785217285,\n        \"max\": 4471.39013671875,\n        \"num_unique_values\": 32795,\n        \"samples\": [\n          194.96884155273438,\n          100.97245788574219,\n          70.06301879882812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 778.0447438818888,\n        \"min\": 18.883487701416016,\n        \"max\": 4592.25,\n        \"num_unique_values\": 25343,\n        \"samples\": [\n          542.7000122070312,\n          274.9818115234375,\n          70.92803192138672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 761.8998591477632,\n        \"min\": 18.247394561767578,\n        \"max\": 4512.0,\n        \"num_unique_values\": 26244,\n        \"samples\": [\n          201.1531982421875,\n          207.52999877929688,\n          206.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 770.3374435070467,\n        \"min\": 18.46964454650879,\n        \"max\": 4576.0,\n        \"num_unique_values\": 22547,\n        \"samples\": [\n          543.7999877929688,\n          96.13411712646484,\n          965.0999755859375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16623268,\n        \"min\": 11821,\n        \"max\": 390577839,\n        \"num_unique_values\": 33883,\n        \"samples\": [\n          8335181,\n          20802022,\n          14084039\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"HDFCBANK.NS\",\n          \"SBIN.NS\",\n          \"ADANIENT.NS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_benchmark\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5549.329180237873,\n        \"min\": 2524.199951171875,\n        \"max\": 26216.05078125,\n        \"num_unique_values\": 4188,\n        \"samples\": [\n          8225.2001953125,\n          18771.25,\n          6211.14990234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.87066468860229,\n        \"min\": -536.0850033761576,\n        \"max\": 236.7158061492073,\n        \"num_unique_values\": 33897,\n        \"samples\": [\n          9.083544534477994,\n          -11.9114702586038,\n          -2.001460136162649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"boll_ub\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 780.431280892595,\n        \"min\": 15.709664311928872,\n        \"max\": 4638.026725824739,\n        \"num_unique_values\": 33890,\n        \"samples\": [\n          751.8099308831395,\n          158.48128181129624,\n          250.79281872093856\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"boll_lb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 698.8068657189793,\n        \"min\": 12.11878748437637,\n        \"max\": 4365.811002534436,\n        \"num_unique_values\": 33890,\n        \"samples\": [\n          656.0141963141261,\n          122.16933616966075,\n          218.96884357154192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rsi_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.957004937989392,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 33819,\n        \"samples\": [\n          48.94678537400492,\n          58.356884790747095,\n          50.447834011699065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cci_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 113.78566709291107,\n        \"min\": -675.2894148794771,\n        \"max\": 589.4292902520285,\n        \"num_unique_values\": 33893,\n        \"samples\": [\n          -2.899542821956259,\n          162.89616907114632,\n          146.75699824136393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.265045887177415,\n        \"min\": 0.0005956110442219442,\n        \"max\": 100.0,\n        \"num_unique_values\": 32756,\n        \"samples\": [\n          7.49566267499093,\n          28.75986559518698,\n          20.79734954881317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_30_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 735.9493072375417,\n        \"min\": 15.704917367299398,\n        \"max\": 4369.393489583334,\n        \"num_unique_values\": 33892,\n        \"samples\": [\n          554.5351277669271,\n          135.1910316467285,\n          217.7895980834961\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_60_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 728.9570844492808,\n        \"min\": 17.068274863560994,\n        \"max\": 4282.140169270833,\n        \"num_unique_values\": 33890,\n        \"samples\": [\n          701.7646443684896,\n          1739.4489908854166,\n          158.0380610148112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turbulence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.8135100807319,\n        \"min\": 0.0,\n        \"max\": 423.77426738168407,\n        \"num_unique_values\": 3985,\n        \"samples\": [\n          4.727772966189221,\n          2.5496438561542822,\n          2.6944785598325103\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from finrl.config import INDICATORS\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "import pandas as pd\n",
        "tickers = [\"RELIANCE.NS\", \"INFY.NS\", \"TCS.NS\", \"HDFCBANK.NS\", \"ICICIBANK.NS\", \"SBIN.NS\",\n",
        "           \"ADANIENT.NS\", \"PAYTM.NS\", \"ZOMATO.NS\", \"TATAMOTORS.NS\"]\n",
        "benchmark_ticker = \"^NSEI\"  # NIFTY 50\n",
        "\n",
        "start_date = \"2007-01-01\"\n",
        "end_date = \"2025-01-01\"\n",
        "\n",
        "df_s = YahooDownloader(start_date=start_date, end_date=end_date, ticker_list=tickers).fetch_data()\n",
        "df_benchmark = YahooDownloader(start_date=start_date, end_date=end_date, ticker_list=[benchmark_ticker]).fetch_data()\n",
        "\n",
        "df = pd.merge(df_s, df_benchmark[['date', 'close']], on='date', suffixes=('', '_benchmark'))\n",
        "\n",
        "df\n",
        "fe = FeatureEngineer(\n",
        "    use_technical_indicator=True,\n",
        "    tech_indicator_list=INDICATORS,\n",
        "    use_turbulence=True\n",
        ")\n",
        "df = fe.preprocess_data(df)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B_3Vjn5eo2D",
        "outputId": "06043f6e-5d40-4613-b774-9b3b234d8f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to indian_stock_data_this.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the processed dataset to a CSV file\n",
        "csv_filename = \"indian_stock_data_this.csv\"\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"Data saved to {csv_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zoOE0d49JH3-"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from typing import List\n",
        "import gymnasium as gym\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "from gymnasium.utils import seeding\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# from stable_baselines3.common.logger import Logger, KVWriter, CSVOutputFormat\n",
        "\n",
        "\n",
        "class StockTradingEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "\n",
        "    metadata = {\"render.modes\": [\"human\"]}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        stock_dim: int,\n",
        "        hmax: int,\n",
        "        initial_amount: int,\n",
        "        num_stock_shares: list[int],\n",
        "        buy_cost_pct: list[float],\n",
        "        sell_cost_pct: list[float],\n",
        "        reward_scaling: float,\n",
        "        state_space: int,\n",
        "        action_space: int,\n",
        "        treynor_rate_learn: float,\n",
        "        drawdown_component_learn: float,\n",
        "        #diversification_component_learn: float,\n",
        "        cost_component_learn: float,\n",
        "        risk_component_learn: float,\n",
        "        return_component_learn: float,\n",
        "        tech_indicator_list: list[str],\n",
        "        turbulence_threshold=None,\n",
        "        risk_indicator_col=\"turbulence\",\n",
        "        make_plots: bool = False,\n",
        "        print_verbosity=10,\n",
        "        day=0,\n",
        "        initial=True,\n",
        "        previous_state=[],\n",
        "        model_name=\"\",\n",
        "        mode=\"\",\n",
        "        iteration=\"\",\n",
        "    ):\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.num_stock_shares = num_stock_shares\n",
        "        self.initial_amount = initial_amount  # get the initial cash\n",
        "        self.buy_cost_pct = buy_cost_pct\n",
        "        self.sell_cost_pct = sell_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
        "        )\n",
        "\n",
        "        self.data = self._get_multi_stock_data()\n",
        "        # self.data = self.df.loc[self.day, :]\n",
        "\n",
        "        self.terminal = False\n",
        "        self.make_plots = make_plots\n",
        "        self.print_verbosity = print_verbosity\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        self.risk_indicator_col = risk_indicator_col\n",
        "        self.initial = initial\n",
        "        self.previous_state = previous_state\n",
        "        self.model_name = model_name\n",
        "        self.mode = mode\n",
        "        self.iteration = iteration\n",
        "        # initalize state\n",
        "        self.state = self._initiate_state()\n",
        "\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.episode = 0\n",
        "        self.treynor_rate_learn = 0.2\n",
        "        self.drawdown_component_learn = 0.1\n",
        "        #self.diversification_component_learn = 0.1\n",
        "        self.cost_component_learn = 0.1\n",
        "        self.risk_component_learn = 0.2\n",
        "        self.return_component_learn = 0.5\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [\n",
        "            self.initial_amount\n",
        "            + np.sum(\n",
        "                np.array(self.num_stock_shares)\n",
        "                * np.array(self.state[1 : 1 + self.stock_dim])\n",
        "            )\n",
        "        ]  # the initial total asset is calculated by cash + sum (num_share_stock_i * price_stock_i)\n",
        "        self.rewards_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.state_memory = (\n",
        "            []\n",
        "        )  # we need sometimes to preserve the state in the middle of trading process\n",
        "        self.date_memory = [self._get_date()]\n",
        "        #         self.logger = Logger('results',[CSVOutputFormat])\n",
        "        # self.reset()\n",
        "        self._seed()\n",
        "\n",
        "    def set_reward_weights(self, w_treynor, w_drawdown, w_cost, w_risk, w_return):\n",
        "        self.treynor_rate_learn = w_treynor\n",
        "        self.drawdown_component_learn = w_drawdown\n",
        "        self.cost_component_learn = w_cost\n",
        "        self.risk_component_learn = w_risk\n",
        "        self.return_component_learn = w_return\n",
        "        return\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        def _do_sell_normal():\n",
        "            if (\n",
        "                self.state[index + 2 * self.stock_dim + 1] != True\n",
        "            ):  # check if the stock is able to sell, for simlicity we just add it in techical index\n",
        "                # if self.state[index + 1] > 0: # if we use price<0 to denote a stock is unable to trade in that day, the total asset calculation may be wrong for the price is unreasonable\n",
        "                # Sell only if the price is > 0 (no missing data in this particular date)\n",
        "                # perform sell action based on the sign of the action\n",
        "                if self.state[index + self.stock_dim + 1] > 0:\n",
        "                    # Sell only if current asset is > 0\n",
        "                    sell_num_shares = min(\n",
        "                        abs(action), self.state[index + self.stock_dim + 1]\n",
        "                    )\n",
        "                    sell_amount = (\n",
        "                        self.state[index + 1]\n",
        "                        * sell_num_shares\n",
        "                        * (1 - self.sell_cost_pct[index])\n",
        "                    )\n",
        "                    # update balance\n",
        "                    self.state[0] += sell_amount\n",
        "\n",
        "                    self.state[index + self.stock_dim + 1] -= sell_num_shares\n",
        "                    self.cost += (\n",
        "                        self.state[index + 1]\n",
        "                        * sell_num_shares\n",
        "                        * self.sell_cost_pct[index]\n",
        "                    )\n",
        "                    self.trades += 1\n",
        "                else:\n",
        "                    sell_num_shares = 0\n",
        "            else:\n",
        "                sell_num_shares = 0\n",
        "\n",
        "            return sell_num_shares\n",
        "\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.turbulence_threshold is not None:\n",
        "            if self.turbulence >= self.turbulence_threshold:\n",
        "                if self.state[index + 1] > 0:\n",
        "                    # Sell only if the price is > 0 (no missing data in this particular date)\n",
        "                    # if turbulence goes over threshold, just clear out all positions\n",
        "                    if self.state[index + self.stock_dim + 1] > 0:\n",
        "                        # Sell only if current asset is > 0\n",
        "                        sell_num_shares = self.state[index + self.stock_dim + 1]\n",
        "                        sell_amount = (\n",
        "                            self.state[index + 1]\n",
        "                            * sell_num_shares\n",
        "                            * (1 - self.sell_cost_pct[index])\n",
        "                        )\n",
        "                        # update balance\n",
        "                        self.state[0] += sell_amount\n",
        "                        self.state[index + self.stock_dim + 1] = 0\n",
        "                        self.cost += (\n",
        "                            self.state[index + 1]\n",
        "                            * sell_num_shares\n",
        "                            * self.sell_cost_pct[index]\n",
        "                        )\n",
        "                        self.trades += 1\n",
        "                    else:\n",
        "                        sell_num_shares = 0\n",
        "                else:\n",
        "                    sell_num_shares = 0\n",
        "            else:\n",
        "                sell_num_shares = _do_sell_normal()\n",
        "        else:\n",
        "            sell_num_shares = _do_sell_normal()\n",
        "\n",
        "        return sell_num_shares\n",
        "\n",
        "    def _buy_stock(self, index, action):\n",
        "        def _do_buy():\n",
        "            if (\n",
        "                self.state[index + 2 * self.stock_dim + 1] != True\n",
        "            ):  # check if the stock is able to buy\n",
        "                # if self.state[index + 1] >0:\n",
        "                # Buy only if the price is > 0 (no missing data in this particular date)\n",
        "                available_amount = self.state[0] // (\n",
        "                    self.state[index + 1] * (1 + self.buy_cost_pct[index])\n",
        "                )  # when buying stocks, we should consider the cost of trading when calculating available_amount, or we may be have cash<0\n",
        "                # print('available_amount:{}'.format(available_amount))\n",
        "\n",
        "                # update balance\n",
        "                buy_num_shares = min(available_amount, action)\n",
        "                buy_amount = (\n",
        "                    self.state[index + 1]\n",
        "                    * buy_num_shares\n",
        "                    * (1 + self.buy_cost_pct[index])\n",
        "                )\n",
        "                self.state[0] -= buy_amount\n",
        "\n",
        "                self.state[index + self.stock_dim + 1] += buy_num_shares\n",
        "\n",
        "                self.cost += (\n",
        "                    self.state[index + 1] * buy_num_shares * self.buy_cost_pct[index]\n",
        "                )\n",
        "                self.trades += 1\n",
        "            else:\n",
        "                buy_num_shares = 0\n",
        "\n",
        "            return buy_num_shares\n",
        "\n",
        "        # perform buy action based on the sign of the action\n",
        "        if self.turbulence_threshold is None:\n",
        "            buy_num_shares = _do_buy()\n",
        "        else:\n",
        "            if self.turbulence < self.turbulence_threshold:\n",
        "                buy_num_shares = _do_buy()\n",
        "            else:\n",
        "                buy_num_shares = 0\n",
        "                pass\n",
        "\n",
        "        return buy_num_shares\n",
        "\n",
        "    def calculate_reward(self):\n",
        "        # Calculate return component\n",
        "        current_total_asset = self.state[0] + sum(\n",
        "            np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "            * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "        )\n",
        "        return_component = (self.asset_memory[-1] - self.asset_memory[-2])/self.asset_memory[-2]\n",
        "\n",
        "        # Convert memory to DataFrame\n",
        "        df_total_value = pd.DataFrame(self.asset_memory, columns=[\"account_value\"])\n",
        "        df_total_value[\"date\"] = self.date_memory\n",
        "        df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
        "\n",
        "        # Get benchmark values from the 'close_benchmark' column, but only for rows up to the length of asset_memory\n",
        "        df_total_value[\"benchmark_value\"] = self.df[\"close_benchmark\"].iloc[:len(df_total_value)].reset_index(drop=True)\n",
        "        df_total_value[\"benchmark_daily_return\"] = df_total_value[\"benchmark_value\"].pct_change(1)\n",
        "\n",
        "        # Calculate risk component (standard deviation of returns)\n",
        "        if len(self.asset_memory) > 1:\n",
        "            daily_returns = pd.Series(self.asset_memory).pct_change().dropna()\n",
        "            risk_component = -np.std(daily_returns) * 100  # Scale for learning\n",
        "        else:\n",
        "            risk_component = 0\n",
        "\n",
        "        # Calculate transaction cost component\n",
        "        cost_component = -self.cost * 0.1  # Scale for learning\n",
        "\n",
        "        # Calculate diversification component\n",
        "        if sum(np.abs(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])) == 0:\n",
        "            position_concentration = 0\n",
        "        else:\n",
        "            position_concentration = np.max(np.abs(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])) / sum(np.abs(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]))\n",
        "        #diversification_component = -position_concentration * 100  # Scale for learning\n",
        "\n",
        "        # Calculate drawdown component\n",
        "        if len(self.asset_memory) > 0:\n",
        "            peak_value = np.max(self.asset_memory)\n",
        "            drawdown_component = -(peak_value - current_total_asset) / peak_value * 100  # Scale for learning\n",
        "        else:\n",
        "            drawdown_component = 0\n",
        "        #remove_nan = lambda x: 0 if np.isnan(x) else x\n",
        "\n",
        "        # Calculate portfolio returns and risks\n",
        "        mean_returns = df_total_value[\"daily_return\"].mean()\n",
        "        std_returns = df_total_value[\"daily_return\"].std()\n",
        "\n",
        "        # Calculate benchmark returns and risks\n",
        "        bench_returns = df_total_value[\"benchmark_daily_return\"].mean()\n",
        "        bench_std = df_total_value[\"benchmark_daily_return\"].std()\n",
        "\n",
        "        # Calculate beta\n",
        "        beta = 1.0  # default value\n",
        "        if bench_std and not np.isnan(bench_std) and bench_std != 0:\n",
        "            portfolio_returns = df_total_value[\"daily_return\"].fillna(0)\n",
        "            benchmark_returns = df_total_value[\"benchmark_daily_return\"].fillna(0)\n",
        "            if len(portfolio_returns) == len(benchmark_returns):\n",
        "                covariance = np.cov(portfolio_returns, benchmark_returns)[0][1]\n",
        "                beta = covariance / (bench_std ** 2)\n",
        "\n",
        "        treynor = 0\n",
        "        if beta and not np.isnan(beta) and beta != 0:\n",
        "            treynor = (252**0.5) * mean_returns / beta\n",
        "        # Combine components with weights\n",
        "        total_reward = (return_component * self.return_component_learn +\n",
        "                        risk_component * self.risk_component_learn +\n",
        "                        cost_component * self.cost_component_learn +\n",
        "                        #diversification_component * self.diversification_component_learn +\n",
        "                        drawdown_component * self.drawdown_component_learn\n",
        "                        +treynor*self.treynor_rate_learn)\n",
        "\n",
        "        self.previous_total_asset = current_total_asset\n",
        "\n",
        "        return total_reward\n",
        "\n",
        "    def _make_plot(self):\n",
        "        plt.plot(self.asset_memory, \"r\")\n",
        "        plt.savefig(f\"results/account_value_trade_{self.episode}.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.terminal = self.day >= len(self.df.index.unique()) / len(self.df[\"tic\"].unique()) - 1\n",
        "        if self.terminal:\n",
        "            # print(f\"Episode: {self.episode}\")\n",
        "            if self.make_plots:\n",
        "                self._make_plot()\n",
        "            end_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "            )\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            tot_reward = (\n",
        "                self.state[0]\n",
        "                + sum(\n",
        "                    np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                    * np.array(\n",
        "                        self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
        "                    )\n",
        "                )\n",
        "                - self.asset_memory[0]\n",
        "            )  # initial_amount is only cash part of our initial asset\n",
        "            df_total_value.columns = [\"account_value\"]\n",
        "            df_total_value[\"date\"] = self.date_memory\n",
        "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(\n",
        "                1\n",
        "            )\n",
        "            if df_total_value[\"daily_return\"].std() != 0:\n",
        "                sharpe = (\n",
        "                    (252**0.5)\n",
        "                    * df_total_value[\"daily_return\"].mean()\n",
        "                    / df_total_value[\"daily_return\"].std()\n",
        "                )\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.columns = [\"account_rewards\"]\n",
        "            df_rewards[\"date\"] = self.date_memory[:-1]\n",
        "            if self.episode % self.print_verbosity == 0:\n",
        "                print(f\"day: {self.day}, episode: {self.episode}\")\n",
        "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
        "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
        "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
        "                print(f\"total_cost: {self.cost:0.2f}\")\n",
        "                print(f\"total_trades: {self.trades}\")\n",
        "                if df_total_value[\"daily_return\"].std() != 0:\n",
        "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
        "                print(\"=================================\")\n",
        "\n",
        "            if (self.model_name != \"\") and (self.mode != \"\"):\n",
        "                df_actions = self.save_action_memory()\n",
        "                df_actions.to_csv(\n",
        "                    \"results/actions_{}_{}_{}.csv\".format(\n",
        "                        self.mode, self.model_name, self.iteration\n",
        "                    )\n",
        "                )\n",
        "                df_total_value.to_csv(\n",
        "                    \"results/account_value_{}_{}_{}.csv\".format(\n",
        "                        self.mode, self.model_name, self.iteration\n",
        "                    ),\n",
        "                    index=False,\n",
        "                )\n",
        "                df_rewards.to_csv(\n",
        "                    \"results/account_rewards_{}_{}_{}.csv\".format(\n",
        "                        self.mode, self.model_name, self.iteration\n",
        "                    ),\n",
        "                    index=False,\n",
        "                )\n",
        "                plt.plot(self.asset_memory, \"r\")\n",
        "                plt.savefig(\n",
        "                    \"results/account_value_{}_{}_{}.png\".format(\n",
        "                        self.mode, self.model_name, self.iteration\n",
        "                    )\n",
        "                )\n",
        "                plt.close()\n",
        "\n",
        "            # Add outputs to logger interface\n",
        "            # logger.record(\"environment/portfolio_value\", end_total_asset)\n",
        "            # logger.record(\"environment/total_reward\", tot_reward)\n",
        "            # logger.record(\"environment/total_reward_pct\", (tot_reward / (end_total_asset - tot_reward)) * 100)\n",
        "            # logger.record(\"environment/total_cost\", self.cost)\n",
        "            # logger.record(\"environment/total_trades\", self.trades)\n",
        "\n",
        "            return self.state, self.reward, self.terminal, False, {}\n",
        "\n",
        "        else:\n",
        "            actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n",
        "            actions = actions.astype(\n",
        "                int\n",
        "            )  # convert into integer because we can't by fraction of shares\n",
        "            if self.turbulence_threshold is not None:\n",
        "                if self.turbulence >= self.turbulence_threshold:\n",
        "                    actions = np.array([-self.hmax] * self.stock_dim)\n",
        "            begin_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "            )\n",
        "            # print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "\n",
        "            argsort_actions = np.argsort(actions)\n",
        "            sell_index = argsort_actions[: np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][: np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print(f\"Num shares before: {self.state[index+self.stock_dim+1]}\")\n",
        "                # print(f'take sell action before : {actions[index]}')\n",
        "                actions[index] = self._sell_stock(index, actions[index]) * (-1)\n",
        "                # print(f'take sell action after : {actions[index]}')\n",
        "                # print(f\"Num shares after: {self.state[index+self.stock_dim+1]}\")\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                actions[index] = self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.actions_memory.append(actions)\n",
        "\n",
        "            # state: s -> s+1\n",
        "            self.day += 1\n",
        "            self.data = self._get_multi_stock_data()\n",
        "            # self.data = self.df.loc[self.day, :]\n",
        "\n",
        "            if self.turbulence_threshold is not None:\n",
        "                if len(self.df.tic.unique()) == 1:\n",
        "                    self.turbulence = self.data[self.risk_indicator_col]\n",
        "                elif len(self.df.tic.unique()) > 1:\n",
        "                    self.turbulence = self.data[self.risk_indicator_col].values[0]\n",
        "            self.state = self._update_state()\n",
        "\n",
        "            end_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "            )\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            self.date_memory.append(self._get_date())\n",
        "            self.reward = self.calculate_reward()\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            self.reward = self.reward * self.reward_scaling\n",
        "            self.state_memory.append(\n",
        "                self.state\n",
        "            )  # add current state in state_recorder for each step\n",
        "\n",
        "        return self.state, self.reward, self.terminal, False, {}\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed=None,\n",
        "        options=None,\n",
        "    ):\n",
        "        # initiate state\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day, :]\n",
        "        self.state = self._initiate_state()\n",
        "\n",
        "        if self.initial:\n",
        "            self.asset_memory = [\n",
        "                self.initial_amount\n",
        "                + np.sum(\n",
        "                    np.array(self.num_stock_shares)\n",
        "                    * np.array(self.state[1 : 1 + self.stock_dim])\n",
        "                )\n",
        "            ]\n",
        "        else:\n",
        "            previous_total_asset = self.previous_state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(\n",
        "                    self.previous_state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
        "                )\n",
        "            )\n",
        "            self.asset_memory = [previous_total_asset]\n",
        "\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False\n",
        "        # self.iteration=self.iteration\n",
        "        self.rewards_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.date_memory = [self._get_date()]\n",
        "\n",
        "        self.episode += 1\n",
        "\n",
        "        return self.state, {}\n",
        "\n",
        "    def render(self, mode=\"human\", close=False):\n",
        "        return self.state\n",
        "\n",
        "    def _initiate_state(self):\n",
        "        if self.initial:\n",
        "            # For Initial State\n",
        "            if len(self.df.tic.unique()) > 1:\n",
        "                self.data = self._get_multi_stock_data()\n",
        "                # for multiple stock\n",
        "                state = (\n",
        "                    [self.initial_amount]\n",
        "                    + self.data.close.values.tolist()\n",
        "                    + self.num_stock_shares\n",
        "                    + sum(\n",
        "                        (\n",
        "                            self.data[tech].values.tolist()\n",
        "                            for tech in self.tech_indicator_list\n",
        "                        ),\n",
        "                        [],\n",
        "                    )\n",
        "                )  # append initial stocks_share to initial state, instead of all zero\n",
        "            else:\n",
        "                # for single stock\n",
        "                state = (\n",
        "                    [self.initial_amount]\n",
        "                    + [self.data.close]\n",
        "                    + [0] * self.stock_dim\n",
        "                    + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n",
        "                )\n",
        "        else:\n",
        "            # Using Previous State\n",
        "            if len(self.df.tic.unique()) > 1:\n",
        "                # for multiple stock\n",
        "                state = (\n",
        "                    [self.previous_state[0]]\n",
        "                    + self.data.close.values.tolist()\n",
        "                    + self.previous_state[\n",
        "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
        "                    ]\n",
        "                    + sum(\n",
        "                        (\n",
        "                            self.data[tech].values.tolist()\n",
        "                            for tech in self.tech_indicator_list\n",
        "                        ),\n",
        "                        [],\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                # for single stock\n",
        "                state = (\n",
        "                    [self.previous_state[0]]\n",
        "                    + [self.data.close]\n",
        "                    + self.previous_state[\n",
        "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
        "                    ]\n",
        "                    + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n",
        "                )\n",
        "        return state\n",
        "\n",
        "    def _update_state(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            self.data = self._get_multi_stock_data()\n",
        "            # for multiple stock\n",
        "            state = (\n",
        "                [self.state[0]]\n",
        "                + self.data.close.values.tolist()\n",
        "                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "                + sum(\n",
        "                    (\n",
        "                        self.data[tech].values.tolist()\n",
        "                        for tech in self.tech_indicator_list\n",
        "                    ),\n",
        "                    [],\n",
        "                )\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            # for single stock\n",
        "            state = (\n",
        "                [self.state[0]]\n",
        "                + [self.data.close]\n",
        "                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "                + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n",
        "            )\n",
        "\n",
        "        return state\n",
        "\n",
        "    ############################## Custom Method to parse data for multi stock data\n",
        "    def _get_multi_stock_data(self):\n",
        "        _tickers = len(self.df.tic.unique())\n",
        "        return self.df.loc[ [i for i in range(\n",
        "            self.day * _tickers, self.day * _tickers + _tickers\n",
        "        )], : ]\n",
        "\n",
        "    def _get_date(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            date = self.data.date.unique()[0]\n",
        "        else:\n",
        "            date = self.data.date\n",
        "        return date\n",
        "\n",
        "    # add save_state_memory to preserve state in the trading process\n",
        "    def save_state_memory(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            # date and close price length must match actions length\n",
        "            date_list = self.date_memory[:-1]\n",
        "            df_date = pd.DataFrame(date_list)\n",
        "            df_date.columns = [\"date\"]\n",
        "\n",
        "            state_list = self.state_memory\n",
        "            df_states = pd.DataFrame(\n",
        "                state_list,\n",
        "                columns=[\n",
        "                    \"cash\",\n",
        "                    \"Bitcoin_price\",\n",
        "                    \"Gold_price\",\n",
        "                    \"Bitcoin_num\",\n",
        "                    \"Gold_num\",\n",
        "                    \"Bitcoin_Disable\",\n",
        "                    \"Gold_Disable\",\n",
        "                ],\n",
        "            )\n",
        "            df_states.index = df_date.date\n",
        "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        else:\n",
        "            date_list = self.date_memory[:-1]\n",
        "            state_list = self.state_memory\n",
        "            df_states = pd.DataFrame({\"date\": date_list, \"states\": state_list})\n",
        "        # print(df_states)\n",
        "        return df_states\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        asset_list = self.asset_memory\n",
        "        # print(len(date_list))\n",
        "        # print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame(\n",
        "            {\"date\": date_list, \"account_value\": asset_list}\n",
        "        )\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            # date and close price length must match actions length\n",
        "            date_list = self.date_memory[:-1]\n",
        "            df_date = pd.DataFrame(date_list)\n",
        "            df_date.columns = [\"date\"]\n",
        "\n",
        "            action_list = self.actions_memory\n",
        "            df_actions = pd.DataFrame(action_list)\n",
        "            df_actions.columns = self.data.tic.values\n",
        "            df_actions.index = df_date.date\n",
        "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        else:\n",
        "            date_list = self.date_memory[:-1]\n",
        "            action_list = self.actions_memory\n",
        "            df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_D0JKUe7GyUU",
        "outputId": "c58c2647-b178-40c5-cd77-2d28b3b4fb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             date        close         high          low         open  \\\n",
            "0      2010-01-04    57.215858    69.586876    66.368103    67.011856   \n",
            "1      2010-01-04   151.915100   172.850006   169.255005   170.000000   \n",
            "2      2010-01-04   132.206039   160.909088   159.090912   159.454544   \n",
            "3      2010-01-04   234.755280   328.750000   324.412506   326.250000   \n",
            "4      2010-01-04   209.196442   249.407104   233.577728   249.407104   \n",
            "...           ...          ...          ...          ...          ...   \n",
            "15183  2017-10-05  1050.873901  1221.724976  1212.199951  1220.500000   \n",
            "15184  2017-10-06    66.201927    68.112656    66.341721    66.968361   \n",
            "15185  2017-10-06   851.347168   902.224976   897.000000   899.000000   \n",
            "15186  2017-10-06   258.971344   274.450012   270.549988   272.149994   \n",
            "15187  2017-10-06   379.751068   461.000000   451.975006   452.000000   \n",
            "\n",
            "         volume           tic  day  close_benchmark      macd      boll_ub  \\\n",
            "0       1860224   ADANIENT.NS    0      5232.200195  0.000000    59.750214   \n",
            "1       3050490   HDFCBANK.NS    0      5232.200195  0.000000    59.750214   \n",
            "2       9162186  ICICIBANK.NS    0      5232.200195  0.000000    59.750214   \n",
            "3       4069264       INFY.NS    0      5232.200195  0.000000    59.750214   \n",
            "4      76646086   RELIANCE.NS    0      5232.200195  0.000000    59.750214   \n",
            "...         ...           ...  ...              ...       ...          ...   \n",
            "15183   1684686        TCS.NS    3      9888.700195 -4.138332  1095.542915   \n",
            "15184  11055196   ADANIENT.NS    4      9979.700195 -1.326967    74.247553   \n",
            "15185   1515330   HDFCBANK.NS    4      9979.700195  2.160692   883.950929   \n",
            "15186  25447787  ICICIBANK.NS    4      9979.700195 -5.341962   285.945932   \n",
            "15187   8574308       INFY.NS    4      9979.700195 -1.705964   380.511787   \n",
            "\n",
            "           boll_lb      rsi_30      cci_30       dx_30  close_30_sma  \\\n",
            "0        56.005470  100.000000   66.666667  100.000000     57.215858   \n",
            "1        56.005470  100.000000   66.666667  100.000000    151.915100   \n",
            "2        56.005470  100.000000   66.666667  100.000000    132.206039   \n",
            "3        56.005470  100.000000   66.666667  100.000000    234.755280   \n",
            "4        56.005470  100.000000   66.666667  100.000000    209.196442   \n",
            "...            ...         ...         ...         ...           ...   \n",
            "15183  1049.297783   46.291797 -167.126720    8.651446   1072.148576   \n",
            "15184    58.716668   49.223835  -16.219189   10.123769     67.017929   \n",
            "15185   836.275462   55.841483    0.313555    3.899871    851.124894   \n",
            "15186   255.041797   39.100407 -136.762091   43.353010    274.841004   \n",
            "15187   362.220046   49.265826   62.419736    5.677169    373.254396   \n",
            "\n",
            "       close_60_sma  turbulence  \n",
            "0         57.215858    0.000000  \n",
            "1        151.915100    0.000000  \n",
            "2        132.206039    0.000000  \n",
            "3        234.755280    0.000000  \n",
            "4        209.196442    0.000000  \n",
            "...             ...         ...  \n",
            "15183   1073.160583    5.230936  \n",
            "15184     68.510368    5.050381  \n",
            "15185    838.678182    5.050381  \n",
            "15186    279.337329    5.050381  \n",
            "15187    387.188026         NaN  \n",
            "\n",
            "[15188 rows x 18 columns]\n",
            "stock_dim = 8\n",
            "state_space = 97\n",
            "             date        close         high          low         open  \\\n",
            "0      2010-01-04    57.215858    69.586876    66.368103    67.011856   \n",
            "1      2010-01-04   151.915100   172.850006   169.255005   170.000000   \n",
            "2      2010-01-04   132.206039   160.909088   159.090912   159.454544   \n",
            "3      2010-01-04   234.755280   328.750000   324.412506   326.250000   \n",
            "4      2010-01-04   209.196442   249.407104   233.577728   249.407104   \n",
            "...           ...          ...          ...          ...          ...   \n",
            "15183  2017-10-05  1050.873901  1221.724976  1212.199951  1220.500000   \n",
            "15184  2017-10-06    66.201927    68.112656    66.341721    66.968361   \n",
            "15185  2017-10-06   851.347168   902.224976   897.000000   899.000000   \n",
            "15186  2017-10-06   258.971344   274.450012   270.549988   272.149994   \n",
            "15187  2017-10-06   379.751068   461.000000   451.975006   452.000000   \n",
            "\n",
            "         volume           tic  day  close_benchmark      macd      boll_ub  \\\n",
            "0       1860224   ADANIENT.NS    0      5232.200195  0.000000    59.750214   \n",
            "1       3050490   HDFCBANK.NS    0      5232.200195  0.000000    59.750214   \n",
            "2       9162186  ICICIBANK.NS    0      5232.200195  0.000000    59.750214   \n",
            "3       4069264       INFY.NS    0      5232.200195  0.000000    59.750214   \n",
            "4      76646086   RELIANCE.NS    0      5232.200195  0.000000    59.750214   \n",
            "...         ...           ...  ...              ...       ...          ...   \n",
            "15183   1684686        TCS.NS    3      9888.700195 -4.138332  1095.542915   \n",
            "15184  11055196   ADANIENT.NS    4      9979.700195 -1.326967    74.247553   \n",
            "15185   1515330   HDFCBANK.NS    4      9979.700195  2.160692   883.950929   \n",
            "15186  25447787  ICICIBANK.NS    4      9979.700195 -5.341962   285.945932   \n",
            "15187   8574308       INFY.NS    4      9979.700195 -1.705964   380.511787   \n",
            "\n",
            "           boll_lb      rsi_30      cci_30       dx_30  close_30_sma  \\\n",
            "0        56.005470  100.000000   66.666667  100.000000     57.215858   \n",
            "1        56.005470  100.000000   66.666667  100.000000    151.915100   \n",
            "2        56.005470  100.000000   66.666667  100.000000    132.206039   \n",
            "3        56.005470  100.000000   66.666667  100.000000    234.755280   \n",
            "4        56.005470  100.000000   66.666667  100.000000    209.196442   \n",
            "...            ...         ...         ...         ...           ...   \n",
            "15183  1049.297783   46.291797 -167.126720    8.651446   1072.148576   \n",
            "15184    58.716668   49.223835  -16.219189   10.123769     67.017929   \n",
            "15185   836.275462   55.841483    0.313555    3.899871    851.124894   \n",
            "15186   255.041797   39.100407 -136.762091   43.353010    274.841004   \n",
            "15187   362.220046   49.265826   62.419736    5.677169    373.254396   \n",
            "\n",
            "       close_60_sma  turbulence  \n",
            "0         57.215858    0.000000  \n",
            "1        151.915100    0.000000  \n",
            "2        132.206039    0.000000  \n",
            "3        234.755280    0.000000  \n",
            "4        209.196442    0.000000  \n",
            "...             ...         ...  \n",
            "15183   1073.160583    5.230936  \n",
            "15184     68.510368    5.050381  \n",
            "15185    838.678182    5.050381  \n",
            "15186    279.337329    5.050381  \n",
            "15187    387.188026         NaN  \n",
            "\n",
            "[15188 rows x 18 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.StockTradingEnv at 0x796ce2b762d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "all_indicators = [\"volume\",\t\"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\", \"turbulence\"]\n",
        "use_indicators = [\"volume\",\t\"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\", \"turbulence\"]\n",
        "turbulence_thresold=100\n",
        "df = pd.read_csv(\"/content/indian_stock_data.csv\")\n",
        "df = df[(df['date'] >= \"2008-09-24\") & (df['date'] <= \"2022-01-01\")]\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(df)\n",
        "\n",
        "stock_dim = len(df[\"tic\"].unique())\n",
        "print(\"stock_dim =\", stock_dim)\n",
        "\n",
        "state_space = 1 + 2*stock_dim + stock_dim * len(use_indicators)\n",
        "print(\"state_space =\", state_space)\n",
        "\n",
        "max_price = df['close'].max()\n",
        "initial_amount = 100000\n",
        "hmax = int(initial_amount / max_price)\n",
        "\n",
        "env = StockTradingEnv(\n",
        "    df=df,\n",
        "    stock_dim=stock_dim,\n",
        "    hmax=hmax,\n",
        "    initial_amount=initial_amount,\n",
        "    num_stock_shares=[0] * stock_dim,\n",
        "\n",
        "    # Verbose\n",
        "    make_plots=True,\n",
        "    print_verbosity=1,\n",
        "    treynor_rate_learn = 0.2,\n",
        "    drawdown_component_learn = 0.1,\n",
        "    #diversification_component_learn = 0.1,\n",
        "    cost_component_learn = 0.1,\n",
        "    risk_component_learn = 0.2,\n",
        "    return_component_learn = 0.5,\n",
        "\n",
        "    # Transaction Cost\n",
        "    buy_cost_pct=[0.001] * stock_dim,\n",
        "    sell_cost_pct=[0.001] * stock_dim,\n",
        "\n",
        "    # Turbulence Thresold\n",
        "    turbulence_threshold=turbulence_thresold,\n",
        "\n",
        "    reward_scaling=1e-4,\n",
        "    tech_indicator_list=use_indicators,\n",
        "\n",
        "    # State Space: Portfolio Value + Holdings + Tech Indicators\n",
        "    state_space=state_space,\n",
        "\n",
        "    # Action Space\n",
        "    action_space=stock_dim,\n",
        ")\n",
        "\n",
        "os.makedirs(\"results\", exist_ok=True) # set up folder for plots\n",
        "print(df)\n",
        "env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tickers = df[\"tic\"].unique()\n",
        "tickers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BM-6ycykWzSR",
        "outputId": "41dabc44-b15a-445c-ba88-5917c504c179"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ADANIENT.NS', 'HDFCBANK.NS', 'ICICIBANK.NS', 'INFY.NS',\n",
              "       'RELIANCE.NS', 'SBIN.NS', 'TATAMOTORS.NS', 'TCS.NS'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tG-NkZJ6KSY6",
        "outputId": "2e88b4ef-a9ac-4f62-ec73-47263ca42b49",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.24e+03    |\n",
            "|    ep_rew_mean          | -165        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 62          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 294         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012022428 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.2       |\n",
            "|    explained_variance   | 0.653       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.264       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0255     |\n",
            "|    std                  | 0.981       |\n",
            "|    value_loss           | 0.403       |\n",
            "-----------------------------------------\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n",
            "Treynor: 0.2\n",
            "Drawdown: 0.1\n",
            "Cost: 0.1\n",
            "Risk: 0.2\n",
            "Return: 0.5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0f232c8ff2a3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting new training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6da8e1f42638>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6da8e1f42638>\u001b[0m in \u001b[0;36mcalculate_reward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mbenchmark_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_total_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"benchmark_daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportfolio_returns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportfolio_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovariance\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbench_std\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2747\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0maweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2749\u001b[0;31m     \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2750\u001b[0m     \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeepdims_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mavg_as_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_as_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg_as_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_no_nep50_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "resume_training=True\n",
        "env.reset()\n",
        "vec_env = make_vec_env(lambda: Monitor(env, '/'), n_envs=1)\n",
        "\n",
        "if resume_training:\n",
        "    try:\n",
        "      model = PPO.load(\"resume\", env=vec_env, verbose=1)\n",
        "      print(\"Resuming training...\")\n",
        "    except:\n",
        "      model = PPO(\"MlpPolicy\", env=vec_env, verbose=1)\n",
        "      print(\"Starting new training...\")\n",
        "else:\n",
        "    model = PPO(\"MlpPolicy\", env=vec_env, verbose=1)\n",
        "    print(\"Starting new training...\")\n",
        "\n",
        "model.learn(total_timesteps=100_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rSoFMEb0RxAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4b835373-97ef-4dfa-b419-caf8513b7d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import gym\n",
        "import warnings\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize the environment\n",
        "#env = StockTradingEnv()  # Ensure this is correctly defined\n",
        "vec_env = make_vec_env(lambda: Monitor(env, '/'), n_envs=1)  # Wrap in VecEnv\n",
        "\n",
        "def optimize_agent(trial):\n",
        "    \"\"\"Objective function for Optuna to optimize PPO hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the hyperparameter search space\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.8, 0.999)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 128, 2048, step=128)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 32, 1024, step=64)\n",
        "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 20)\n",
        "    ent_coef = trial.suggest_float(\"ent_coef\", 0.0, 0.1)\n",
        "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.4)\n",
        "    w_treynor = trial.suggest_float(\"treynor_rate_learn\", 0.1, 5.0)  # More profit weight\n",
        "    w_drawdown = trial.suggest_float(\"drawdown_component_learn\", 0.1, 5.0)  # Risk penalty weight\n",
        "    #w_diverse = trial.suggest_float(\"diversification_component_learn\", 0.1, 5.0)  # Risk penalty weight\n",
        "    w_cost = trial.suggest_float(\"cost_component_learn\", 0.1, 5.0)\n",
        "    w_risk = trial.suggest_float(\"risk_component_learn\", 0.1, 6.0)\n",
        "    w_return = trial.suggest_float(\"return_component_learn\", 0.1, 7.0)\n",
        "    \"\"\"treynor_rate_learn = 0.2\n",
        "drawdown_component_learn = 0.1\n",
        "diversification_component_learn = 0.1\n",
        "cost_component_learn = 0.1\n",
        "risk_component_learn = 0.2\n",
        "return_component_learn = 0.5\"\"\"\n",
        "    print(f\"Treynor: {w_treynor}\")\n",
        "    print(f\"Drawdown: {w_drawdown}\")\n",
        "    #print(f\"Diversification: {self.diversification_component_learn}\")\n",
        "    print(f\"Cost: {w_cost}\")\n",
        "    print(f\"Risk: {w_risk}\")\n",
        "    print(f\"Return: {w_return}\")\n",
        "\n",
        "    # Ensure batch_size does not exceed n_steps\n",
        "\n",
        "    if batch_size > n_steps:\n",
        "        return float(\"-inf\")\n",
        "\n",
        "    # Initialize the PPO model with suggested hyperparameters\n",
        "    env.set_reward_weights(w_treynor, w_drawdown, w_cost, w_risk, w_return)\n",
        "    model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "\n",
        "    # Train the model\n",
        "    model.learn(total_timesteps=100_000)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mean_reward, _ = evaluate_policy(model, vec_env, n_eval_episodes=1)\n",
        "\n",
        "    return mean_reward  # Optuna will maximize this reward\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(optimize_agent, n_trials=15)\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 29392
        },
        "id": "MTiok6_uQSJ8",
        "outputId": "b2fd785f-5e15-43a7-8283-7a551a86b28d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-16 04:34:57,123] A new study created in memory with name: no-name-18a4b3e6-946e-4808-a9d0-8733c3391166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treynor: 0.4013949773199673\n",
            "Drawdown: 2.9068009015669793\n",
            "Cost: 4.994821708372366\n",
            "Risk: 2.947383762136368\n",
            "Return: 4.862429692924584\n",
            "Using cuda device\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 67   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 24   |\n",
            "|    total_timesteps | 1664 |\n",
            "-----------------------------\n",
            "day: 2940, episode: 1\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 240670.79\n",
            "total_reward: 140670.79\n",
            "total_cost: 117284.68\n",
            "total_trades: 20412\n",
            "Sharpe: 0.474\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.73e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 3328        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008682915 |\n",
            "|    clip_fraction        | 0.0182      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | 0.0564      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 9.52        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00745    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 23.2        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.73e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 67            |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 74            |\n",
            "|    total_timesteps      | 4992          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00091784325 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.4         |\n",
            "|    explained_variance   | -0.0253       |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 102           |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00164      |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 208           |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 2\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 362461.64\n",
            "total_reward: 262461.64\n",
            "total_cost: 132746.25\n",
            "total_trades: 20846\n",
            "Sharpe: 0.680\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.92e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 6656         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022137985 |\n",
            "|    clip_fraction        | 0.000104     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.0541      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 20.8         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 46           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.92e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 123          |\n",
            "|    total_timesteps      | 8320         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017185119 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.0487      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 99.3         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 199          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 3\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 280511.90\n",
            "total_reward: 180511.90\n",
            "total_cost: 118247.85\n",
            "total_trades: 20248\n",
            "Sharpe: 0.546\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.83e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 147          |\n",
            "|    total_timesteps      | 9984         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043916297 |\n",
            "|    clip_fraction        | 0.00253      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.119       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 34.3         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0045      |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 76.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.83e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 172          |\n",
            "|    total_timesteps      | 11648        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032337308 |\n",
            "|    clip_fraction        | 0.000506     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.0674      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 46.4         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00406     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 109          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 4\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 204575.80\n",
            "total_reward: 104575.80\n",
            "total_cost: 112567.52\n",
            "total_trades: 20112\n",
            "Sharpe: 0.408\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.72e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 196          |\n",
            "|    total_timesteps      | 13312        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036483165 |\n",
            "|    clip_fraction        | 0.00152      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.124       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 54.3         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00406     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 121          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 5\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 555397.74\n",
            "total_reward: 455397.74\n",
            "total_cost: 130034.91\n",
            "total_trades: 20470\n",
            "Sharpe: 0.817\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.75e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 67          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 221         |\n",
            "|    total_timesteps      | 14976       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010378239 |\n",
            "|    clip_fraction        | 0.0366      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | -0.0404     |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 18.8        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0078     |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 33.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.75e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 245          |\n",
            "|    total_timesteps      | 16640        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014520298 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.0202      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 80.9         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00256     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 164          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 6\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 262505.30\n",
            "total_reward: 162505.30\n",
            "total_cost: 104035.79\n",
            "total_trades: 20108\n",
            "Sharpe: 0.499\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.64e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 67          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 269         |\n",
            "|    total_timesteps      | 18304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010925145 |\n",
            "|    clip_fraction        | 0.0311      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | -0.109      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 5.24        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00765    |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 12.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.64e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 294          |\n",
            "|    total_timesteps      | 19968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030754458 |\n",
            "|    clip_fraction        | 0.00107      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.0439      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 43           |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.005       |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 95.4         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 7\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 322743.66\n",
            "total_reward: 222743.66\n",
            "total_cost: 118795.10\n",
            "total_trades: 20288\n",
            "Sharpe: 0.612\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.62e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 318          |\n",
            "|    total_timesteps      | 21632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060277674 |\n",
            "|    clip_fraction        | 0.00465      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.0907      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 12.9         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00533     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 29.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.62e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 357          |\n",
            "|    total_timesteps      | 23296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045922045 |\n",
            "|    clip_fraction        | 0.00247      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.0531      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 47.9         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.005       |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 95.6         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 8\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 589353.51\n",
            "total_reward: 489353.51\n",
            "total_cost: 124750.91\n",
            "total_trades: 20547\n",
            "Sharpe: 0.844\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.61e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 381          |\n",
            "|    total_timesteps      | 24960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019494899 |\n",
            "|    clip_fraction        | 4.96e-05     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.0602      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 34.2         |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 65.7         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 9\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 830047.80\n",
            "total_reward: 730047.80\n",
            "total_cost: 131069.26\n",
            "total_trades: 20817\n",
            "Sharpe: 1.005\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.63e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 65          |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 406         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011156484 |\n",
            "|    clip_fraction        | 0.042       |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | -0.0374     |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 24.3        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0107     |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 54.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.63e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 431          |\n",
            "|    total_timesteps      | 28288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007457463 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | 0.00719      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 55.6         |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00093     |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 120          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 10\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 711901.37\n",
            "total_reward: 611901.37\n",
            "total_cost: 119003.91\n",
            "total_trades: 20628\n",
            "Sharpe: 0.951\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.62e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 65          |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 456         |\n",
            "|    total_timesteps      | 29952       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006990984 |\n",
            "|    clip_fraction        | 0.00871     |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | -0.107      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 4.69        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00613    |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.62e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 482          |\n",
            "|    total_timesteps      | 31616        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016447109 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | 0.0121       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 53.4         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00241     |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 103          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 11\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 502835.89\n",
            "total_reward: 402835.89\n",
            "total_cost: 115554.67\n",
            "total_trades: 20248\n",
            "Sharpe: 0.796\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.57e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 506          |\n",
            "|    total_timesteps      | 33280        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0144661665 |\n",
            "|    clip_fraction        | 0.0409       |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | -0.0708      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 6.4          |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00879     |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 14.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.57e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 532          |\n",
            "|    total_timesteps      | 34944        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028075026 |\n",
            "|    clip_fraction        | 0.000704     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | 0.0078       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 38.5         |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00343     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 79.6         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 12\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 239076.95\n",
            "total_reward: 139076.95\n",
            "total_cost: 99369.68\n",
            "total_trades: 20181\n",
            "Sharpe: 0.468\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.5e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 22            |\n",
            "|    time_elapsed         | 556           |\n",
            "|    total_timesteps      | 36608         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00086675305 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.6         |\n",
            "|    explained_variance   | 0.0203        |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 10.5          |\n",
            "|    n_updates            | 210           |\n",
            "|    policy_gradient_loss | -0.00142      |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 21.5          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 13\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 662831.42\n",
            "total_reward: 562831.42\n",
            "total_cost: 127303.83\n",
            "total_trades: 20850\n",
            "Sharpe: 0.942\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.5e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 581          |\n",
            "|    total_timesteps      | 38272        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074132737 |\n",
            "|    clip_fraction        | 0.00987      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.7        |\n",
            "|    explained_variance   | 0.0112       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 20.1         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00608     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 41.7         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.5e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 24            |\n",
            "|    time_elapsed         | 605           |\n",
            "|    total_timesteps      | 39936         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00026421997 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.7         |\n",
            "|    explained_variance   | 0.0556        |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 46.1          |\n",
            "|    n_updates            | 230           |\n",
            "|    policy_gradient_loss | -0.000422     |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 92.2          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 14\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 792150.46\n",
            "total_reward: 692150.46\n",
            "total_cost: 126257.59\n",
            "total_trades: 20732\n",
            "Sharpe: 1.026\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.49e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 630          |\n",
            "|    total_timesteps      | 41600        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035025862 |\n",
            "|    clip_fraction        | 0.00116      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.7        |\n",
            "|    explained_variance   | -0.0361      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 4.98         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00426     |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 12.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.49e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 654          |\n",
            "|    total_timesteps      | 43264        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011629144 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.7        |\n",
            "|    explained_variance   | 0.0552       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 48.6         |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 93.3         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 15\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1229544.80\n",
            "total_reward: 1129544.80\n",
            "total_cost: 133187.15\n",
            "total_trades: 20968\n",
            "Sharpe: 1.163\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.51e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 679         |\n",
            "|    total_timesteps      | 44928       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008331915 |\n",
            "|    clip_fraction        | 0.0634      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.7       |\n",
            "|    explained_variance   | -0.0672     |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 6.04        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 12.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.51e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 703          |\n",
            "|    total_timesteps      | 46592        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009613579 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.7        |\n",
            "|    explained_variance   | 0.0421       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 52.9         |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 107          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 16\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 533779.35\n",
            "total_reward: 433779.35\n",
            "total_cost: 112905.18\n",
            "total_trades: 20249\n",
            "Sharpe: 0.755\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.48e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 727         |\n",
            "|    total_timesteps      | 48256       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003923295 |\n",
            "|    clip_fraction        | 0.00116     |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.7       |\n",
            "|    explained_variance   | 0.0664      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 8.45        |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00499    |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 18.2        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.94e+03   |\n",
            "|    ep_rew_mean          | -6.48e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 66         |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 752        |\n",
            "|    total_timesteps      | 49920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00402782 |\n",
            "|    clip_fraction        | 0.00294    |\n",
            "|    clip_range           | 0.243      |\n",
            "|    entropy_loss         | -11.8      |\n",
            "|    explained_variance   | 0.0535     |\n",
            "|    learning_rate        | 0.000105   |\n",
            "|    loss                 | 32.9       |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.00456   |\n",
            "|    std                  | 1.05       |\n",
            "|    value_loss           | 61.8       |\n",
            "----------------------------------------\n",
            "day: 2940, episode: 17\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1021514.03\n",
            "total_reward: 921514.03\n",
            "total_cost: 112630.24\n",
            "total_trades: 20216\n",
            "Sharpe: 0.980\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.45e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 776          |\n",
            "|    total_timesteps      | 51584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005081296 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.125        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 19.3         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.000888    |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 43.5         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 18\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 589640.46\n",
            "total_reward: 489640.46\n",
            "total_cost: 111835.58\n",
            "total_trades: 20143\n",
            "Sharpe: 0.812\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.43e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 801          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007879911 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.0418       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 10.7         |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 27.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.43e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 825          |\n",
            "|    total_timesteps      | 54912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004957947 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.0882       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 32.1         |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00172     |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 66.3         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 19\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1019710.53\n",
            "total_reward: 919710.53\n",
            "total_cost: 104543.02\n",
            "total_trades: 19798\n",
            "Sharpe: 0.875\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.38e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 849         |\n",
            "|    total_timesteps      | 56576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002834181 |\n",
            "|    clip_fraction        | 0.000352    |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | -0.0541     |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 4.67        |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.00297    |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.38e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 874         |\n",
            "|    total_timesteps      | 58240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003111181 |\n",
            "|    clip_fraction        | 0.000149    |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.0971      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 24.1        |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.00362    |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 51.2        |\n",
            "-----------------------------------------\n",
            "day: 2940, episode: 20\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1386997.88\n",
            "total_reward: 1286997.88\n",
            "total_cost: 106301.38\n",
            "total_trades: 20097\n",
            "Sharpe: 1.014\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.34e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 898         |\n",
            "|    total_timesteps      | 59904       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012214008 |\n",
            "|    clip_fraction        | 0.0323      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.0906      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 5.39        |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.00745    |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 11.7        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.94e+03   |\n",
            "|    ep_rew_mean          | -6.34e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 66         |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 923        |\n",
            "|    total_timesteps      | 61568      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00531216 |\n",
            "|    clip_fraction        | 0.00339    |\n",
            "|    clip_range           | 0.243      |\n",
            "|    entropy_loss         | -11.8      |\n",
            "|    explained_variance   | 0.125      |\n",
            "|    learning_rate        | 0.000105   |\n",
            "|    loss                 | 27.8       |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.00504   |\n",
            "|    std                  | 1.06       |\n",
            "|    value_loss           | 54.9       |\n",
            "----------------------------------------\n",
            "day: 2940, episode: 21\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1503009.09\n",
            "total_reward: 1403009.09\n",
            "total_cost: 93064.47\n",
            "total_trades: 19565\n",
            "Sharpe: 0.943\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.28e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 947          |\n",
            "|    total_timesteps      | 63232        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013699089 |\n",
            "|    clip_fraction        | 0.000104     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.25         |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 6.19         |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00163     |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 14.2         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 22\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 973330.50\n",
            "total_reward: 873330.50\n",
            "total_cost: 106610.03\n",
            "total_trades: 19850\n",
            "Sharpe: 0.880\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.24e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 66            |\n",
            "|    iterations           | 39            |\n",
            "|    time_elapsed         | 972           |\n",
            "|    total_timesteps      | 64896         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00094813184 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.9         |\n",
            "|    explained_variance   | 0.13          |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 13.1          |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | -0.00195      |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 28.7          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.24e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 996          |\n",
            "|    total_timesteps      | 66560        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007227364 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.158        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 20.1         |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 46           |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 23\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1246943.01\n",
            "total_reward: 1146943.01\n",
            "total_cost: 95303.00\n",
            "total_trades: 19606\n",
            "Sharpe: 0.957\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.19e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 1020         |\n",
            "|    total_timesteps      | 68224        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022763002 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | -0.113       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 5.45         |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 12.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.19e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 1045         |\n",
            "|    total_timesteps      | 69888        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012889606 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.162        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 19.2         |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 40.6         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 24\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1172890.79\n",
            "total_reward: 1072890.79\n",
            "total_cost: 100168.83\n",
            "total_trades: 19758\n",
            "Sharpe: 0.958\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.16e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 1069        |\n",
            "|    total_timesteps      | 71552       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008368599 |\n",
            "|    clip_fraction        | 0.0604      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.0546      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 3.88        |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.0121     |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 8.03        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.16e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 1094        |\n",
            "|    total_timesteps      | 73216       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005516864 |\n",
            "|    clip_fraction        | 0.00634     |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.211       |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 22.1        |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.0057     |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 45.1        |\n",
            "-----------------------------------------\n",
            "day: 2940, episode: 25\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 863863.50\n",
            "total_reward: 763863.50\n",
            "total_cost: 110747.03\n",
            "total_trades: 19929\n",
            "Sharpe: 0.855\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.13e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 66            |\n",
            "|    iterations           | 45            |\n",
            "|    time_elapsed         | 1118          |\n",
            "|    total_timesteps      | 74880         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00091871194 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.9         |\n",
            "|    explained_variance   | 0.308         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 9             |\n",
            "|    n_updates            | 440           |\n",
            "|    policy_gradient_loss | -0.0015       |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 18.4          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 26\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 647203.80\n",
            "total_reward: 547203.80\n",
            "total_cost: 106185.41\n",
            "total_trades: 19739\n",
            "Sharpe: 0.736\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.1e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 1143         |\n",
            "|    total_timesteps      | 76544        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012932502 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 17.6         |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00299     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 41.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.1e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 67          |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 1166        |\n",
            "|    total_timesteps      | 78208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001110583 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -12         |\n",
            "|    explained_variance   | 0.266       |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 17.3        |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.00243    |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 36.3        |\n",
            "-----------------------------------------\n",
            "day: 2940, episode: 27\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 421944.21\n",
            "total_reward: 321944.21\n",
            "total_cost: 101277.78\n",
            "total_trades: 19514\n",
            "Sharpe: 0.663\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.08e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 1191         |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009184624 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | -0.215       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 5.29         |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00221     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 12.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.08e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 1215         |\n",
            "|    total_timesteps      | 81536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005104587 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.193        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 21.9         |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 46.2         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 28\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 283825.17\n",
            "total_reward: 183825.17\n",
            "total_cost: 95669.92\n",
            "total_trades: 19241\n",
            "Sharpe: 0.490\n",
            "=================================\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.94e+03   |\n",
            "|    ep_rew_mean          | -6.04e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 67         |\n",
            "|    iterations           | 50         |\n",
            "|    time_elapsed         | 1240       |\n",
            "|    total_timesteps      | 83200      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00921503 |\n",
            "|    clip_fraction        | 0.0159     |\n",
            "|    clip_range           | 0.243      |\n",
            "|    entropy_loss         | -12        |\n",
            "|    explained_variance   | 0.004      |\n",
            "|    learning_rate        | 0.000105   |\n",
            "|    loss                 | 2.58       |\n",
            "|    n_updates            | 490        |\n",
            "|    policy_gradient_loss | -0.00607   |\n",
            "|    std                  | 1.08       |\n",
            "|    value_loss           | 6.54       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.04e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 1264         |\n",
            "|    total_timesteps      | 84864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016182092 |\n",
            "|    clip_fraction        | 0.000198     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.265        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 16.9         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00275     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 36           |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 29\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 433412.23\n",
            "total_reward: 333412.23\n",
            "total_cost: 103647.36\n",
            "total_trades: 19677\n",
            "Sharpe: 0.636\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.02e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 1288         |\n",
            "|    total_timesteps      | 86528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004939457 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.352        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 4.84         |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 11.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.02e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 1313         |\n",
            "|    total_timesteps      | 88192        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015311093 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.274        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 16.9         |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 36.4         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 30\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 514124.49\n",
            "total_reward: 414124.49\n",
            "total_cost: 113538.74\n",
            "total_trades: 20027\n",
            "Sharpe: 0.750\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.01e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 67            |\n",
            "|    iterations           | 54            |\n",
            "|    time_elapsed         | 1337          |\n",
            "|    total_timesteps      | 89856         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00027126863 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -12           |\n",
            "|    explained_variance   | 0.379         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 20.5          |\n",
            "|    n_updates            | 530           |\n",
            "|    policy_gradient_loss | -0.000508     |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 43.3          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 31\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 431593.85\n",
            "total_reward: 331593.85\n",
            "total_cost: 111567.80\n",
            "total_trades: 20070\n",
            "Sharpe: 0.668\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.01e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 1362         |\n",
            "|    total_timesteps      | 91520        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019386854 |\n",
            "|    clip_fraction        | 4.96e-05     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | -0.0149      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 9.57         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00391     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 17.8         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.01e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 67            |\n",
            "|    iterations           | 56            |\n",
            "|    time_elapsed         | 1386          |\n",
            "|    total_timesteps      | 93184         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030760924 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -12           |\n",
            "|    explained_variance   | 0.23          |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 28            |\n",
            "|    n_updates            | 550           |\n",
            "|    policy_gradient_loss | -0.00014      |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 55.9          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 32\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 717541.57\n",
            "total_reward: 617541.57\n",
            "total_cost: 114125.27\n",
            "total_trades: 19955\n",
            "Sharpe: 0.856\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6e+03       |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 1410         |\n",
            "|    total_timesteps      | 94848        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0146389445 |\n",
            "|    clip_fraction        | 0.0447       |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | -0.0576      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 4.12         |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.0105      |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 8.64         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6e+03       |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 1435         |\n",
            "|    total_timesteps      | 96512        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005505512 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.248        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 25.2         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 55.5         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 33\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 622118.80\n",
            "total_reward: 522118.80\n",
            "total_cost: 104586.09\n",
            "total_trades: 19705\n",
            "Sharpe: 0.800\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.98e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 1459         |\n",
            "|    total_timesteps      | 98176        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016061607 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.297        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 3.53         |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 8.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.98e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 1484         |\n",
            "|    total_timesteps      | 99840        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030338727 |\n",
            "|    clip_fraction        | 0.000918     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.304        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 17.6         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00375     |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 38.5         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 34\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 282209.64\n",
            "total_reward: 182209.64\n",
            "total_cost: 107794.69\n",
            "total_trades: 19808\n",
            "Sharpe: 0.508\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.98e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 1508         |\n",
            "|    total_timesteps      | 101504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006911902 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.43         |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 14           |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 28.3         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-16 05:00:51,619] Trial 0 finished with value: -273.149111 and parameters: {'learning_rate': 0.00010549002305172715, 'gamma': 0.8046311802225579, 'n_steps': 1664, 'batch_size': 672, 'n_epochs': 10, 'ent_coef': 0.0450140438981059, 'clip_range': 0.24319251611478007, 'treynor_rate_learn': 0.4013949773199673, 'drawdown_component_learn': 2.9068009015669793, 'cost_component_learn': 4.994821708372366, 'risk_component_learn': 2.947383762136368, 'return_component_learn': 4.862429692924584}. Best is trial 0 with value: -273.149111.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day: 2940, episode: 36\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 818991.90\n",
            "total_reward: 718991.90\n",
            "total_cost: 5628.03\n",
            "total_trades: 10795\n",
            "Sharpe: 0.938\n",
            "=================================\n",
            "Treynor: 1.889150297004358\n",
            "Drawdown: 1.769847556231132\n",
            "Cost: 4.012148939695053\n",
            "Risk: 2.0055043101138925\n",
            "Return: 5.617623012947028\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2025-04-16 05:00:58,455] Trial 1 failed with parameters: {'learning_rate': 3.023245926210957e-05, 'gamma': 0.8994929407434951, 'n_steps': 1280, 'batch_size': 672, 'n_epochs': 12, 'ent_coef': 0.06455004558009568, 'clip_range': 0.12065109399156487, 'treynor_rate_learn': 1.889150297004358, 'drawdown_component_learn': 1.769847556231132, 'cost_component_learn': 4.012148939695053, 'risk_component_learn': 2.0055043101138925, 'return_component_learn': 5.617623012947028} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-14-a737f0375116>\", line 57, in optimize_agent\n",
            "    model.learn(total_timesteps=100_000)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\", line 311, in learn\n",
            "    return super().learn(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 324, in learn\n",
            "    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 218, in collect_rollouts\n",
            "    new_obs, rewards, dones, infos = env.step(clipped_actions)\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\", line 222, in step\n",
            "    return self.step_wait()\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 59, in step_wait\n",
            "    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n",
            "                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\", line 94, in step\n",
            "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
            "                                                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\", line 94, in step\n",
            "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
            "                                                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-12-7e2139a180be>\", line 439, in step\n",
            "    self.state = self._update_state()\n",
            "                 ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-12-7e2139a180be>\", line 558, in _update_state\n",
            "    self.data = self._get_multi_stock_data()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-12-7e2139a180be>\", line 586, in _get_multi_stock_data\n",
            "    _tickers = len(self.df.tic.unique())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\", line 2407, in unique\n",
            "    return super().unique()\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\", line 1025, in unique\n",
            "    result = algorithms.unique1d(values)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\", line 401, in unique\n",
            "    return unique_with_mask(values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\", line 440, in unique_with_mask\n",
            "    uniques = table.unique(values)\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-04-16 05:00:58,467] Trial 1 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a737f0375116>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Run Optuna optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Print best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-a737f0375116>\u001b[0m in \u001b[0;36moptimize_agent\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7e2139a180be>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mturbulence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrisk_indicator_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             end_total_asset = self.state[0] + sum(\n",
            "\u001b[0;32m<ipython-input-12-7e2139a180be>\u001b[0m in \u001b[0;36m_update_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_multi_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;31m# for multiple stock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             state = (\n",
            "\u001b[0;32m<ipython-input-12-7e2139a180be>\u001b[0m in \u001b[0;36m_get_multi_stock_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;31m############################## Custom Method to parse data for multi stock data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_multi_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0m_tickers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         return self.df.loc[ [i for i in range(\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_tickers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_tickers\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_tickers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2405\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m         \"\"\"\n\u001b[0;32m-> 2407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \"\"\"\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique_with_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N3e1W4MRRWXx",
        "outputId": "17d3ee51-011c-4c29-ab5c-c27e583e846c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-15 16:15:20,515] A new study created in memory with name: no-name-a2045131-3592-449e-adbe-da25240b4ea4\n",
            "[W 2025-04-15 16:15:20,563] Trial 0 failed with parameters: {'learning_rate': 0.00013556257844653342, 'gamma': 0.9843227854401423, 'n_steps': 1664, 'batch_size': 288, 'n_epochs': 11, 'ent_coef': 0.08674719396507213, 'clip_range': 0.37852411940807307, 'treynor_weight': 1.5569013467256325, 'log_return_weight': 2.1486476132903176, 'cost_penalty_weight': 0.3630822891850808, 'sortino_weight': 2.988339422974664, 'info_ratio_weight': 1.765931582941819} because of the following error: AttributeError(\"'StockTradingEnv' object has no attribute '_calculate_daily_returns_and_benchmark'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-10-72a9a0780ade>\", line 58, in optimize_agent\n",
            "    model.learn(total_timesteps=100_000)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\", line 311, in learn\n",
            "    return super().learn(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 324, in learn\n",
            "    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 218, in collect_rollouts\n",
            "    new_obs, rewards, dones, infos = env.step(clipped_actions)\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\", line 222, in step\n",
            "    return self.step_wait()\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 59, in step_wait\n",
            "    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n",
            "                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\", line 94, in step\n",
            "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
            "                                                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\", line 94, in step\n",
            "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
            "                                                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-5-2c25da811fa5>\", line 453, in step\n",
            "    self.reward = self.calculate_reward()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-5-2c25da811fa5>\", line 259, in calculate_reward\n",
            "    df_a = self._calculate_daily_returns_and_benchmark()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'StockTradingEnv' object has no attribute '_calculate_daily_returns_and_benchmark'\n",
            "[W 2025-04-15 16:15:20,566] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treynor: 1.5569013467256325\n",
            "log: 2.1486476132903176\n",
            "Cost: 0.3630822891850808\n",
            "sortino: 2.988339422974664\n",
            "info: 1.765931582941819\n",
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'StockTradingEnv' object has no attribute '_calculate_daily_returns_and_benchmark'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-72a9a0780ade>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Run Optuna optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Print best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-72a9a0780ade>\u001b[0m in \u001b[0;36moptimize_agent\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2c25da811fa5>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2c25da811fa5>\u001b[0m in \u001b[0;36mcalculate_reward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# --- Advanced Metrics (calculated only if weights > 0 and enough data) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreynor_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-9\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortino_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-9\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_ratio_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mdf_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_daily_returns_and_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdf_a\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'StockTradingEnv' object has no attribute '_calculate_daily_returns_and_benchmark'"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import gym\n",
        "import warnings\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize the environment\n",
        "#env = StockTradingEnv()  # Ensure this is correctly defined\n",
        "vec_env = make_vec_env(lambda: Monitor(env, '/'), n_envs=1)  # Wrap in VecEnv\n",
        "\n",
        "def optimize_agent(trial):\n",
        "    \"\"\"Objective function for Optuna to optimize PPO hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the hyperparameter search space\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.8, 0.999)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 128, 2048, step=128)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 32, 1024, step=64)\n",
        "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 20)\n",
        "    ent_coef = trial.suggest_float(\"ent_coef\", 0.0, 0.1)\n",
        "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.4)\n",
        "    w_treynor = trial.suggest_float(\"treynor_rate_learn\", 0.1, 5.0)  # More profit weight\n",
        "    w_drawdown = trial.suggest_float(\"drawdown_component_learn\", 0.1, 5.0)  # Risk penalty weight\n",
        "    #w_diverse = trial.suggest_float(\"diversification_component_learn\", 0.1, 5.0)  # Risk penalty weight\n",
        "    w_cost = trial.suggest_float(\"cost_component_learn\", 0.1, 5.0)\n",
        "    w_risk = trial.suggest_float(\"risk_component_learn\", 0.1, 6.0)\n",
        "    w_return = trial.suggest_float(\"return_component_learn\", 0.1, 7.0)\n",
        "    \"\"\"treynor_rate_learn = 0.2\n",
        "drawdown_component_learn = 0.1\n",
        "diversification_component_learn = 0.1\n",
        "cost_component_learn = 0.1\n",
        "risk_component_learn = 0.2\n",
        "return_component_learn = 0.5\"\"\"\n",
        "    print(f\"Treynor: {self.treynor_rate_learn}\")\n",
        "    print(f\"Drawdown: {self.drawdown_component_learn}\")\n",
        "    #print(f\"Diversification: {self.diversification_component_learn}\")\n",
        "    print(f\"Cost: {self.cost_component_learn}\")\n",
        "    print(f\"Risk: {self.risk_component_learn}\")\n",
        "    print(f\"Return: {self.return_component_learn}\")\n",
        "\n",
        "    # Ensure batch_size does not exceed n_steps\n",
        "\n",
        "    if batch_size > n_steps:\n",
        "        return float(\"-inf\")\n",
        "\n",
        "    # Initialize the PPO model with suggested hyperparameters\n",
        "    env.set_reward_weights(w_treynor, w_drawdown, w_cost, w_risk, w_return)\n",
        "    model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "\n",
        "    # Train the model\n",
        "    model.learn(total_timesteps=100_000)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mean_reward, _ = evaluate_policy(model, vec_env, n_eval_episodes=10)\n",
        "\n",
        "    return mean_reward  # Optuna will maximize this reward\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(optimize_agent, n_trials=15)\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "\n",
        "# Apply reward weights\n",
        "env.set_reward_weights(\n",
        "    best_params['treynor_rate_learn'],\n",
        "    best_params['drawdown_component_learn'],\n",
        "    best_params['cost_component_learn'],\n",
        "    best_params['risk_component_learn'],\n",
        "    best_params['return_component_learn']\n",
        ")\n",
        "\n",
        "# Filter out only PPO-relevant keys\n",
        "ppo_keys = ['learning_rate', 'gamma', 'n_steps', 'batch_size', 'n_epochs', 'ent_coef', 'clip_range']\n",
        "ppo_params = {k: best_params[k] for k in ppo_keys}\n",
        "\n",
        "# Rebuild and retrain the best model\n",
        "best_model = PPO(\"MlpPolicy\", vec_env, **ppo_params, verbose=1)\n",
        "best_model.learn(total_timesteps=100_000)\n",
        "\n",
        "# Save it\n",
        "best_model.save(\"best_optuna_ppo_model\")\n"
      ],
      "metadata": {
        "id": "WHrNb3Fke3ql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4634b130-8e64-4cd0-a3d5-26df75c60000"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 71   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 23   |\n",
            "|    total_timesteps | 1664 |\n",
            "-----------------------------\n",
            "day: 2940, episode: 39\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 385739.83\n",
            "total_reward: 285739.83\n",
            "total_cost: 125026.99\n",
            "total_trades: 20548\n",
            "Sharpe: 0.688\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.91e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 48          |\n",
            "|    total_timesteps      | 3328        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004968228 |\n",
            "|    clip_fraction        | 0.00427     |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | -0.0774     |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 10.8        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00664    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 25          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.91e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 4992        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001258616 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | -0.00823    |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 105         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00204    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 214         |\n",
            "-----------------------------------------\n",
            "day: 2940, episode: 40\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 159894.96\n",
            "total_reward: 59894.96\n",
            "total_cost: 102404.28\n",
            "total_trades: 20056\n",
            "Sharpe: 0.297\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.51e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 6656         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013625793 |\n",
            "|    clip_fraction        | 0.000154     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.0786      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 13.8         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 35.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.51e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 121          |\n",
            "|    total_timesteps      | 8320         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019852621 |\n",
            "|    clip_fraction        | 4.96e-05     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.0272      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 59.6         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00252     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 122          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 41\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 254830.59\n",
            "total_reward: 154830.59\n",
            "total_cost: 103456.10\n",
            "total_trades: 19930\n",
            "Sharpe: 0.483\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.24e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 145          |\n",
            "|    total_timesteps      | 9984         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027100176 |\n",
            "|    clip_fraction        | 0.000203     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | 0.029        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 23.6         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0034      |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 47.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.24e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 11648        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062224455 |\n",
            "|    clip_fraction        | 0.00777      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.0335      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 31.6         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00533     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 73.3         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 42\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 341008.54\n",
            "total_reward: 241008.54\n",
            "total_cost: 115677.66\n",
            "total_trades: 20175\n",
            "Sharpe: 0.639\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.29e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 194          |\n",
            "|    total_timesteps      | 13312        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012367951 |\n",
            "|    clip_fraction        | 0.000104     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | 0.00476      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 54.2         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00235     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 116          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 43\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 157822.28\n",
            "total_reward: 57822.28\n",
            "total_cost: 101347.58\n",
            "total_trades: 19583\n",
            "Sharpe: 0.296\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.25e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 219          |\n",
            "|    total_timesteps      | 14976        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0096131265 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | -0.0367      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 15.3         |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00865     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 33           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.25e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 243          |\n",
            "|    total_timesteps      | 16640        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025258013 |\n",
            "|    clip_fraction        | 0.000308     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.019       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 49.7         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 103          |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 44\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 426071.67\n",
            "total_reward: 326071.67\n",
            "total_cost: 122793.38\n",
            "total_trades: 20116\n",
            "Sharpe: 0.739\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.3e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 268          |\n",
            "|    total_timesteps      | 18304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0111277355 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.181       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 5.12         |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00833     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.3e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 292           |\n",
            "|    total_timesteps      | 19968         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00070976955 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.5         |\n",
            "|    explained_variance   | -0.0307       |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 55.7          |\n",
            "|    n_updates            | 110           |\n",
            "|    policy_gradient_loss | -0.00147      |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 117           |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 45\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 239210.19\n",
            "total_reward: 139210.19\n",
            "total_cost: 115616.84\n",
            "total_trades: 19645\n",
            "Sharpe: 0.497\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.32e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 316          |\n",
            "|    total_timesteps      | 21632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015376614 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.0282      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 12.6         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00273     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 26.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.32e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 341          |\n",
            "|    total_timesteps      | 23296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068977945 |\n",
            "|    clip_fraction        | 0.00799      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | -0.0304      |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 38.2         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00754     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 86.2         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 46\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 267103.24\n",
            "total_reward: 167103.24\n",
            "total_cost: 106996.70\n",
            "total_trades: 19514\n",
            "Sharpe: 0.514\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.28e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 365          |\n",
            "|    total_timesteps      | 24960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012852215 |\n",
            "|    clip_fraction        | 0.000104     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.5        |\n",
            "|    explained_variance   | 0.0214       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 20           |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00198     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 42.7         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 47\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 599855.15\n",
            "total_reward: 499855.15\n",
            "total_cost: 118839.56\n",
            "total_trades: 19861\n",
            "Sharpe: 0.839\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.29e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 390         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008054958 |\n",
            "|    clip_fraction        | 0.0216      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | -0.038      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 18.8        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00986    |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 38.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.29e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 413          |\n",
            "|    total_timesteps      | 28288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014432456 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | 0.0204       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 46           |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 95           |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 48\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 260658.99\n",
            "total_reward: 160658.99\n",
            "total_cost: 108578.31\n",
            "total_trades: 19376\n",
            "Sharpe: 0.506\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.23e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 438         |\n",
            "|    total_timesteps      | 29952       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012070794 |\n",
            "|    clip_fraction        | 0.0301      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | -0.289      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 4.08        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0097     |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 9.6         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.23e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 462          |\n",
            "|    total_timesteps      | 31616        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016913969 |\n",
            "|    clip_fraction        | 4.96e-05     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | 0.0124       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 34.3         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 74.1         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 49\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 380264.36\n",
            "total_reward: 280264.36\n",
            "total_cost: 102535.69\n",
            "total_trades: 19037\n",
            "Sharpe: 0.683\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.2e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 486         |\n",
            "|    total_timesteps      | 33280       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008799837 |\n",
            "|    clip_fraction        | 0.0142      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | -0.0878     |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 5.33        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0058     |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 12.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.2e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 511          |\n",
            "|    total_timesteps      | 34944        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046344493 |\n",
            "|    clip_fraction        | 0.00232      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | 0.0226       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 33.9         |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00494     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 66.1         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 50\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 345440.98\n",
            "total_reward: 245440.98\n",
            "total_cost: 115000.24\n",
            "total_trades: 18811\n",
            "Sharpe: 0.674\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.18e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 535          |\n",
            "|    total_timesteps      | 36608        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015498617 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.6        |\n",
            "|    explained_variance   | 0.0838       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 13.2         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 28.2         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 51\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 351799.76\n",
            "total_reward: 251799.76\n",
            "total_cost: 109602.59\n",
            "total_trades: 19104\n",
            "Sharpe: 0.663\n",
            "=================================\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.94e+03   |\n",
            "|    ep_rew_mean          | -6.17e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 68         |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 560        |\n",
            "|    total_timesteps      | 38272      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00855934 |\n",
            "|    clip_fraction        | 0.0141     |\n",
            "|    clip_range           | 0.243      |\n",
            "|    entropy_loss         | -11.7      |\n",
            "|    explained_variance   | 0.0254     |\n",
            "|    learning_rate        | 0.000105   |\n",
            "|    loss                 | 28.5       |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | -0.00642   |\n",
            "|    std                  | 1.04       |\n",
            "|    value_loss           | 56.8       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.17e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 584          |\n",
            "|    total_timesteps      | 39936        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009223853 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.7        |\n",
            "|    explained_variance   | 0.096        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 34.1         |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 67.8         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 52\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 502551.47\n",
            "total_reward: 402551.47\n",
            "total_cost: 102163.43\n",
            "total_trades: 18422\n",
            "Sharpe: 0.802\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.11e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 609         |\n",
            "|    total_timesteps      | 41600       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001102935 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.7       |\n",
            "|    explained_variance   | -0.241      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 7.35        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00181    |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 16          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.11e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 633          |\n",
            "|    total_timesteps      | 43264        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013550002 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.7        |\n",
            "|    explained_variance   | 0.0551       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 25           |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 57.5         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 53\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 448634.84\n",
            "total_reward: 348634.84\n",
            "total_cost: 109086.34\n",
            "total_trades: 19004\n",
            "Sharpe: 0.777\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -6.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 657         |\n",
            "|    total_timesteps      | 44928       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008423292 |\n",
            "|    clip_fraction        | 0.075       |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.7       |\n",
            "|    explained_variance   | -0.125      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 5.79        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.12e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 682          |\n",
            "|    total_timesteps      | 46592        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013147825 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.0532       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 35           |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00261     |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 74.2         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 54\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 622533.91\n",
            "total_reward: 522533.91\n",
            "total_cost: 124773.76\n",
            "total_trades: 19208\n",
            "Sharpe: 0.956\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.12e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 706          |\n",
            "|    total_timesteps      | 48256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017236214 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.106        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 9.21         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00299     |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 20.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -6.12e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 731          |\n",
            "|    total_timesteps      | 49920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028575985 |\n",
            "|    clip_fraction        | 0.000506     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.0604       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 33.7         |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 72.7         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 55\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 482027.62\n",
            "total_reward: 382027.62\n",
            "total_cost: 108424.99\n",
            "total_trades: 18978\n",
            "Sharpe: 0.818\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.1e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 31            |\n",
            "|    time_elapsed         | 754           |\n",
            "|    total_timesteps      | 51584         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00047048368 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.8         |\n",
            "|    explained_variance   | 0.159         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 19.3          |\n",
            "|    n_updates            | 300           |\n",
            "|    policy_gradient_loss | -0.00109      |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 41.5          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 56\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 583615.52\n",
            "total_reward: 483615.52\n",
            "total_cost: 104598.43\n",
            "total_trades: 18734\n",
            "Sharpe: 0.866\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.07e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 32            |\n",
            "|    time_elapsed         | 779           |\n",
            "|    total_timesteps      | 53248         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021362123 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.8         |\n",
            "|    explained_variance   | 0.013         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 12.6          |\n",
            "|    n_updates            | 310           |\n",
            "|    policy_gradient_loss | -0.00105      |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 28.8          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.07e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 33            |\n",
            "|    time_elapsed         | 803           |\n",
            "|    total_timesteps      | 54912         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00034453793 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.8         |\n",
            "|    explained_variance   | 0.0832        |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 26.9          |\n",
            "|    n_updates            | 320           |\n",
            "|    policy_gradient_loss | -0.00102      |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 54.8          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 57\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 515446.82\n",
            "total_reward: 415446.82\n",
            "total_cost: 93340.50\n",
            "total_trades: 18364\n",
            "Sharpe: 0.801\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -6.02e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 34            |\n",
            "|    time_elapsed         | 828           |\n",
            "|    total_timesteps      | 56576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00042954774 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.8         |\n",
            "|    explained_variance   | -0.256        |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 5.23          |\n",
            "|    n_updates            | 330           |\n",
            "|    policy_gradient_loss | -0.00141      |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 12.3          |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.94e+03   |\n",
            "|    ep_rew_mean          | -6.02e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 68         |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 852        |\n",
            "|    total_timesteps      | 58240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00304679 |\n",
            "|    clip_fraction        | 0.000556   |\n",
            "|    clip_range           | 0.243      |\n",
            "|    entropy_loss         | -11.8      |\n",
            "|    explained_variance   | 0.098      |\n",
            "|    learning_rate        | 0.000105   |\n",
            "|    loss                 | 21.3       |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | -0.00397   |\n",
            "|    std                  | 1.06       |\n",
            "|    value_loss           | 44.2       |\n",
            "----------------------------------------\n",
            "day: 2940, episode: 58\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 333681.97\n",
            "total_reward: 233681.97\n",
            "total_cost: 102392.70\n",
            "total_trades: 18904\n",
            "Sharpe: 0.613\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -5.99e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 876         |\n",
            "|    total_timesteps      | 59904       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012036931 |\n",
            "|    clip_fraction        | 0.0366      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.0947      |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 5.92        |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.00853    |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 12.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -5.99e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 901         |\n",
            "|    total_timesteps      | 61568       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005430747 |\n",
            "|    clip_fraction        | 0.00353     |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.128       |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 27.6        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00639    |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 54.2        |\n",
            "-----------------------------------------\n",
            "day: 2940, episode: 59\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 625349.86\n",
            "total_reward: 525349.86\n",
            "total_cost: 89763.47\n",
            "total_trades: 18360\n",
            "Sharpe: 0.884\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.93e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 925          |\n",
            "|    total_timesteps      | 63232        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012159484 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | 0.29         |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 5.42         |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 14.3         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 60\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 541847.51\n",
            "total_reward: 441847.51\n",
            "total_cost: 99637.74\n",
            "total_trades: 18850\n",
            "Sharpe: 0.815\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -5.89e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 39            |\n",
            "|    time_elapsed         | 950           |\n",
            "|    total_timesteps      | 64896         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00080125843 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.9         |\n",
            "|    explained_variance   | 0.129         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 13.3          |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | -0.00191      |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 30.3          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.89e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 974          |\n",
            "|    total_timesteps      | 66560        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006348893 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.183        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 17.9         |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00164     |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 37.6         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 61\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 588058.60\n",
            "total_reward: 488058.60\n",
            "total_cost: 100009.42\n",
            "total_trades: 18773\n",
            "Sharpe: 0.894\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.86e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 998          |\n",
            "|    total_timesteps      | 68224        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010280058 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | -0.409       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 5.03         |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 12.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -5.86e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 1023        |\n",
            "|    total_timesteps      | 69888       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001234586 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.151       |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 21.8        |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00266    |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 45.6        |\n",
            "-----------------------------------------\n",
            "day: 2940, episode: 62\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 540071.49\n",
            "total_reward: 440071.49\n",
            "total_cost: 95921.43\n",
            "total_trades: 18610\n",
            "Sharpe: 0.834\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -5.83e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 1047        |\n",
            "|    total_timesteps      | 71552       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008274309 |\n",
            "|    clip_fraction        | 0.0697      |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | -0.000105   |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 3.29        |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 7.84        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.83e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 1073         |\n",
            "|    total_timesteps      | 73216        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020024471 |\n",
            "|    clip_fraction        | 0.000303     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.207        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 21.7         |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 44.8         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 63\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 626335.51\n",
            "total_reward: 526335.51\n",
            "total_cost: 103106.40\n",
            "total_trades: 18749\n",
            "Sharpe: 0.892\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -5.81e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 45            |\n",
            "|    time_elapsed         | 1097          |\n",
            "|    total_timesteps      | 74880         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032863964 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.9         |\n",
            "|    explained_variance   | 0.343         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 5.98          |\n",
            "|    n_updates            | 440           |\n",
            "|    policy_gradient_loss | -0.000674     |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 15.3          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 64\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 700641.35\n",
            "total_reward: 600641.35\n",
            "total_cost: 98828.03\n",
            "total_trades: 18954\n",
            "Sharpe: 0.952\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.78e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 1123         |\n",
            "|    total_timesteps      | 76544        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011866192 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 16.3         |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00283     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 36.1         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -5.78e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 47            |\n",
            "|    time_elapsed         | 1146          |\n",
            "|    total_timesteps      | 78208         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010991305 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -11.9         |\n",
            "|    explained_variance   | 0.314         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 13.1          |\n",
            "|    n_updates            | 460           |\n",
            "|    policy_gradient_loss | -9.57e-05     |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 31.1          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 65\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 347208.80\n",
            "total_reward: 247208.80\n",
            "total_cost: 103454.65\n",
            "total_trades: 19223\n",
            "Sharpe: 0.640\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.76e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 1172         |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011232569 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | -0.507       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 5.53         |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00265     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -5.76e+03     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 49            |\n",
            "|    time_elapsed         | 1196          |\n",
            "|    total_timesteps      | 81536         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00066936977 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -12           |\n",
            "|    explained_variance   | 0.179         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 23.7          |\n",
            "|    n_updates            | 480           |\n",
            "|    policy_gradient_loss | -0.00162      |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 49.8          |\n",
            "-------------------------------------------\n",
            "day: 2940, episode: 66\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 640051.07\n",
            "total_reward: 540051.07\n",
            "total_cost: 99723.81\n",
            "total_trades: 18858\n",
            "Sharpe: 0.892\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -5.73e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 1220        |\n",
            "|    total_timesteps      | 83200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003376523 |\n",
            "|    clip_fraction        | 0.000655    |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -12         |\n",
            "|    explained_variance   | -0.0663     |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 3.05        |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.00399    |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 7.59        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.73e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 1245         |\n",
            "|    total_timesteps      | 84864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025464164 |\n",
            "|    clip_fraction        | 0.000149     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.256        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 19.3         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.0034      |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 40.1         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 67\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 584610.25\n",
            "total_reward: 484610.25\n",
            "total_cost: 96404.86\n",
            "total_trades: 18683\n",
            "Sharpe: 0.862\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -5.7e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 1269        |\n",
            "|    total_timesteps      | 86528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001964477 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -12         |\n",
            "|    explained_variance   | 0.383       |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 3.96        |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.0033     |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 9.28        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.7e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 1294         |\n",
            "|    total_timesteps      | 88192        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013896461 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.285        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 16.5         |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.00223     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 34           |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 68\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 773172.36\n",
            "total_reward: 673172.36\n",
            "total_cost: 98919.62\n",
            "total_trades: 18909\n",
            "Sharpe: 0.975\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94e+03    |\n",
            "|    ep_rew_mean          | -5.68e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 68          |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 1318        |\n",
            "|    total_timesteps      | 89856       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000417227 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.243       |\n",
            "|    entropy_loss         | -12         |\n",
            "|    explained_variance   | 0.45        |\n",
            "|    learning_rate        | 0.000105    |\n",
            "|    loss                 | 16          |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.000898   |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 34.4        |\n",
            "-----------------------------------------\n",
            "day: 2940, episode: 69\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 679524.55\n",
            "total_reward: 579524.55\n",
            "total_cost: 97522.49\n",
            "total_trades: 18956\n",
            "Sharpe: 0.944\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.67e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 1343         |\n",
            "|    total_timesteps      | 91520        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004323792 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | -0.103       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 8.69         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 17.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.67e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 1367         |\n",
            "|    total_timesteps      | 93184        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002593441 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.238        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 22.5         |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.000985    |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 43.7         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 70\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 665360.68\n",
            "total_reward: 565360.68\n",
            "total_cost: 91674.49\n",
            "total_trades: 18500\n",
            "Sharpe: 0.913\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.64e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 1391         |\n",
            "|    total_timesteps      | 94848        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013826826 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | -0.307       |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 3.03         |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 7.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.64e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 1416         |\n",
            "|    total_timesteps      | 96512        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036345776 |\n",
            "|    clip_fraction        | 0.00153      |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.284        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 15.4         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00454     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 33.7         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 71\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 528638.39\n",
            "total_reward: 428638.39\n",
            "total_cost: 85172.81\n",
            "total_trades: 18420\n",
            "Sharpe: 0.809\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.61e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 1440         |\n",
            "|    total_timesteps      | 98176        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035769688 |\n",
            "|    clip_fraction        | 0.000967     |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.291        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 3.24         |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00339     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 7.82         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.94e+03     |\n",
            "|    ep_rew_mean          | -5.61e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 68           |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 1465         |\n",
            "|    total_timesteps      | 99840        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051661283 |\n",
            "|    clip_fraction        | 0.0043       |\n",
            "|    clip_range           | 0.243        |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.349        |\n",
            "|    learning_rate        | 0.000105     |\n",
            "|    loss                 | 13.9         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00586     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 28.4         |\n",
            "------------------------------------------\n",
            "day: 2940, episode: 72\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 899950.54\n",
            "total_reward: 799950.54\n",
            "total_cost: 98761.34\n",
            "total_trades: 18501\n",
            "Sharpe: 1.043\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 2.94e+03      |\n",
            "|    ep_rew_mean          | -5.6e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 61            |\n",
            "|    time_elapsed         | 1488          |\n",
            "|    total_timesteps      | 101504        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00078163255 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.243         |\n",
            "|    entropy_loss         | -12.1         |\n",
            "|    explained_variance   | 0.494         |\n",
            "|    learning_rate        | 0.000105      |\n",
            "|    loss                 | 10.9          |\n",
            "|    n_updates            | 600           |\n",
            "|    policy_gradient_loss | -0.000979     |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 22.6          |\n",
            "-------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiOstNgzenJk"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import gym\n",
        "import warnings\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "resume_training = True  # Set to True to resume training from 'resume.zip'\n",
        "\n",
        "# Initialize the environment\n",
        "#env = SingleStockTradingEnv()  # Ensure this is correctly defined\n",
        "\n",
        "vec_env = make_vec_env(lambda: Monitor(env, '/'), n_envs=1)  # Wrap in VecEnv\n",
        "\n",
        "def optimize_agent(trial):\n",
        "    \"\"\"Objective function for Optuna to optimize PPO hyperparameters with mini-batch training and resumption.\"\"\"\n",
        "\n",
        "    # Hyperparameter search space\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.8, 0.999)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 128, 2048, step=128)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 32, min(n_steps, 1024), step=32)\n",
        "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 20)\n",
        "    ent_coef = trial.suggest_float(\"ent_coef\", 0.0, 0.1)\n",
        "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.4)\n",
        "    w_treynor = trial.suggest_float(\"treynor_rate_learn\", 0.1, 0.5)\n",
        "    w_drawdown = trial.suggest_float(\"drawdown_component_learn\", 0.1, 0.5)\n",
        "    w_diverse = trial.suggest_float(\"diversification_component_learn\", 0.1, 0.5)\n",
        "    w_cost = trial.suggest_float(\"cost_component_learn\", 0.1, 0.5)\n",
        "    w_risk = trial.suggest_float(\"risk_component_learn\", 0.1, 0.6)\n",
        "    w_return = trial.suggest_float(\"return_component_learn\", 0.1, 0.7)\n",
        "\n",
        "    # Ensure batch_size does not exceed n_steps but it wont run the below if statement as batchsize is always <= n_steps\n",
        "    if batch_size > n_steps:\n",
        "        return float(\"-inf\")\n",
        "\n",
        "    # Load model if resuming training\n",
        "    env.set_reward_weights(w_treynor, w_drawdown, w_diverse, w_cost, w_risk, w_return)\n",
        "\n",
        "    if resume_training:\n",
        "        try:\n",
        "            model = PPO.load(\"resume\", env=vec_env, verbose=1)\n",
        "            print(\"Resuming training with previous model...\")\n",
        "        except:\n",
        "            model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                        n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                        ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "            print(\"Previous model not found. Starting new training...\")\n",
        "    else:\n",
        "        model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                    n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                    ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "        print(\"Starting new training...\")\n",
        "\n",
        "    # Train the model\n",
        "    model.learn(total_timesteps=100_000)\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(\"resume\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    mean_reward, _ = evaluate_policy(model, vec_env, n_eval_episodes=10)\n",
        "\n",
        "    return mean_reward  # Optuna maximizes this reward\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(optimize_agent, n_trials=10)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpC92qxUwME1"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import gym\n",
        "import warnings\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "resume_training = True  # Set to True to resume training from 'resume.zip'\n",
        "\n",
        "# Define the Optuna objective function\n",
        "def optimize_agent(trial):\n",
        "    \"\"\"Objective function for Optuna to optimize PPO hyperparameters with mini-batch training and resumption.\"\"\"\n",
        "\n",
        "    # Tune PPO hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 5e-3, log=True)  # Adjusted range\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.8, 0.999)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 128, 2048, step=128)\n",
        "    batch_size = min(trial.suggest_int(\"batch_size\", 32, 1024, step=32), n_steps)  # Ensure batch_size <= n_steps\n",
        "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 20)\n",
        "    ent_coef = trial.suggest_float(\"ent_coef\", 0.0, 0.1)\n",
        "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.4)\n",
        "\n",
        "    # Tune reward function weights (broader range)\n",
        "    w_treynor = trial.suggest_float(\"w_treynor\", 0.01, 5.0)\n",
        "    w_drawdown = trial.suggest_float(\"w_drawdown\", 0.01, 5.0)\n",
        "    w_diverse = trial.suggest_float(\"w_diverse\", 0.01, 5.0)\n",
        "    w_cost = trial.suggest_float(\"w_cost\", 0.01, 5.0)\n",
        "    w_risk = trial.suggest_float(\"w_risk\", 0.01, 5.0)\n",
        "    w_return = trial.suggest_float(\"w_return\", 0.01, 5.0)\n",
        "    env.reset()\n",
        "    env.set_reward_weights(w_treynor, w_drawdown, w_diverse, w_cost, w_risk, w_return)\n",
        "    vec_env = make_vec_env(lambda: Monitor(env, '/'), n_envs=1)\n",
        "\n",
        "    # Initialize environment (fresh instance per trial)\n",
        "    '''\n",
        "    print(f\"w_treynor: {w_treynor}\")\n",
        "    print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
        "    print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
        "    print(f\"total_reward: {tot_reward:0.2f}\")\n",
        "    print(f\"total_cost: {self.cost:0.2f}\")\n",
        "    print(f\"total_trades: {self.trades}\")\n",
        "    print(\"=================================\")\n",
        "    '''\n",
        "\n",
        "\n",
        "    # Load model if resuming training\n",
        "    if resume_training:\n",
        "        try:\n",
        "            model = PPO.load(\"resume\", env=vec_env, verbose=1)\n",
        "            print(\"Resuming training with previous model...\")\n",
        "        except:\n",
        "            model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                        n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                        ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "            print(\"Previous model not found. Starting new training...\")\n",
        "    else:\n",
        "        model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                    n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                    ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "        print(\"Starting new training...\")\n",
        "\n",
        "    # Train the model\n",
        "    model.learn(total_timesteps=100_000)\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(\"resume\")\n",
        "\n",
        "    # Evaluate the model with more episodes\n",
        "    mean_reward, _ = evaluate_policy(model, vec_env, n_eval_episodes=20)  # Increased from 10 to 20\n",
        "\n",
        "    return mean_reward  # Optuna maximizes this reward\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(optimize_agent, n_trials=10)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1d4zRybpgNU"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import warnings\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize the environment\n",
        "env = SingleStockTradingEnv()  # Ensure this is correctly defined\n",
        "vec_env = make_vec_env(lambda: Monitor(env, '/'), n_envs=1)  # Wrap in VecEnv\n",
        "\n",
        "# Define PPO hyperparameters for batch training\n",
        "learning_rate = 3e-4\n",
        "gamma = 0.99\n",
        "n_steps = 1024  # Collect 1024 steps before each update\n",
        "batch_size = 64  # Mini-batch size for updates\n",
        "n_epochs = 10  # Number of times each batch is used for training\n",
        "ent_coef = 0.01\n",
        "clip_range = 0.2\n",
        "\n",
        "# Load model if resuming training\n",
        "resume_training = True\n",
        "\n",
        "if resume_training:\n",
        "    try:\n",
        "        model = PPO.load(\"resume\", env=vec_env, verbose=1)\n",
        "        print(\"Resuming training with previous model...\")\n",
        "    except:\n",
        "        model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                    n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                    ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "        print(\"Previous model not found. Starting new training...\")\n",
        "else:\n",
        "    model = PPO(\"MlpPolicy\", vec_env, learning_rate=learning_rate, gamma=gamma,\n",
        "                n_steps=n_steps, batch_size=batch_size, n_epochs=n_epochs,\n",
        "                ent_coef=ent_coef, clip_range=clip_range, verbose=1)\n",
        "    print(\"Starting new training...\")\n",
        "\n",
        "# Train the model using mini-batch training\n",
        "model.learn(total_timesteps=100_000)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"resume\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install quantstats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oFxFZXn7EGy7",
        "outputId": "5f29c3e1-86d2-48df-f305-755130c21cee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting quantstats\n",
            "  Downloading QuantStats-0.0.64-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from quantstats) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from quantstats) (2.0.2)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from quantstats) (0.13.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from quantstats) (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from quantstats) (1.14.1)\n",
            "Requirement already satisfied: tabulate>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from quantstats) (0.9.0)\n",
            "Requirement already satisfied: yfinance>=0.1.70 in /usr/local/lib/python3.11/dist-packages (from quantstats) (0.2.55)\n",
            "Requirement already satisfied: python-dateutil>=2.0 in /usr/local/lib/python3.11/dist-packages (from quantstats) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->quantstats) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->quantstats) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->quantstats) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->quantstats) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->quantstats) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->quantstats) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->quantstats) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->quantstats) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->quantstats) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.0->quantstats) (1.17.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance>=0.1.70->quantstats) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance>=0.1.70->quantstats) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance>=0.1.70->quantstats) (4.3.7)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance>=0.1.70->quantstats) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance>=0.1.70->quantstats) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance>=0.1.70->quantstats) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance>=0.1.70->quantstats) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance>=0.1.70->quantstats) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance>=0.1.70->quantstats) (2025.1.31)\n",
            "Downloading QuantStats-0.0.64-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: quantstats\n",
            "Successfully installed quantstats-0.0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gymnasium as gym # Using Gymnasium based on your Env code\n",
        "from stable_baselines3 import PPO # Your training used PPO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# import argparse # No longer needed\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- Import Your Environment ---\n",
        "# Make sure the file containing StockTradingEnv is in your PYTHONPATH\n",
        "# or in the same directory as this script.\n",
        "# Example: Assume it's in the same directory or a sub-directory\n",
        "\n",
        "# --- Optional: Install quantstats ---\n",
        "# pip install quantstats\n",
        "try:\n",
        "    import quantstats\n",
        "    QUANTSTATS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    QUANTSTATS_AVAILABLE = False\n",
        "    print(\"Warning: quantstats not installed. Some metrics will be unavailable. Run: pip install quantstats\")\n",
        "\n",
        "# --- Backtesting Function (Unchanged) ---\n",
        "def run_backtest(\n",
        "    data_path: str,\n",
        "    model_path: str,\n",
        "    env_config: dict, # Dictionary with ALL required env init args derived from hardcoded vars\n",
        "    backtest_start_date: str,\n",
        "    backtest_end_date: str,\n",
        "    deterministic: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs a backtest for a trained RL agent using the provided StockTradingEnv.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the FULL historical data file (CSV, Parquet, etc.).\n",
        "        model_path (str): Path to the saved PPO model file (.zip).\n",
        "        env_config (dict): Dictionary of keyword arguments to pass to StockTradingEnv.__init__.\n",
        "                           Must include all necessary parameters derived from args.\n",
        "                           The 'df' key will be added/overwritten within this function.\n",
        "        backtest_start_date (str): Start date for the backtest period (e.g., \"YYYY-MM-DD\").\n",
        "        backtest_end_date (str): End date for the backtest period (e.g., \"YYYY-MM-DD\").\n",
        "        deterministic (bool): Whether to use deterministic actions. True for evaluation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (results_df, metrics) or (None, None) on failure.\n",
        "               results_df (pd.DataFrame): DataFrame with account value history.\n",
        "               metrics (dict): Dictionary containing performance metrics.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Backtest ---\")\n",
        "    print(f\"Data: {DATA_PATH}\")\n",
        "    print(f\"Model: {MODEL_PATH}\")\n",
        "    print(f\"Period: {backtest_start_date} to {backtest_end_date}\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    print(\"Loading and preparing data...\")\n",
        "    try:\n",
        "        if data_path.endswith('.csv'):\n",
        "            df_full = pd.read_csv(data_path)\n",
        "        elif data_path.endswith('.parquet'):\n",
        "            df_full = pd.read_parquet(data_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported data file format: {data_path}\")\n",
        "\n",
        "        # --- Preprocessing & Filtering ---\n",
        "        # Convert date column if necessary\n",
        "        if 'date' in df_full.columns:\n",
        "             df_full['date'] = pd.to_datetime(df_full['date'])\n",
        "        else:\n",
        "            print(\"Error: 'date' column not found in the data.\")\n",
        "            return None, None\n",
        "\n",
        "        # Filter data for the backtest period\n",
        "        df_backtest = df_full[\n",
        "            (df_full['date'] >= backtest_start_date) &\n",
        "            (df_full['date'] <= backtest_end_date)\n",
        "        ].copy()\n",
        "\n",
        "        # Reset index **after** filtering\n",
        "        df_backtest.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        if df_backtest.empty:\n",
        "            print(\"Error: No data available for the specified backtest period.\")\n",
        "            return None, None\n",
        "\n",
        "        # --- Sanity Check: Ensure required columns are present ---\n",
        "        required_cols = set(env_config.get('tech_indicator_list', []))\n",
        "        required_cols.update(['close', 'tic', 'date', env_config.get('risk_indicator_col', 'turbulence')]) # Add essentials\n",
        "        missing_cols = required_cols - set(df_backtest.columns)\n",
        "        if missing_cols:\n",
        "            print(f\"Error: Missing required columns in backtest data: {missing_cols}\")\n",
        "            return None, None\n",
        "\n",
        "        print(f\"Backtest data prepared. Shape: {df_backtest.shape}, Date range: {df_backtest['date'].min().date()} to {df_backtest['date'].max().date()}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Data file not found at {data_path}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or preprocessing data: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "    # 2. Load Model\n",
        "    print(f\"Loading model ({env_config.get('model_class_name', 'PPO')})...\")\n",
        "    try:\n",
        "        model = PPO.load(model_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Model file not found at {model_path}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "\n",
        "    # 3. Instantiate Environment with Backtest Data and Config\n",
        "    print(\"Instantiating environment...\")\n",
        "    try:\n",
        "        env_kwargs = env_config.copy() # Start with base config from hardcoded values\n",
        "        env_kwargs['df'] = df_backtest\n",
        "\n",
        "        # Calculate dynamic parameters based specifically on the backtest data slice\n",
        "        stock_dim = len(df_backtest[\"tic\"].unique())\n",
        "        if stock_dim == 0:\n",
        "             print(\"Error: No unique tickers ('tic') found in the backtest data slice.\")\n",
        "             return None, None\n",
        "        max_price = df_backtest['close'].max()\n",
        "        hmax = int(env_kwargs['initial_amount'] / max_price) if max_price > 0 else 1\n",
        "\n",
        "        env_kwargs['stock_dim'] = stock_dim\n",
        "        env_kwargs['hmax'] = hmax\n",
        "        env_kwargs['num_stock_shares'] = [0] * stock_dim\n",
        "        env_kwargs['buy_cost_pct'] = [env_kwargs.get('buy_cost_pct', [0.001])[0]] * stock_dim\n",
        "        env_kwargs['sell_cost_pct'] = [env_kwargs.get('sell_cost_pct', [0.001])[0]] * stock_dim\n",
        "\n",
        "        env_kwargs['state_space'] = 1 + 2 * stock_dim + stock_dim * len(env_kwargs['tech_indicator_list'])\n",
        "        env_kwargs['action_space'] = stock_dim\n",
        "\n",
        "        env_kwargs['make_plots'] = False\n",
        "        env_kwargs['print_verbosity'] = env_kwargs.get('print_verbosity', 0)\n",
        "        env_kwargs['initial'] = True\n",
        "        env_kwargs['day'] = 0\n",
        "        env_kwargs['previous_state'] = []\n",
        "        env_kwargs['model_name'] = \"\"\n",
        "        env_kwargs['mode'] = \"backtest\"\n",
        "        env_kwargs['iteration'] = \"\"\n",
        "\n",
        "        env = StockTradingEnv(**env_kwargs)\n",
        "\n",
        "        assert env.observation_space == model.observation_space, \\\n",
        "            f\"Observation space mismatch! Env: {env.observation_space}, Model: {model.observation_space}\"\n",
        "        assert env.action_space == model.action_space, \\\n",
        "            f\"Action space mismatch! Env: {env.action_space}, Model: {model.action_space}\"\n",
        "\n",
        "        print(\"Environment instantiated successfully:\")\n",
        "        print(f\"  Stock Dimension: {env.stock_dim}\")\n",
        "        print(f\"  State Space: {env.state_space}\")\n",
        "        print(f\"  Action Space: {env.action_space.shape}\")\n",
        "        print(f\"  Indicators: {env.tech_indicator_list}\")\n",
        "        print(f\"  Reward Weights (T/D/C/R/Ret): {env.treynor_rate_learn:.2f}/{env.drawdown_component_learn:.2f}/{env.cost_component_learn:.2f}/{env.risk_component_learn:.2f}/{env.return_component_learn:.2f}\")\n",
        "\n",
        "    except AssertionError as e:\n",
        "        print(f\"Error: Environment space mismatch: {e}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error instantiating environment: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    # 4. Run Simulation Loop\n",
        "    print(\"\\nStarting simulation loop...\")\n",
        "    obs, info = env.reset(seed=42)\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    step_count = 0\n",
        "    num_unique_days = len(df_backtest['date'].unique())\n",
        "    print(f\"Expecting approx {num_unique_days} steps for the backtest period.\")\n",
        "\n",
        "    while not (terminated or truncated):\n",
        "        action, _states = model.predict(obs, deterministic=deterministic)\n",
        "        obs, reward, terminated, truncated, info_step = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if step_count % 100 == 0 or done:\n",
        "            current_val = env.asset_memory[-1] if env.asset_memory else env.initial_amount\n",
        "            current_date = env._get_date()\n",
        "            print(f\"  Step: {env.day}/{num_unique_days}, Date: {current_date}, Portfolio: ${current_val:,.2f}, Reward: {reward:.4f}\")\n",
        "\n",
        "        step_count += 1\n",
        "\n",
        "        if done:\n",
        "            print(\"Simulation loop finished.\")\n",
        "            break\n",
        "\n",
        "        # Safety break\n",
        "        if step_count > num_unique_days * 1.1 and num_unique_days > 0:\n",
        "             print(f\"Warning: Simulation loop exceeded expected length ({num_unique_days}). Breaking at step {step_count}.\")\n",
        "             break\n",
        "        elif step_count > 60000:\n",
        "             print(f\"Warning: Simulation loop exceeded 60,000 iterations. Breaking.\")\n",
        "             break\n",
        "\n",
        "    # 5. Get Results & Calculate Metrics\n",
        "    print(\"\\nCalculating performance metrics...\")\n",
        "    try:\n",
        "        results_df = env.save_asset_memory()\n",
        "\n",
        "        if results_df.empty or len(results_df) <= 1:\n",
        "            print(\"Error: Not enough history recorded by the environment to calculate metrics.\")\n",
        "            return None, None\n",
        "\n",
        "        results_df['date'] = pd.to_datetime(results_df['date'])\n",
        "        results_df.set_index('date', inplace=True)\n",
        "        results_df.sort_index(inplace=True)\n",
        "\n",
        "        metrics = {}\n",
        "        portfolio_values = results_df['account_value']\n",
        "        initial_portfolio_value = portfolio_values.iloc[0]\n",
        "        final_portfolio_value = portfolio_values.iloc[-1]\n",
        "\n",
        "        metrics['Start Date'] = portfolio_values.index[0].strftime('%Y-%m-%d')\n",
        "        metrics['End Date'] = portfolio_values.index[-1].strftime('%Y-%m-%d')\n",
        "        metrics['Initial Portfolio Value ($)'] = initial_portfolio_value\n",
        "        metrics['Final Portfolio Value ($)'] = final_portfolio_value\n",
        "        metrics['Total Return (%)'] = ((final_portfolio_value - initial_portfolio_value) / initial_portfolio_value) * 100 if initial_portfolio_value != 0 else 0\n",
        "        metrics['Total Steps'] = step_count\n",
        "        metrics['Total Trades'] = env.trades\n",
        "        metrics['Total Transaction Cost ($)'] = env.cost\n",
        "\n",
        "        returns = portfolio_values.pct_change().dropna()\n",
        "        returns.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "        if not returns.empty:\n",
        "            std_dev = returns.std()\n",
        "            metrics['Volatility (Ann.) (%)'] = (std_dev * np.sqrt(252)) * 100 if std_dev > 0 else 0\n",
        "            metrics['Sharpe Ratio (Ann.)'] = (returns.mean() / std_dev) * np.sqrt(252) if std_dev > 0 else 0\n",
        "\n",
        "            rolling_max = portfolio_values.cummax()\n",
        "            daily_drawdown = portfolio_values / rolling_max - 1.0\n",
        "            max_drawdown = daily_drawdown.min()\n",
        "            metrics['Max Drawdown (%)'] = max_drawdown * 100\n",
        "\n",
        "            duration_years = (portfolio_values.index[-1] - portfolio_values.index[0]).days / 365.25\n",
        "            if duration_years > 0 and initial_portfolio_value != 0:\n",
        "                 annualized_return = ((final_portfolio_value / initial_portfolio_value) ** (1 / duration_years)) - 1\n",
        "            else:\n",
        "                 annualized_return = 0\n",
        "            metrics['Annualized Return (%)'] = annualized_return * 100\n",
        "            metrics['Calmar Ratio'] = (annualized_return / abs(max_drawdown)) if max_drawdown < 0 else np.nan\n",
        "\n",
        "            if QUANTSTATS_AVAILABLE:\n",
        "                try:\n",
        "                    qs_returns = returns.copy()\n",
        "                    qs_returns.name = \"Strategy\"\n",
        "                    if isinstance(qs_returns.index, pd.DatetimeIndex):\n",
        "                        print(\"Calculating extended metrics using quantstats...\")\n",
        "                        # Use basic mode first, as 'full' can sometimes cause issues depending on data/version\n",
        "                        try:\n",
        "                             qs_metrics_dict = quantstats.reports.metrics(qs_returns, mode='basic', display=False).iloc[0].to_dict()\n",
        "                             metrics.update(qs_metrics_dict)\n",
        "                             print(\"Quantstats basic metrics calculated.\")\n",
        "                        except Exception as qs_basic_e:\n",
        "                             print(f\"Warning: quantstats basic calculation failed: {qs_basic_e}. Trying simple stats.\")\n",
        "                             try:\n",
        "                                 # Fallback to simpler quantstats functions if metrics fails\n",
        "                                 metrics['QS Sharpe'] = quantstats.stats.sharpe(qs_returns)\n",
        "                                 metrics['QS Sortino'] = quantstats.stats.sortino(qs_returns)\n",
        "                                 metrics['QS Max Drawdown'] = quantstats.stats.max_drawdown(qs_returns) * 100\n",
        "                                 metrics['QS Volatility (Ann.)'] = quantstats.stats.volatility(qs_returns, annualize=True) * 100\n",
        "                                 print(\"Quantstats simple metrics calculated.\")\n",
        "                             except Exception as qs_simple_e:\n",
        "                                 print(f\"Warning: quantstats simple calculation also failed: {qs_simple_e}\")\n",
        "\n",
        "                    else:\n",
        "                        print(\"Warning: Index is not DatetimeIndex. Skipping quantstats.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: quantstats calculation failed: {e}\")\n",
        "        else:\n",
        "            print(\"Warning: Could not calculate performance ratios (empty/single-point returns series).\")\n",
        "            metrics.update({\n",
        "                'Volatility (Ann.) (%)': 0, 'Sharpe Ratio (Ann.)': 0,\n",
        "                'Max Drawdown (%)': 0, 'Annualized Return (%)': metrics.get('Total Return (%)', 0),\n",
        "                'Calmar Ratio': np.nan\n",
        "            })\n",
        "\n",
        "        print(\"\\n--- Backtest Metrics Summary ---\")\n",
        "        key_metrics_to_print = [\n",
        "            'Initial Portfolio Value ($)', 'Final Portfolio Value ($)', 'Total Return (%)',\n",
        "            'Annualized Return (%)', 'Sharpe Ratio (Ann.)', 'Max Drawdown (%)',\n",
        "            'Volatility (Ann.) (%)', 'Calmar Ratio', 'Total Trades', 'Total Transaction Cost ($)'\n",
        "        ]\n",
        "        # Add quantstats metrics if calculated\n",
        "        qs_keys = ['QS Sharpe', 'QS Sortino', 'QS Max Drawdown', 'QS Volatility (Ann.)', 'Sortino', 'Avg. Drawdown [%]', 'Win Rate [%]', 'Best Day [%]', 'Worst Day [%]']\n",
        "        key_metrics_to_print.extend([k for k in qs_keys if k in metrics])\n",
        "\n",
        "        for key in key_metrics_to_print:\n",
        "             if key in metrics:\n",
        "                 value = metrics[key]\n",
        "                 try:\n",
        "                     print(f\"  {key}: {float(value):,.4f}\")\n",
        "                 except (ValueError, TypeError, OverflowError): # Add OverflowError for very large/small numbers\n",
        "                     print(f\"  {key}: {value}\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating or displaying metrics: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        metrics = {\"error\": str(e)}\n",
        "        # Try to return results_df even if metrics fail\n",
        "        results_df = env.save_asset_memory() if 'env' in locals() and hasattr(env, 'save_asset_memory') else pd.DataFrame()\n",
        "        return results_df, metrics\n",
        "\n",
        "    # 6. Report/Visualize and Save Outputs\n",
        "    print(\"\\nGenerating plot and saving results...\")\n",
        "    try:\n",
        "        model_filename_base = os.path.splitext(os.path.basename(model_path))[0]\n",
        "        output_prefix = f\"backtest_{model_filename_base}_{backtest_start_date}_to_{backtest_end_date}\"\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        portfolio_values.plot(title=f'Portfolio Value Over Time\\n({backtest_start_date} to {backtest_end_date})')\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Portfolio Value ($)\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plot_filename = f'{output_prefix}_portfolio_value.png'\n",
        "        plt.savefig(plot_filename)\n",
        "        print(f\"Saved portfolio value plot to: {plot_filename}\")\n",
        "        plt.close()\n",
        "\n",
        "        results_csv_filename = f'{output_prefix}_results.csv'\n",
        "        results_df.to_csv(results_csv_filename)\n",
        "        print(f\"Saved detailed results (account value) to: {results_csv_filename}\")\n",
        "\n",
        "        metrics_json_filename = f'{output_prefix}_metrics.json'\n",
        "        serializable_metrics = {}\n",
        "        for k, v in metrics.items():\n",
        "            if isinstance(v, (np.integer, np.int64)):\n",
        "                serializable_metrics[k] = int(v)\n",
        "            elif isinstance(v, (np.floating, np.float64)):\n",
        "                serializable_metrics[k] = float(v) if not pd.isna(v) else None\n",
        "            elif isinstance(v, (np.ndarray,)):\n",
        "                 serializable_metrics[k] = v.tolist()\n",
        "            elif isinstance(v, (pd.Timestamp)):\n",
        "                 serializable_metrics[k] = v.strftime('%Y-%m-%d')\n",
        "            elif pd.isna(v):\n",
        "                 serializable_metrics[k] = None\n",
        "            else:\n",
        "                serializable_metrics[k] = v\n",
        "\n",
        "        with open(metrics_json_filename, 'w') as f:\n",
        "            json.dump(serializable_metrics, f, indent=4)\n",
        "        print(f\"Saved performance metrics to: {metrics_json_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during plotting or saving files: {e}\")\n",
        "\n",
        "    if hasattr(env, 'close'):\n",
        "        env.close()\n",
        "\n",
        "    return results_df, metrics\n",
        "\n",
        "\n",
        "# --- Main Execution Block (`if __name__ == \"__main__\":`) ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # <<< --- CHANGE THESE VALUES --- <<<\n",
        "    # --- Core Configuration ---\n",
        "    DATA_PATH = \"/content/indian_stock_data.csv\"  # IMPORTANT: Use the SAME processed data as for training\n",
        "    MODEL_PATH = \"/content/best_optuna_ppo_model new.zip\" # IMPORTANT: Path to the specific model .zip file\n",
        "    BACKTEST_START_DATE = \"2015-01-01\" # Example: Start date for the backtest period\n",
        "    BACKTEST_END_DATE = \"2023-12-31\"   # Example: End date for the backtest period\n",
        "\n",
        "    # --- Environment Configuration (Must match the settings used for training the specific model) ---\n",
        "    INITIAL_AMOUNT = 100000\n",
        "    TURBULENCE_THRESHOLD = 100.0 # Or the value used during training/Optuna\n",
        "    REWARD_SCALING = 1e-4      # Or the value used during training/Optuna\n",
        "    BUY_COST = 0.001             # 0.1%\n",
        "    SELL_COST = 0.001            # 0.1%\n",
        "    # Use the exact list of indicators the model was trained with\n",
        "    INDICATORS = [\"volume\", \"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\", \"turbulence\"]\n",
        "\n",
        "    # ** CRITICAL: Reward Weights **\n",
        "    # These MUST match the weights of the specific trained model being tested (e.g., from Optuna best trial)\n",
        "    W_TREYNOR = 0.4013949773199673    # Example value - REPLACE with actual model weight\n",
        "    W_DRAWDOWN = 2.9068009015669793   # Example value - REPLACE with actual model weight\n",
        "    W_COST = 4.994821708372366       # Example value - REPLACE with actual model weight\n",
        "    W_RISK = 2.947383762136368       # Example value - REPLACE with actual model weight\n",
        "    W_RETURN = 4.862429692924584   # Example value - REPLACE with actual model weight\n",
        "    # >>> --- END OF VALUES TO CHANGE --- >>>\n",
        "\n",
        "    # --- Prepare Environment Configuration Dictionary ---\n",
        "    # This dictionary must contain keys matching StockTradingEnv's __init__ arguments\n",
        "    env_configuration = {\n",
        "        \"initial_amount\": INITIAL_AMOUNT,\n",
        "        \"reward_scaling\": REWARD_SCALING,\n",
        "        \"tech_indicator_list\": INDICATORS,\n",
        "        \"turbulence_threshold\": TURBULENCE_THRESHOLD,\n",
        "        \"risk_indicator_col\": \"turbulence\", # Assuming 'turbulence' is used based on INDICATORS list\n",
        "        # Reward weights passed directly from hardcoded vars\n",
        "        \"treynor_rate_learn\": W_TREYNOR,\n",
        "        \"drawdown_component_learn\": W_DRAWDOWN,\n",
        "        \"cost_component_learn\": W_COST,\n",
        "        \"risk_component_learn\": W_RISK,\n",
        "        \"return_component_learn\": W_RETURN,\n",
        "        # Costs - provide as lists (will be resized inside run_backtest)\n",
        "        \"buy_cost_pct\": [BUY_COST],\n",
        "        \"sell_cost_pct\": [SELL_COST],\n",
        "        # Parameters calculated dynamically inside run_backtest:\n",
        "        # 'df', 'stock_dim', 'hmax', 'num_stock_shares', 'state_space', 'action_space'\n",
        "        # Parameters set for backtesting mode inside run_backtest:\n",
        "        # 'make_plots', 'initial', 'day', 'previous_state', etc.\n",
        "        \"print_verbosity\": 1, # Set verbosity for backtest console output (0=silent, 1=basic, >1 more details)\n",
        "    }\n",
        "\n",
        "    # --- Run the Backtest ---\n",
        "    results, performance_metrics = run_backtest(\n",
        "        data_path=DATA_PATH,\n",
        "        model_path=MODEL_PATH,\n",
        "        env_config=env_configuration, # Pass the constructed dict\n",
        "        backtest_start_date=BACKTEST_START_DATE,\n",
        "        backtest_end_date=BACKTEST_END_DATE,\n",
        "        deterministic=True # Use deterministic actions for evaluation\n",
        "    )\n",
        "\n",
        "    # --- Final Status ---\n",
        "    if results is not None and performance_metrics is not None and 'error' not in performance_metrics:\n",
        "        print(\"\\nBacktest finished successfully.\")\n",
        "        # Use the hardcoded vars for the filename info\n",
        "        model_filename_base = os.path.splitext(os.path.basename(MODEL_PATH))[0]\n",
        "        print(f\"Results saved with prefix: backtest_{model_filename_base}_{BACKTEST_START_DATE}_to_{BACKTEST_END_DATE}\")\n",
        "    else:\n",
        "        print(\"\\nBacktest failed or encountered errors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "jn8zLSHD2QLj",
        "outputId": "c771e7eb-8319-4fe5-9013-30f6db2c583f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "f-string: invalid syntax (<ipython-input-10-f4347ce3103e>, line 61)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-f4347ce3103e>\"\u001b[0;36m, line \u001b[0;32m61\u001b[0m\n\u001b[0;31m    print(f\"Data: {/content/indian_stock_data.csv}\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gymnasium as gym # Using Gymnasium\n",
        "from stable_baselines3 import PPO # Your training used PPO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# import argparse # No longer needed\n",
        "import json\n",
        "import os\n",
        "import logging # Optional: For cleaner logging within the env\n",
        "\n",
        "# --- Optional: Install quantstats ---\n",
        "# pip install quantstats\n",
        "try:\n",
        "    import quantstats\n",
        "    QUANTSTATS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    QUANTSTATS_AVAILABLE = False\n",
        "    print(\"Warning: quantstats not installed. Some metrics will be unavailable. Run: pip install quantstats\")\n",
        "\n",
        "# ==============================================================================\n",
        "# <<< --- PASTE YOUR COMPLETE StockTradingEnv CLASS DEFINITION HERE --- >>>\n",
        "# Make sure it uses 'gymnasium as gym' and matches the interface expected\n",
        "# by the run_backtest function and your trained model.\n",
        "# ==============================================================================\n",
        "\n",
        "# Example Placeholder (REPLACE THIS with your actual class):\n",
        "class StockTradingEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        df,\n",
        "        stock_dim,\n",
        "        hmax,\n",
        "        initial_amount,\n",
        "        num_stock_shares,\n",
        "        buy_cost_pct,\n",
        "        sell_cost_pct,\n",
        "        reward_scaling,\n",
        "        state_space,\n",
        "        action_space,\n",
        "        tech_indicator_list,\n",
        "        turbulence_threshold=None,\n",
        "        risk_indicator_col='turbulence',\n",
        "        make_plots = False,\n",
        "        print_verbosity = 10,\n",
        "        day = 0,\n",
        "        initial=True,\n",
        "        previous_state=[],\n",
        "        model_name = '',\n",
        "        mode = '',\n",
        "        iteration = '',\n",
        "        # --- Reward Weights ---\n",
        "        treynor_rate_learn = 0.0,\n",
        "        drawdown_component_learn = 0.0,\n",
        "        cost_component_learn = 0.0,\n",
        "        risk_component_learn = 0.0,\n",
        "        return_component_learn = 1.0, # Default to only return if weights aren't set\n",
        "        ):\n",
        "\n",
        "        self.day = day\n",
        "        self.df = df # DataFrame should have 'date_id' as index\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        # num_stock_shares should be initialized if needed, but state tracks it\n",
        "        self.num_stock_shares = num_stock_shares # Might be redundant if state handles it\n",
        "        self.initial_amount = initial_amount\n",
        "        # Ensure costs are lists of correct length\n",
        "        self.buy_cost_pct = buy_cost_pct if isinstance(buy_cost_pct, list) and len(buy_cost_pct) == stock_dim else [0.001] * stock_dim\n",
        "        self.sell_cost_pct = sell_cost_pct if isinstance(sell_cost_pct, list) and len(sell_cost_pct) == stock_dim else [0.001] * stock_dim\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space # Provided state space size\n",
        "        # Action space size is implicitly stock_dim for Box shape=(stock_dim,)\n",
        "        self.action_space_size = action_space # Parameter name might be confusing, using internally\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        self.risk_indicator_col = risk_indicator_col\n",
        "        self.make_plots = make_plots\n",
        "        self.print_verbosity = print_verbosity\n",
        "        self.initial = initial\n",
        "        self.previous_state = previous_state\n",
        "        self.model_name=model_name\n",
        "        self.mode=mode\n",
        "        self.iteration=iteration\n",
        "\n",
        "        # --- Reward Weights ---\n",
        "        self.treynor_rate_learn = treynor_rate_learn\n",
        "        self.drawdown_component_learn = drawdown_component_learn\n",
        "        self.cost_component_learn = cost_component_learn\n",
        "        self.risk_component_learn = risk_component_learn\n",
        "        self.return_component_learn = return_component_learn\n",
        "\n",
        "        # --- Action & Observation Spaces ---\n",
        "        # Action space: [-1, 1] for each stock, scaled internally\n",
        "        # Shape is (stock_dim,)\n",
        "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(self.stock_dim,))\n",
        "\n",
        "        # Observation space: [Balance] + [Prices]*stock_dim + [Shares]*stock_dim + [Indicators]*stock_dim\n",
        "        # Shape is (state_space,) which should be 1 + 2*stock_dim + stock_dim*len(indicators)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
        "        )\n",
        "\n",
        "        # --- Data Loading & State Initialization ---\n",
        "        # Access data using the integer index 'day' (which corresponds to 'date_id')\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False\n",
        "        # Initial state is set in reset() or step()\n",
        "        self.state = [] # Initialize as empty, set in reset\n",
        "\n",
        "        # --- Portfolio Tracking ---\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        self.asset_memory = [self.initial_amount] # Record portfolio value over time\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[]\n",
        "        self.date_memory=[self._get_date()] # Stores actual dates\n",
        "        self.trades = 0\n",
        "        self.cost = 0.0\n",
        "\n",
        "        # --- Reward Components Tracking ---\n",
        "        self.rewards_memory = [] # Store cumulative reward per step\n",
        "        self.treynor_rewards_memory = []\n",
        "        self.drawdown_rewards_memory = []\n",
        "        self.cost_rewards_memory = []\n",
        "        self.risk_rewards_memory = []\n",
        "        self.return_rewards_memory = []\n",
        "\n",
        "        # --- Internal State ---\n",
        "        self._seed() # Handled by reset in newer gym\n",
        "\n",
        "    def _initiate_state(self):\n",
        "        \"\"\"Initializes the state array FOR THE CURRENT DAY.\"\"\"\n",
        "        # Ensure data for the current day is loaded correctly\n",
        "        if self.day not in self.df.index:\n",
        "            raise IndexError(f\"Day {self.day} not found in DataFrame index. Max index: {self.df.index.max()}\")\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "\n",
        "        # Verify self.data contains data for all stocks for the current day\n",
        "        if len(self.data.tic.unique()) != self.stock_dim:\n",
        "             print(f\"Warning: Day {self.day}, Date {self._get_date()}: Expected {self.stock_dim} tickers, found {len(self.data.tic.unique())} in self.data.\")\n",
        "             # Handle potential missing data for a day if necessary (e.g., forward fill state?)\n",
        "             # For now, assume data is complete for the day\n",
        "\n",
        "        if self.initial:\n",
        "            # [Account Balance] + [Price Columns] * stock_dim + [Shares Owned] * stock_dim + [Tech Indicators] * stock_dim\n",
        "            # Ensure data is sorted by 'tic' within the day group if needed for consistent order\n",
        "            current_data = self.data.sort_values(by='tic') # Sort to ensure consistent order\n",
        "\n",
        "            state = (\n",
        "                [self.initial_amount] # Balance\n",
        "                + current_data.close.values.tolist() # Prices\n",
        "                + [0] * self.stock_dim # Shares\n",
        "                + sum([current_data[tech].values.tolist() for tech in self.tech_indicator_list], []) # Flattened indicators\n",
        "            )\n",
        "            self.initial = False # Set initial to False after the first state initialization\n",
        "        else:\n",
        "             # Use previous state structure but update with current market data\n",
        "             # Ensure previous_state is available and has the correct structure\n",
        "             if not self.previous_state or len(self.previous_state) != self.state_space:\n",
        "                 raise ValueError(\"Invalid previous_state for non-initial step.\")\n",
        "\n",
        "             current_data = self.data.sort_values(by='tic') # Sort to ensure consistent order\n",
        "\n",
        "             state = (\n",
        "                [self.previous_state[0]] # Balance from previous state\n",
        "                + current_data.close.values.tolist() # Current prices\n",
        "                + self.previous_state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)] # Shares from previous state\n",
        "                + sum([current_data[tech].values.tolist() for tech in self.tech_indicator_list], []) # Current indicators\n",
        "            )\n",
        "        # Ensure state shape matches observation space\n",
        "        if len(state) != self.state_space:\n",
        "             print(f\"DEBUG: State Length Mismatch in _initiate_state!\")\n",
        "             print(f\"  Expected state_space: {self.state_space}\")\n",
        "             print(f\"  Actual state length: {len(state)}\")\n",
        "             print(f\"  Balance: 1\")\n",
        "             print(f\"  Prices: {len(current_data.close.values.tolist())} (stock_dim={self.stock_dim})\")\n",
        "             if self.initial:\n",
        "                print(f\"  Shares: {len([0] * self.stock_dim)}\")\n",
        "             else:\n",
        "                 print(f\"  Shares: {len(self.previous_state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)])}\")\n",
        "             indicators_len = len(sum([current_data[tech].values.tolist() for tech in self.tech_indicator_list], []))\n",
        "             print(f\"  Indicators: {indicators_len} (num_indicators={len(self.tech_indicator_list)})\")\n",
        "             # Raise error if mismatch is detected\n",
        "             raise AssertionError(f\"State length mismatch: Expected {self.state_space}, got {len(state)}\")\n",
        "\n",
        "        # Ensure state is numpy array of float32\n",
        "        return np.array(state, dtype=np.float32)\n",
        "\n",
        "    def _get_date(self):\n",
        "        \"\"\"Retrieves the actual date for the current step.\"\"\"\n",
        "        if self.day < len(self.df.index.unique()):\n",
        "            # Get the 'date' associated with the first row of the current day index group\n",
        "            # Assumes 'date' column exists even if 'date_id' is the index\n",
        "            return self.df.loc[self.day, 'date'].iloc[0]\n",
        "        else:\n",
        "           # Handle edge case where day might exceed data length briefly during termination check\n",
        "           last_day_index = self.df.index.max()\n",
        "           return self.df.loc[last_day_index, 'date'].iloc[0]\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        \"\"\"Performs a sell action.\"\"\"\n",
        "        # Map action from [-1, 0) to [0, self.hmax] shares to sell\n",
        "        # Action is negative for selling\n",
        "        shares_owned = self.state[index + 1 + self.stock_dim]\n",
        "        sell_num_shares = min(shares_owned, int(self.hmax * abs(action)))\n",
        "\n",
        "        if sell_num_shares > 0 and self.state[index + 1] > 0: # Check if price is positive\n",
        "            sell_amount = self.state[index + 1] * sell_num_shares * (1 - self.sell_cost_pct[index])\n",
        "            self.state[0] += sell_amount # Increase balance\n",
        "            self.state[index + 1 + self.stock_dim] -= sell_num_shares # Decrease shares owned\n",
        "            transaction_cost = self.state[index + 1] * sell_num_shares * self.sell_cost_pct[index]\n",
        "            self.cost += transaction_cost\n",
        "            self.trades += 1\n",
        "            if self.print_verbosity > 1:\n",
        "                 current_tic = self.df.loc[self.day, 'tic'].iloc[index] # Assumes consistent order\n",
        "                 print(f\"  Sell {sell_num_shares} of {current_tic}: Price={self.state[index+1]:.2f}, Cost={transaction_cost:.2f}, CumCost={self.cost:.2f}\")\n",
        "        else:\n",
        "            sell_num_shares = 0\n",
        "\n",
        "        return sell_num_shares\n",
        "\n",
        "    def _buy_stock(self, index, action):\n",
        "        \"\"\"Performs a buy action.\"\"\"\n",
        "        # Map action from (0, 1] to [0, self.hmax] shares to buy\n",
        "        current_price = self.state[index + 1]\n",
        "        if current_price <= 0: # Cannot buy if price is non-positive\n",
        "            return 0\n",
        "\n",
        "        cost_per_share = current_price * (1 + self.buy_cost_pct[index])\n",
        "        available_amount = self.state[0] // cost_per_share # Max affordable shares based on integer division\n",
        "        buy_num_shares = min(available_amount, int(self.hmax * action)) # Shares to buy based on action and affordability\n",
        "\n",
        "        if buy_num_shares > 0:\n",
        "            buy_amount = current_price * buy_num_shares * (1 + self.buy_cost_pct[index])\n",
        "            self.state[0] -= buy_amount # Decrease balance\n",
        "            self.state[index + 1 + self.stock_dim] += buy_num_shares # Increase shares owned\n",
        "            transaction_cost = current_price * buy_num_shares * self.buy_cost_pct[index]\n",
        "            self.cost += transaction_cost\n",
        "            self.trades += 1\n",
        "            if self.print_verbosity > 1:\n",
        "                current_tic = self.df.loc[self.day, 'tic'].iloc[index] # Assumes consistent order\n",
        "                print(f\"  Buy {buy_num_shares} of {current_tic}: Price={current_price:.2f}, Cost={transaction_cost:.2f}, CumCost={self.cost:.2f}\")\n",
        "        else:\n",
        "            buy_num_shares = 0\n",
        "\n",
        "        return buy_num_shares\n",
        "\n",
        "\n",
        "    def _calculate_reward(self, P0, P1):\n",
        "        \"\"\"Calculates the reward based on portfolio value change and optional components.\"\"\"\n",
        "        # --- Core Return Component ---\n",
        "        portfolio_return = (P1 / P0) - 1 if P0 != 0 else 0\n",
        "        # Simple return-based reward (scaled)\n",
        "        return_reward_unweighted = portfolio_return * self.reward_scaling # Scaled but not weighted\n",
        "\n",
        "        # --- Calculate Optional Components (Unweighted and Scaled) ---\n",
        "        treynor_reward_unweighted = 0.0\n",
        "        drawdown_reward_unweighted = 0.0\n",
        "        cost_penalty_unweighted = 0.0\n",
        "        turbulence_penalty_unweighted = 0.0\n",
        "\n",
        "        # Treynor Ratio Component (Simplified)\n",
        "        if self.treynor_rate_learn > 0:\n",
        "            treynor_reward_unweighted = max(portfolio_return, 0) * self.reward_scaling # Only reward positive returns, scaled\n",
        "\n",
        "        # Max Drawdown Component\n",
        "        if self.drawdown_component_learn > 0 and len(self.asset_memory) > 1:\n",
        "            portfolio_values = pd.Series(self.asset_memory)\n",
        "            rolling_max = portfolio_values.cummax()\n",
        "            current_drawdown = (portfolio_values.iloc[-1] / rolling_max.iloc[-1]) - 1.0 if rolling_max.iloc[-1] > 0 else 0\n",
        "            # Penalize based on the magnitude of the current drawdown\n",
        "            drawdown_reward_unweighted = current_drawdown * self.reward_scaling # Drawdown is negative, scaled\n",
        "\n",
        "        # Transaction Cost Component\n",
        "        if self.cost_component_learn > 0 and self.step_cost > 0: # Use step_cost\n",
        "            cost_penalty_unweighted = (self.step_cost / P1) * self.reward_scaling if P1 > 0 else 0\n",
        "            cost_penalty_unweighted = -abs(cost_penalty_unweighted) # Ensure it's a penalty, scaled\n",
        "\n",
        "        # Risk (Turbulence) Component\n",
        "        # Assume turbulence is the last indicator for simplicity if risk_indicator_col isn't used directly\n",
        "        # Find index of risk indicator\n",
        "        try:\n",
        "            risk_col_idx = self.tech_indicator_list.index(self.risk_indicator_col)\n",
        "            # State structure: [bal] + [prices]*N + [shares]*N + [indic1]*N + [indic2]*N ...\n",
        "            # Start index of indicators section: 1 + 2*N\n",
        "            # Start index for the specific risk indicator: 1 + 2*N + risk_col_idx*N\n",
        "            # We need the value for the first stock (or avg?) - let's assume first stock's value represents market risk\n",
        "            risk_indicator_state_index = 1 + 2 * self.stock_dim + risk_col_idx * self.stock_dim\n",
        "            current_turbulence = self.state[risk_indicator_state_index]\n",
        "        except (ValueError, IndexError):\n",
        "            current_turbulence = 0\n",
        "            if self.risk_component_learn > 0:\n",
        "                print(f\"Warning: Risk indicator '{self.risk_indicator_col}' not found or index out of bounds.\")\n",
        "\n",
        "\n",
        "        if self.risk_component_learn > 0 and self.turbulence_threshold is not None:\n",
        "            if current_turbulence > self.turbulence_threshold:\n",
        "               turbulence_penalty_unweighted = -(current_turbulence / self.turbulence_threshold) * self.reward_scaling # Scaled penalty\n",
        "\n",
        "\n",
        "        # --- Combine Components with Weights ---\n",
        "        total_reward = (return_reward_unweighted * self.return_component_learn +\n",
        "                        treynor_reward_unweighted * self.treynor_rate_learn +\n",
        "                        drawdown_reward_unweighted * self.drawdown_component_learn +\n",
        "                        cost_penalty_unweighted * self.cost_component_learn +\n",
        "                        turbulence_penalty_unweighted * self.risk_component_learn)\n",
        "\n",
        "        # Store unweighted components for logging if needed (optional)\n",
        "        self.return_rewards_memory.append(return_reward_unweighted * self.return_component_learn)\n",
        "        self.treynor_rewards_memory.append(treynor_reward_unweighted * self.treynor_rate_learn)\n",
        "        self.drawdown_rewards_memory.append(drawdown_reward_unweighted * self.drawdown_component_learn)\n",
        "        self.cost_rewards_memory.append(cost_penalty_unweighted * self.cost_component_learn)\n",
        "        self.risk_rewards_memory.append(turbulence_penalty_unweighted * self.risk_component_learn)\n",
        "\n",
        "\n",
        "        return total_reward\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
        "        truncated = False # Gymnasium uses truncated, not done for time limits\n",
        "\n",
        "        if self.terminal:\n",
        "            # End of data episode\n",
        "            if self.make_plots:\n",
        "                self._plot()\n",
        "\n",
        "            end_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (1 + self.stock_dim)]) # Prices\n",
        "                * np.array(self.state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)]) # Shares\n",
        "            )\n",
        "\n",
        "            # --- Final Metrics Log ---\n",
        "            if self.print_verbosity >= 1:\n",
        "                print(\"-\" * 30)\n",
        "                print(f\"EPISODE END - Day: {self.day}\")\n",
        "                print(f\"Beginning Portfolio Value: {self.asset_memory[0]:,.2f}\")\n",
        "                print(f\"End Portfolio Value: {end_total_asset:,.2f}\")\n",
        "                total_return = (end_total_asset / self.asset_memory[0] - 1) * 100 if self.asset_memory[0] != 0 else 0\n",
        "                print(f\"Total Return: {total_return:.2f}%\")\n",
        "                print(f\"Total Trades: {self.trades}\")\n",
        "                print(f\"Total Transaction Costs: ${self.cost:,.2f}\") # Cumulative cost\n",
        "                sharpe = 0\n",
        "                max_drawdown = 0\n",
        "                if len(self.asset_memory) > 1:\n",
        "                    try:\n",
        "                        portfolio_values = pd.Series(self.asset_memory)\n",
        "                        returns = portfolio_values.pct_change().dropna()\n",
        "                        if not returns.empty and returns.std() != 0:\n",
        "                            sharpe = (returns.mean() / returns.std()) * np.sqrt(252)\n",
        "                            print(f\"Sharpe Ratio (Approx. Annualized): {sharpe:.3f}\")\n",
        "                        else: print(\"Sharpe Ratio: N/A (std=0 or no returns)\")\n",
        "\n",
        "                        rolling_max = portfolio_values.cummax()\n",
        "                        daily_drawdown = portfolio_values / rolling_max - 1.0\n",
        "                        max_drawdown = daily_drawdown.min() * 100\n",
        "                        print(f\"Max Drawdown: {max_drawdown:.2f}%\")\n",
        "                    except Exception as e:\n",
        "                         print(f\"Error calculating final Sharpe/Drawdown: {e}\")\n",
        "\n",
        "                print(\"-\" * 30)\n",
        "\n",
        "            # Provide final info dict\n",
        "            info = {\n",
        "                'final_value': end_total_asset,\n",
        "                'total_return_percent': total_return,\n",
        "                'total_trades': self.trades,\n",
        "                'total_cost': self.cost,\n",
        "                'sharpe_ratio': sharpe,\n",
        "                'max_drawdown_percent': max_drawdown\n",
        "            }\n",
        "            # Return the *last valid state* before termination might be better than zeros\n",
        "            # Ensure it's float32\n",
        "            return self.state.astype(np.float32), 0.0, True, False, info\n",
        "\n",
        "        else:\n",
        "            # --- Process Actions ---\n",
        "            # Store portfolio value before taking action\n",
        "            begin_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (1 + self.stock_dim)]) # Prices\n",
        "                * np.array(self.state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)]) # Shares\n",
        "            )\n",
        "\n",
        "            # Reset step-specific cost/trades for reward calculation\n",
        "            self.step_cost = 0.0\n",
        "            step_trades = 0\n",
        "            cost_before_step = self.cost # Store cumulative cost before this step\n",
        "\n",
        "            # Apply actions scaled by hmax\n",
        "            actions = actions * self.hmax # Scale actions from [-1, 1] to [-hmax, hmax]\n",
        "            self.actions_memory.append(actions) # Store the scaled actions\n",
        "\n",
        "            # Ensure correct sorting for processing trades (Sells before Buys)\n",
        "            argsort_actions = np.argsort(actions)\n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            # Perform sells first\n",
        "            for index in sell_index:\n",
        "                step_trades += self._sell_stock(index, actions[index]) > 0 # Increment if trade occurred\n",
        "\n",
        "            # Perform buys\n",
        "            for index in buy_index:\n",
        "                step_trades += self._buy_stock(index, actions[index]) > 0 # Increment if trade occurred\n",
        "\n",
        "            # Calculate cost incurred ONLY in this step\n",
        "            self.step_cost = self.cost - cost_before_step\n",
        "\n",
        "\n",
        "            # --- Move to Next Day ---\n",
        "            self.day += 1\n",
        "            # Check if next day exists in index\n",
        "            if self.day not in self.df.index:\n",
        "                 print(f\"Warning: Next day {self.day} not in DataFrame index. Ending episode.\")\n",
        "                 self.terminal = True\n",
        "                 # Recalculate end asset value based on current state\n",
        "                 end_total_asset = self.state[0] + sum(\n",
        "                     np.array(self.state[1 : (1 + self.stock_dim)])\n",
        "                     * np.array(self.state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)])\n",
        "                 )\n",
        "                 info = { 'final_value': end_total_asset, 'error': 'Data ended prematurely' }\n",
        "                 return self.state.astype(np.float32), 0.0, True, False, info # Terminate\n",
        "\n",
        "            # Load data for the new day\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.data = self.data.sort_values(by='tic') # Ensure consistent order\n",
        "\n",
        "            # --- Turbulence Check (Optional) ---\n",
        "            turbulence_sell_off = False\n",
        "            if self.turbulence_threshold is not None:\n",
        "                 try:\n",
        "                    # Assuming turbulence is consistent across stocks for the day\n",
        "                    current_turbulence = self.data[self.risk_indicator_col].iloc[0]\n",
        "                    if current_turbulence > self.turbulence_threshold:\n",
        "                        turbulence_sell_off = True\n",
        "                        if self.print_verbosity >=1:\n",
        "                           print(f\"Turbulence Alert! Day {self.day} ({current_turbulence:.2f} > {self.turbulence_threshold}). Selling all assets.\")\n",
        "                        # Simulate selling everything - modify state directly\n",
        "                        sell_cost_step = 0\n",
        "                        for i in range(self.stock_dim):\n",
        "                           shares_owned = self.state[i + 1 + self.stock_dim]\n",
        "                           if shares_owned > 0 and self.state[i + 1] > 0:\n",
        "                               sell_amount = self.state[i + 1] * shares_owned * (1 - self.sell_cost_pct[i])\n",
        "                               self.state[0] += sell_amount # Increase balance\n",
        "                               self.state[i + 1 + self.stock_dim] = 0 # Decrease shares to 0\n",
        "                               cost_i = self.state[i + 1] * shares_owned * self.sell_cost_pct[i]\n",
        "                               self.cost += cost_i\n",
        "                               self.step_cost += cost_i # Add to step cost as well\n",
        "                               self.trades += 1\n",
        "                               step_trades += 1\n",
        "\n",
        "                 except Exception as e:\n",
        "                      print(f\"Warning: Error during turbulence check: {e}\")\n",
        "\n",
        "\n",
        "            # --- Update State ---\n",
        "            # State uses: [New Balance] + [New Prices] + [Updated Shares] + [New Indicators]\n",
        "            new_state = (\n",
        "                [self.state[0]] # Updated Balance (potentially from turbulence sell-off)\n",
        "                + self.data.close.values.tolist() # New Prices from self.data\n",
        "                + list(self.state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)]) # Shares owned (potentially updated)\n",
        "                + sum([self.data[tech].values.tolist() for tech in self.tech_indicator_list], []) # New Indicators\n",
        "            )\n",
        "            # Update the internal state and previous state tracker\n",
        "            self.previous_state = self.state # Store the state *before* the update\n",
        "            self.state = np.array(new_state, dtype=np.float32)\n",
        "\n",
        "            # --- Sanity Check for State Shape ---\n",
        "            if len(self.state) != self.state_space:\n",
        "                 print(f\"DEBUG: State Length Mismatch in step!\")\n",
        "                 print(f\"  Day: {self.day}, Date: {self._get_date()}\")\n",
        "                 print(f\"  Expected state_space: {self.state_space}\")\n",
        "                 print(f\"  Actual state length: {len(self.state)}\")\n",
        "                 # Raise error if mismatch is detected\n",
        "                 raise AssertionError(f\"State length mismatch after step: Expected {self.state_space}, got {len(self.state)}\")\n",
        "\n",
        "\n",
        "            # --- Calculate Portfolio Value & Reward ---\n",
        "            end_total_asset = self.state[0] + sum(\n",
        "                 np.array(self.state[1 : (1 + self.stock_dim)]) # Prices\n",
        "                 * np.array(self.state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)]) # Shares\n",
        "            )\n",
        "            # Use portfolio value *before* turbulence sell-off for reward calc? Or after?\n",
        "            # Let's use value *after* all actions for the day (including turbulence)\n",
        "            reward = self._calculate_reward(begin_total_asset, end_total_asset)\n",
        "\n",
        "            # Store results\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            self.date_memory.append(self._get_date())\n",
        "            self.portfolio_return_memory.append((end_total_asset/begin_total_asset)-1 if begin_total_asset!=0 else 0)\n",
        "            self.rewards_memory.append(reward)\n",
        "\n",
        "\n",
        "            if self.print_verbosity >= 1 and self.day % 20 == 0: # Print status periodically\n",
        "                 print(f\"Day: {self.day}, Date: {self._get_date()}, Portfolio: {end_total_asset:,.2f}, Reward: {reward:.4f}, StepCost: {self.step_cost:.2f}\")\n",
        "\n",
        "            # Return observation, reward, terminated, truncated, info\n",
        "            info = {\n",
        "                'current_value': end_total_asset,\n",
        "                'step_reward': reward,\n",
        "                'step_cost': self.step_cost,\n",
        "                'step_trades': step_trades,\n",
        "                'turbulence_selloff': turbulence_sell_off\n",
        "                }\n",
        "\n",
        "        # Ensure state is float32\n",
        "        return self.state.astype(np.float32), reward, False, truncated, info\n",
        "\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        super().reset(seed=seed) # Important for reproducibility in Gym v26+\n",
        "\n",
        "        # Reset internal env state\n",
        "        self.day = 0\n",
        "        self.initial = True # Reset initial flag\n",
        "        # Re-initialize state using the method\n",
        "        self.state = self._initiate_state() # This handles self.initial=True case\n",
        "\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory = []\n",
        "        self.date_memory = [self._get_date()] # Get date for day 0\n",
        "        self.trades = 0\n",
        "        self.cost = 0.0\n",
        "        self.step_cost = 0.0 # Reset step cost\n",
        "\n",
        "        # Reset reward component tracking\n",
        "        self.rewards_memory = []\n",
        "        self.treynor_rewards_memory = []\n",
        "        self.drawdown_rewards_memory = []\n",
        "        self.cost_rewards_memory = []\n",
        "        self.risk_rewards_memory = []\n",
        "        self.return_rewards_memory = []\n",
        "\n",
        "        self.terminal = False\n",
        "        self.previous_state = [] # Reset previous state\n",
        "\n",
        "        # Return initial observation and info dictionary\n",
        "        # Ensure state is float32\n",
        "        observation = self.state.astype(np.float32)\n",
        "        info = {'initial_value': self.initial_amount}\n",
        "\n",
        "        # Gym requires returning obs, info\n",
        "        return observation, info\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        # Simple text-based rendering\n",
        "        print(f\"Day: {self.day}, Date: {self._get_date()}\")\n",
        "        print(f\"Portfolio Value: {self.asset_memory[-1]:,.2f}\")\n",
        "        print(f\"Total Shares Held: {np.sum(self.state[(1 + self.stock_dim) : (1 + 2 * self.stock_dim)]):.0f}\")\n",
        "        print(f\"Total Transaction Costs: ${self.cost:,.2f}\")\n",
        "        if len(self.actions_memory) > 0:\n",
        "            last_action_str = \", \".join([f\"{a:.2f}\" for a in self.actions_memory[-1]])\n",
        "            print(f\"Last Action (Scaled): [{last_action_str}]\")\n",
        "        if len(self.rewards_memory) > 0:\n",
        "            print(f\"Last Step Reward: {self.rewards_memory[-1]:.4f}\")\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        # Handled by super().reset(seed=seed) in gymnasium >= 0.26\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        if self.make_plots:\n",
        "           plt.close('all') # Close any figures created by _plot\n",
        "        #print(\"Environment closed.\") # Optional\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        \"\"\" Saves the recorded asset values over time. \"\"\"\n",
        "        if not self.date_memory or not self.asset_memory:\n",
        "             print(\"Warning: Date or Asset memory is empty.\")\n",
        "             return pd.DataFrame()\n",
        "\n",
        "        # Ensure lengths match, possibly due to early termination\n",
        "        min_len = min(len(self.date_memory), len(self.asset_memory))\n",
        "        if len(self.date_memory) != len(self.asset_memory):\n",
        "             print(f\"Warning: Date memory length ({len(self.date_memory)}) != Asset memory length ({len(self.asset_memory)}). Truncating to {min_len}.\")\n",
        "\n",
        "        date_mem = self.date_memory[:min_len]\n",
        "        asset_mem = self.asset_memory[:min_len]\n",
        "\n",
        "        account_value_df = pd.DataFrame({'date': date_mem, 'account_value': asset_mem})\n",
        "        account_value_df = account_value_df.drop_duplicates(subset=['date'], keep='last')\n",
        "        account_value_df['date'] = pd.to_datetime(account_value_df['date'])\n",
        "        account_value_df.set_index('date', inplace=True) # Set date as index\n",
        "        return account_value_df\n",
        "\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        \"\"\"Saves the actions taken by the agent.\"\"\"\n",
        "        # Actions correspond to the decision made *before* the date increments\n",
        "        # Action at index t leads to state/value at date t+1\n",
        "        if not self.actions_memory:\n",
        "            print(\"Warning: Action memory is empty.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        num_actions = len(self.actions_memory)\n",
        "        # Match actions with the date *after* the action was taken\n",
        "        if len(self.date_memory) > num_actions:\n",
        "            action_dates = self.date_memory[1:num_actions+1]\n",
        "            actions_to_save = self.actions_memory\n",
        "        else: # If lengths mismatch unexpectedly, truncate\n",
        "            print(f\"Warning: Action memory length ({num_actions}) >= Date memory length ({len(self.date_memory)}). Truncating actions.\")\n",
        "            min_len = min(num_actions, len(self.date_memory) - 1)\n",
        "            if min_len <= 0: return pd.DataFrame() # Cannot save if no matching dates\n",
        "            action_dates = self.date_memory[1:min_len+1]\n",
        "            actions_to_save = self.actions_memory[:min_len]\n",
        "\n",
        "        action_df = pd.DataFrame({'date': action_dates, 'actions': actions_to_save})\n",
        "        action_df['date'] = pd.to_datetime(action_df['date'])\n",
        "        action_df.set_index('date', inplace=True)\n",
        "        return action_df\n",
        "\n",
        "    def _plot(self):\n",
        "         \"\"\"Plots the portfolio value over time during the episode.\"\"\"\n",
        "         if not self.date_memory or not self.asset_memory:\n",
        "              print(\"Cannot plot: Date or Asset memory is empty.\")\n",
        "              return\n",
        "\n",
        "         plt.figure(figsize=(12, 6))\n",
        "         # Ensure date_memory and asset_memory are aligned\n",
        "         min_len = min(len(self.date_memory), len(self.asset_memory))\n",
        "         plt.plot(pd.to_datetime(self.date_memory[:min_len]), self.asset_memory[:min_len], label='Portfolio Value')\n",
        "         plt.title(f'Portfolio Value Over Time ({self.mode} {self.iteration})')\n",
        "         plt.xlabel('Date')\n",
        "         plt.ylabel('Portfolio Value ($)')\n",
        "         plt.grid(True)\n",
        "         plt.legend()\n",
        "         plt.tight_layout()\n",
        "         plt.show()\n",
        "\n",
        "# ==============================================================================\n",
        "# --- End of StockTradingEnv Class Definition ---\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# --- Backtesting Function (with Debug prints) ---\n",
        "def run_backtest(\n",
        "    data_path: str,\n",
        "    model_path: str,\n",
        "    env_config: dict, # Dictionary with ALL required env init args derived from hardcoded vars\n",
        "    backtest_start_date: str,\n",
        "    backtest_end_date: str,\n",
        "    deterministic: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs a backtest for a trained RL agent using the provided StockTradingEnv.\n",
        "    Includes debug prints for diagnosing shape mismatches.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Backtest ---\")\n",
        "    print(f\"Data: {data_path}\")\n",
        "    print(f\"Model: {model_path}\")\n",
        "    print(f\"Period: {backtest_start_date} to {backtest_end_date}\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    print(\"Loading and preparing data...\")\n",
        "    try:\n",
        "        if data_path.endswith('.csv'):\n",
        "            df_full = pd.read_csv(data_path)\n",
        "        elif data_path.endswith('.parquet'):\n",
        "            df_full = pd.read_parquet(data_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported data file format: {data_path}\")\n",
        "\n",
        "        # --- Preprocessing & Filtering ---\n",
        "        if 'date' in df_full.columns:\n",
        "             df_full['date'] = pd.to_datetime(df_full['date'])\n",
        "             df_full.sort_values(by=['date', 'tic'], inplace=True)\n",
        "        else:\n",
        "            print(\"Error: 'date' column not found in the data.\")\n",
        "            return None, None\n",
        "\n",
        "        # --- >>> ADD THIS BLOCK TO FILTER FOR THE 8 TRAINING TICKERS EXPECTED BY THE MODEL <<< ---\n",
        "        TRAINING_TICKERS = ['ADANIENT.NS', 'HDFCBANK.NS', 'ICICIBANK.NS', 'INFY.NS', 'RELIANCE.NS', 'SBIN.NS', 'TATAMOTORS.NS', 'TCS.NS']\n",
        "        print(f\"Filtering data to include only the {len(TRAINING_TICKERS)} tickers the loaded model expects (based on error).\")\n",
        "        print(f\"Expected training tickers: {TRAINING_TICKERS}\")\n",
        "        df_full = df_full[df_full['tic'].isin(TRAINING_TICKERS)].copy()\n",
        "        if df_full.empty:\n",
        "            print(f\"Error: No data found for the specified {len(TRAINING_TICKERS)} tickers in {data_path}.\")\n",
        "            return None, None\n",
        "        print(f\"Data shape after filtering by training tickers: {df_full.shape}\")\n",
        "        # --- >>> END OF ADDED BLOCK <<< ---\n",
        "\n",
        "        # Filter data for the backtest period\n",
        "        df_backtest = df_full[\n",
        "            (df_full['date'] >= backtest_start_date) &\n",
        "            (df_full['date'] <= backtest_end_date)\n",
        "        ].copy()\n",
        "\n",
        "        # Final check and index preparation\n",
        "        if df_backtest.empty:\n",
        "            print(\"Error: No data available for the specified backtest period after filtering by tickers.\")\n",
        "            return None, None\n",
        "\n",
        "        df_backtest.sort_values(by=['date', 'tic'], inplace=True)\n",
        "        df_backtest['date_id'] = df_backtest.groupby('date').ngroup()\n",
        "        df_backtest.set_index('date_id', inplace=True)\n",
        "\n",
        "        # --- ADD DEBUG PRINT FOR DF_BACKTEST SHAPE AND TICKERS ---\n",
        "        print(f\"DEBUG: df_backtest shape after all filtering: {df_backtest.shape}\")\n",
        "        print(f\"DEBUG: Unique tickers in df_backtest: {df_backtest['tic'].unique()}\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "\n",
        "        # --- Sanity Check: Ensure required columns are present ---\n",
        "        required_cols = set(env_config.get('tech_indicator_list', []))\n",
        "        required_cols.update(['close', 'tic', 'date'])\n",
        "        risk_col = env_config.get('risk_indicator_col', None)\n",
        "        if risk_col and risk_col not in required_cols: required_cols.add(risk_col)\n",
        "        missing_cols = required_cols - set(df_backtest.columns)\n",
        "        if missing_cols:\n",
        "            print(f\"Error: Missing required columns in backtest data: {missing_cols}\")\n",
        "            return None, None\n",
        "\n",
        "        print(f\"Backtest data prepared. Shape: {df_backtest.shape}, Date range: {df_backtest['date'].min().date()} to {df_backtest['date'].max().date()}\")\n",
        "        print(f\"Index reset based on date groups. Index range: {df_backtest.index.min()} to {df_backtest.index.max()}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Data file not found at {data_path}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or preprocessing data: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "    # 2. Load Model\n",
        "    print(f\"\\nLoading model (PPO)...\")\n",
        "    try:\n",
        "        model = PPO.load(model_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "        # --- ADD DEBUG PRINT FOR MODEL'S EXPECTED SPACE ---\n",
        "        print(f\"DEBUG: Model's expected observation space: {model.observation_space}\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Model file not found at {model_path}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # 3. Instantiate Environment with Backtest Data and Config\n",
        "    print(\"\\nInstantiating environment...\")\n",
        "    try:\n",
        "        env_kwargs = env_config.copy()\n",
        "        env_kwargs['df'] = df_backtest\n",
        "\n",
        "        # --- Calculate dynamic parameters ---\n",
        "        stock_dim = len(df_backtest[\"tic\"].unique())\n",
        "        # --- ADD DEBUG PRINT FOR STOCK_DIM ---\n",
        "        print(f\"DEBUG: stock_dim calculated from df_backtest: {stock_dim}\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "        if stock_dim == 0:\n",
        "             print(\"Error: Zero unique tickers ('tic') found in the final backtest data slice.\")\n",
        "             return None, None\n",
        "\n",
        "        max_price = df_backtest['close'].max()\n",
        "        hmax = int(env_kwargs['initial_amount'] / (max_price * stock_dim * 0.1)) if max_price > 0 else 1 # Conservative hmax\n",
        "\n",
        "        env_kwargs['stock_dim'] = stock_dim\n",
        "        env_kwargs['hmax'] = hmax\n",
        "        env_kwargs['num_stock_shares'] = [0] * stock_dim # Initial shares are 0\n",
        "        base_buy_cost = env_kwargs.get('buy_cost_pct', [0.001])[0]\n",
        "        base_sell_cost = env_kwargs.get('sell_cost_pct', [0.001])[0]\n",
        "        env_kwargs['buy_cost_pct'] = [base_buy_cost] * stock_dim\n",
        "        env_kwargs['sell_cost_pct'] = [base_sell_cost] * stock_dim\n",
        "\n",
        "        # --- Calculate state_space ---\n",
        "        num_indicators = len(env_kwargs['tech_indicator_list'])\n",
        "        env_kwargs['state_space'] = 1 + stock_dim + stock_dim + stock_dim * num_indicators\n",
        "        env_kwargs['action_space'] = stock_dim # Pass stock_dim as action_space size indicator\n",
        "\n",
        "        # Env setup for backtesting mode\n",
        "        env_kwargs['make_plots'] = False\n",
        "        env_kwargs['print_verbosity'] = env_kwargs.get('print_verbosity', 0)\n",
        "        env_kwargs['initial'] = True\n",
        "        env_kwargs['day'] = 0\n",
        "        env_kwargs['previous_state'] = []\n",
        "        env_kwargs['model_name'] = os.path.splitext(os.path.basename(model_path))[0]\n",
        "        env_kwargs['mode'] = \"backtest\"\n",
        "        env_kwargs['iteration'] = f\"{backtest_start_date}_to_{backtest_end_date}\"\n",
        "\n",
        "        # --- ADD DEBUG PRINT BEFORE ENV INIT ---\n",
        "        print(f\"\\nDEBUG: === Parameters Passed to Env Init ===\")\n",
        "        print(f\"  stock_dim: {env_kwargs['stock_dim']}\")\n",
        "        print(f\"  num_indicators: {num_indicators}\")\n",
        "        print(f\"  state_space (calculated for init): {env_kwargs['state_space']}\")\n",
        "        print(f\"  action_space (passed to init): {env_kwargs['action_space']}\")\n",
        "        print(f\"  df shape: {env_kwargs['df'].shape}\")\n",
        "        print(f\"=========================================\\n\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "\n",
        "        # Instantiate the actual environment class defined earlier in the script\n",
        "        env = StockTradingEnv(**env_kwargs)\n",
        "\n",
        "        # --- ADD DEBUG PRINT AFTER ENV INIT ---\n",
        "        print(f\"\\nDEBUG: === Environment Spaces After Init ===\")\n",
        "        print(f\"  env.stock_dim: {env.stock_dim}\")\n",
        "        print(f\"  env.state_space (from env object): {env.state_space}\")\n",
        "        print(f\"  env.observation_space (from env object): {env.observation_space}\")\n",
        "        print(f\"  env.action_space (from env object): {env.action_space}\")\n",
        "        print(f\"=======================================\\n\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "\n",
        "\n",
        "        # --- Verify Spaces ---\n",
        "        print(\"Verifying environment and model spaces...\")\n",
        "        assert isinstance(env.observation_space, gym.spaces.Box), \"Env observation space is not Box\"\n",
        "        assert isinstance(model.observation_space, gym.spaces.Box), \"Model observation space is not Box\"\n",
        "        assert env.observation_space.shape == model.observation_space.shape, \\\n",
        "            f\"Observation space shape mismatch! Env: {env.observation_space.shape}, Model: {model.observation_space.shape}\"\n",
        "\n",
        "        assert isinstance(env.action_space, gym.spaces.Box), \"Env action space is not Box\"\n",
        "        assert isinstance(model.action_space, gym.spaces.Box), \"Model action space is not Box\"\n",
        "        assert env.action_space.shape == model.action_space.shape, \\\n",
        "            f\"Action space shape mismatch! Env: {env.action_space.shape}, Model: {model.action_space.shape}\"\n",
        "        assert np.allclose(env.action_space.low, model.action_space.low), \\\n",
        "            f\"Action space low mismatch! Env: {env.action_space.low}, Model: {model.action_space.low}\"\n",
        "        assert np.allclose(env.action_space.high, model.action_space.high), \\\n",
        "            f\"Action space high mismatch! Env: {env.action_space.high}, Model: {model.action_space.high}\"\n",
        "        print(\"Space verification successful.\")\n",
        "\n",
        "        print(\"\\nEnvironment instantiated successfully:\")\n",
        "        print(f\"  Stock Dimension: {env.stock_dim}\")\n",
        "        print(f\"  State Space Size (Declared): {env.state_space}\")\n",
        "        print(f\"  Action Space Size (Declared): {env.stock_dim}\") # Action space is Box(stock_dim)\n",
        "        print(f\"  Observation Space (Env): {env.observation_space}\")\n",
        "        print(f\"  Action Space (Env): {env.action_space}\")\n",
        "        print(f\"  Indicators: {env.tech_indicator_list}\")\n",
        "        print(f\"  Risk Indicator Col: {env.risk_indicator_col}\")\n",
        "        print(f\"  Turbulence Threshold: {env.turbulence_threshold}\")\n",
        "        print(f\"  HMAX: {env.hmax}\")\n",
        "        print(f\"  Reward Weights (T/D/C/R/Ret): {env.treynor_rate_learn:.4f} / {env.drawdown_component_learn:.4f} / {env.cost_component_learn:.4f} / {env.risk_component_learn:.4f} / {env.return_component_learn:.4f}\")\n",
        "\n",
        "\n",
        "    except AssertionError as e:\n",
        "        print(f\"\\n!!! Error: Environment space mismatch during verification: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error instantiating environment: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "    # 4. Run Simulation Loop\n",
        "    print(\"\\nStarting simulation loop...\")\n",
        "    try:\n",
        "        obs, info = env.reset(seed=42) # Use fixed seed for deterministic backtest run\n",
        "        # --- ADD DEBUG PRINT AFTER RESET ---\n",
        "        print(f\"\\nDEBUG: === Observation After First Reset ===\")\n",
        "        print(f\"  obs type: {type(obs)}\")\n",
        "        print(f\"  obs shape: {obs.shape}\")\n",
        "        print(f\"  obs dtype: {obs.dtype}\")\n",
        "        print(f\"========================================\\n\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        step_count = 0\n",
        "        num_unique_days = len(df_backtest.index.unique())\n",
        "        print(f\"Expecting approx {num_unique_days} steps for the backtest period.\")\n",
        "\n",
        "        while not (terminated or truncated):\n",
        "            # Check observation shape right before prediction\n",
        "            if obs.shape != model.observation_space.shape:\n",
        "                 print(f\"!!! ERROR: Observation shape mismatch right before model.predict()!\")\n",
        "                 print(f\"    Obs shape: {obs.shape}\")\n",
        "                 print(f\"    Model expected shape: {model.observation_space.shape}\")\n",
        "                 raise ValueError(f\"Internal shape mismatch detected before prediction step {step_count}.\")\n",
        "\n",
        "            action, _states = model.predict(obs, deterministic=deterministic)\n",
        "            obs, reward, terminated, truncated, info_step = env.step(action)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            if step_count % 100 == 0 or done:\n",
        "                current_val = env.asset_memory[-1] if env.asset_memory else env.initial_amount\n",
        "                current_date_str = env.date_memory[-1].strftime('%Y-%m-%d') if env.date_memory else \"N/A\"\n",
        "                print(f\"  Step: {env.day}/{num_unique_days}, Date: {current_date_str}, Portfolio: ${current_val:,.2f}, Reward: {reward:.4f}\")\n",
        "\n",
        "            step_count += 1\n",
        "\n",
        "            if done:\n",
        "                print(f\"Simulation loop finished. Terminated: {terminated}, Truncated: {truncated}\")\n",
        "                break\n",
        "\n",
        "            # Safety break\n",
        "            max_steps = num_unique_days * 1.1 + 10\n",
        "            if step_count > max_steps and num_unique_days > 0:\n",
        "                 print(f\"Warning: Simulation loop exceeded expected length ({num_unique_days}). Breaking at step {step_count}.\")\n",
        "                 break\n",
        "            elif step_count > 60000:\n",
        "                 print(f\"Warning: Simulation loop exceeded 60,000 iterations. Breaking.\")\n",
        "                 break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error during simulation loop: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Try to salvage results up to this point\n",
        "        results_df = env.save_asset_memory() if 'env' in locals() and hasattr(env, 'save_asset_memory') else pd.DataFrame()\n",
        "        return results_df, {\"error\": f\"Simulation error: {e}\"}\n",
        "\n",
        "\n",
        "    # 5. Get Results & Calculate Metrics\n",
        "    print(\"\\nCalculating performance metrics...\")\n",
        "    try:\n",
        "        results_df = env.save_asset_memory() # Method defined in the pasted class\n",
        "\n",
        "        if results_df.empty or len(results_df) <= 1:\n",
        "            print(\"Error: Not enough history recorded by the environment to calculate metrics.\")\n",
        "            # Return empty results if calculation isn't possible\n",
        "            return pd.DataFrame(), {\"error\": \"Insufficient data for metrics\"}\n",
        "\n",
        "        # results_df index should already be 'date' from save_asset_memory\n",
        "        if not isinstance(results_df.index, pd.DatetimeIndex):\n",
        "             print(\"Warning: Results DataFrame index is not DatetimeIndex. Attempting conversion.\")\n",
        "             try:\n",
        "                 results_df.index = pd.to_datetime(results_df.index)\n",
        "                 results_df.sort_index(inplace=True)\n",
        "             except Exception as e:\n",
        "                 print(f\"Error converting index to DatetimeIndex: {e}. Metrics requiring time series may fail.\")\n",
        "                 # Continue without datetime index if conversion fails\n",
        "\n",
        "\n",
        "        metrics = {}\n",
        "        portfolio_values = results_df['account_value']\n",
        "        initial_portfolio_value = portfolio_values.iloc[0]\n",
        "        final_portfolio_value = portfolio_values.iloc[-1]\n",
        "\n",
        "        # Basic metrics calculation\n",
        "        metrics['Start Date'] = results_df.index[0].strftime('%Y-%m-%d') if isinstance(results_df.index, pd.DatetimeIndex) else str(results_df.index[0])\n",
        "        metrics['End Date'] = results_df.index[-1].strftime('%Y-%m-%d') if isinstance(results_df.index, pd.DatetimeIndex) else str(results_df.index[-1])\n",
        "        metrics['Initial Portfolio Value ($)'] = initial_portfolio_value\n",
        "        metrics['Final Portfolio Value ($)'] = final_portfolio_value\n",
        "        metrics['Total Return (%)'] = ((final_portfolio_value - initial_portfolio_value) / initial_portfolio_value) * 100 if initial_portfolio_value != 0 else 0\n",
        "        metrics['Total Steps'] = step_count -1 # env.day ends one step ahead\n",
        "        metrics['Total Trades'] = env.trades\n",
        "        metrics['Total Transaction Cost ($)'] = env.cost\n",
        "\n",
        "        # Time-series based metrics\n",
        "        returns = portfolio_values.pct_change().dropna()\n",
        "        returns.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "        duration_years = np.nan\n",
        "        if isinstance(results_df.index, pd.DatetimeIndex) and len(results_df.index) > 1:\n",
        "             duration_years = (results_df.index[-1] - results_df.index[0]).days / 365.25\n",
        "\n",
        "        if not returns.empty and len(returns) > 1:\n",
        "            std_dev = returns.std()\n",
        "            metrics['Volatility (Ann.) (%)'] = (std_dev * np.sqrt(252)) * 100 if std_dev > 0 else 0\n",
        "            metrics['Sharpe Ratio (Ann.)'] = (returns.mean() / std_dev) * np.sqrt(252) if std_dev > 0 else 0\n",
        "\n",
        "            rolling_max = portfolio_values.cummax()\n",
        "            daily_drawdown = portfolio_values / rolling_max - 1.0\n",
        "            max_drawdown = daily_drawdown.min()\n",
        "            metrics['Max Drawdown (%)'] = max_drawdown * 100\n",
        "\n",
        "            annualized_return = 0\n",
        "            if duration_years > 0 and initial_portfolio_value != 0:\n",
        "                 annualized_return = ((final_portfolio_value / initial_portfolio_value) ** (1 / duration_years)) - 1\n",
        "            metrics['Annualized Return (%)'] = annualized_return * 100\n",
        "            metrics['Calmar Ratio'] = (annualized_return / abs(max_drawdown)) if max_drawdown < -1e-9 else np.nan # Avoid division by zero\n",
        "\n",
        "\n",
        "            # Quantstats calculation (requires DatetimeIndex)\n",
        "            if QUANTSTATS_AVAILABLE and isinstance(results_df.index, pd.DatetimeIndex):\n",
        "                try:\n",
        "                    qs_returns = returns.copy()\n",
        "                    qs_returns.name = \"Strategy\"\n",
        "                    print(\"Calculating extended metrics using quantstats...\")\n",
        "                    try:\n",
        "                         qs_metrics_dict = quantstats.reports.metrics(qs_returns, mode='basic', display=False).iloc[0].to_dict()\n",
        "                         qs_metrics_dict = {k.replace(' [%]', '').replace(' (%)','').strip(): v for k, v in qs_metrics_dict.items()}\n",
        "                         metrics.update(qs_metrics_dict)\n",
        "                         print(\"Quantstats basic metrics calculated.\")\n",
        "                    except Exception as qs_basic_e:\n",
        "                         print(f\"Warning: quantstats basic calculation failed: {qs_basic_e}. Trying simple stats.\")\n",
        "                         try:\n",
        "                             metrics['QS Sharpe'] = quantstats.stats.sharpe(qs_returns, annualize=True)\n",
        "                             metrics['QS Sortino'] = quantstats.stats.sortino(qs_returns, annualize=True)\n",
        "                             metrics['QS Max Drawdown'] = quantstats.stats.max_drawdown(qs_returns) * 100\n",
        "                             metrics['QS Volatility (Ann.)'] = quantstats.stats.volatility(qs_returns, annualize=True) * 100\n",
        "                             print(\"Quantstats simple metrics calculated.\")\n",
        "                         except Exception as qs_simple_e:\n",
        "                             print(f\"Warning: quantstats simple calculation also failed: {qs_simple_e}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: quantstats calculation failed: {e}\")\n",
        "            elif QUANTSTATS_AVAILABLE:\n",
        "                 print(\"Warning: Index is not DatetimeIndex. Skipping quantstats.\")\n",
        "\n",
        "        else: # Not enough data for time-series metrics\n",
        "            print(\"Warning: Could not calculate performance ratios (empty/single-point returns series).\")\n",
        "            metrics.update({\n",
        "                'Volatility (Ann.) (%)': 0, 'Sharpe Ratio (Ann.)': 0,\n",
        "                'Max Drawdown (%)': 0,\n",
        "                'Annualized Return (%)': metrics.get('Total Return (%)', 0) if duration_years <= 0 else 0,\n",
        "                'Calmar Ratio': np.nan\n",
        "            })\n",
        "\n",
        "        print(\"\\n--- Backtest Metrics Summary ---\")\n",
        "        key_metrics_to_print = [\n",
        "            'Initial Portfolio Value ($)', 'Final Portfolio Value ($)', 'Total Return (%)',\n",
        "            'Annualized Return (%)', 'Sharpe Ratio (Ann.)', 'Max Drawdown (%)',\n",
        "            'Volatility (Ann.) (%)', 'Calmar Ratio', 'Total Trades', 'Total Transaction Cost ($)'\n",
        "        ]\n",
        "        qs_keys = ['Sharpe', 'Sortino', 'Max Drawdown', 'Volatility (ann.)', 'Avg. Drawdown', 'Win Rate', 'Best Day', 'Worst Day', 'Avg. Trade', 'Profit Factor']\n",
        "        key_metrics_to_print.extend([k for k in qs_keys if k in metrics and k not in key_metrics_to_print]) # Add unique QS keys\n",
        "\n",
        "        for key in key_metrics_to_print:\n",
        "             if key in metrics:\n",
        "                 value = metrics[key]\n",
        "                 try:\n",
        "                     if pd.isna(value): print(f\"  {key}: NaN\")\n",
        "                     else: print(f\"  {key}: {float(value):,.4f}\")\n",
        "                 except (ValueError, TypeError, OverflowError):\n",
        "                     print(f\"  {key}: {value}\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error calculating or displaying metrics: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        metrics = {\"error\": f\"Metrics calculation error: {e}\"}\n",
        "        # Try to return results_df even if metrics fail\n",
        "        results_df = env.save_asset_memory() if 'env' in locals() and hasattr(env, 'save_asset_memory') else pd.DataFrame()\n",
        "        return results_df, metrics\n",
        "\n",
        "    # 6. Report/Visualize and Save Outputs\n",
        "    print(\"\\nGenerating plot and saving results...\")\n",
        "    try:\n",
        "        model_filename_base = os.path.splitext(os.path.basename(model_path))[0]\n",
        "        output_prefix = f\"backtest_{model_filename_base}_{backtest_start_date}_to_{backtest_end_date}\"\n",
        "\n",
        "        # --- Plot Portfolio Value ---\n",
        "        if not portfolio_values.empty:\n",
        "             plt.figure(figsize=(12, 6))\n",
        "             portfolio_values.plot(title=f'Portfolio Value Over Time\\n({backtest_start_date} to {backtest_end_date})')\n",
        "             plt.xlabel(\"Date\")\n",
        "             plt.ylabel(\"Portfolio Value ($)\")\n",
        "             plt.grid(True)\n",
        "             plt.tight_layout()\n",
        "             plot_filename = f'{output_prefix}_portfolio_value.png'\n",
        "             plt.savefig(plot_filename)\n",
        "             print(f\"Saved portfolio value plot to: {plot_filename}\")\n",
        "             plt.close()\n",
        "        else:\n",
        "             print(\"Skipping plot generation: No portfolio values.\")\n",
        "\n",
        "\n",
        "        # --- Save Results CSV ---\n",
        "        results_csv_filename = f'{output_prefix}_results.csv'\n",
        "        if not results_df.empty:\n",
        "             results_df.reset_index().to_csv(results_csv_filename, index=False)\n",
        "             print(f\"Saved detailed results (account value) to: {results_csv_filename}\")\n",
        "        else:\n",
        "             print(\"Skipping results CSV saving: Results DataFrame is empty.\")\n",
        "\n",
        "        # --- Save Metrics JSON ---\n",
        "        metrics_json_filename = f'{output_prefix}_metrics.json'\n",
        "        serializable_metrics = {}\n",
        "        for k, v in metrics.items():\n",
        "            if isinstance(v, (np.integer, np.int64)): serializable_metrics[k] = int(v)\n",
        "            elif isinstance(v, (np.floating, np.float64)): serializable_metrics[k] = float(v) if not pd.isna(v) else None\n",
        "            elif isinstance(v, (np.ndarray,)): serializable_metrics[k] = v.tolist()\n",
        "            elif isinstance(v, (pd.Timestamp)): serializable_metrics[k] = v.strftime('%Y-%m-%d')\n",
        "            elif pd.isna(v): serializable_metrics[k] = None\n",
        "            else: serializable_metrics[k] = v\n",
        "\n",
        "        with open(metrics_json_filename, 'w') as f:\n",
        "            json.dump(serializable_metrics, f, indent=4)\n",
        "        print(f\"Saved performance metrics to: {metrics_json_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error during plotting or saving files: {e}\")\n",
        "\n",
        "    if hasattr(env, 'close'):\n",
        "        env.close()\n",
        "\n",
        "    return results_df, metrics\n",
        "\n",
        "\n",
        "# --- Main Execution Block (`if __name__ == \"__main__\":`) ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # <<< --- PASTE YOUR StockTradingEnv CLASS DEFINITION ABOVE --- <<<\n",
        "\n",
        "    # <<< --- CHANGE THESE VALUES --- <<<\n",
        "    # --- Core Configuration ---\n",
        "    DATA_PATH = \"/content/indian_stock_data.csv\"\n",
        "    MODEL_PATH = \"/content/best_optuna_ppo_model.zip\" # Assuming this is the model expecting shape (97,) i.e., 8 tickers\n",
        "    BACKTEST_START_DATE = \"2015-01-01\"\n",
        "    BACKTEST_END_DATE = \"2023-12-31\"\n",
        "\n",
        "    # --- Environment Configuration (Must match the settings used for training the specific model) ---\n",
        "    INITIAL_AMOUNT = 100000\n",
        "    TURBULENCE_THRESHOLD = 100.0 # Adjust if needed\n",
        "    REWARD_SCALING = 1e-4      # Adjust if needed\n",
        "    BUY_COST = 0.001\n",
        "    SELL_COST = 0.001\n",
        "    # This list MUST match the indicators used when the model (expecting 97,) was trained\n",
        "    INDICATORS = [\"volume\", \"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\", \"turbulence\"]\n",
        "    RISK_INDICATOR = \"turbulence\"\n",
        "\n",
        "    # ** CRITICAL: Reward Weights ** - Should match the loaded model's training\n",
        "    W_TREYNOR = 0.4013949773199673\n",
        "    W_DRAWDOWN = 2.9068009015669793\n",
        "    W_COST = 4.994821708372366\n",
        "    W_RISK = 2.947383762136368\n",
        "    W_RETURN = 4.862429692924584\n",
        "    # >>> --- END OF VALUES TO CHANGE --- >>>\n",
        "\n",
        "    # --- Prepare Environment Configuration Dictionary ---\n",
        "    env_configuration = {\n",
        "        \"initial_amount\": INITIAL_AMOUNT,\n",
        "        \"reward_scaling\": REWARD_SCALING,\n",
        "        \"tech_indicator_list\": INDICATORS,\n",
        "        \"turbulence_threshold\": TURBULENCE_THRESHOLD,\n",
        "        \"risk_indicator_col\": RISK_INDICATOR,\n",
        "        \"treynor_rate_learn\": W_TREYNOR,\n",
        "        \"drawdown_component_learn\": W_DRAWDOWN,\n",
        "        \"cost_component_learn\": W_COST,\n",
        "        \"risk_component_learn\": W_RISK,\n",
        "        \"return_component_learn\": W_RETURN,\n",
        "        \"buy_cost_pct\": [BUY_COST], # Provide as list, resized in run_backtest\n",
        "        \"sell_cost_pct\": [SELL_COST],# Provide as list, resized in run_backtest\n",
        "        \"print_verbosity\": 1,\n",
        "    }\n",
        "\n",
        "    # --- Run the Backtest ---\n",
        "    results, performance_metrics = run_backtest(\n",
        "        data_path=DATA_PATH,\n",
        "        model_path=MODEL_PATH,\n",
        "        env_config=env_configuration,\n",
        "        backtest_start_date=BACKTEST_START_DATE,\n",
        "        backtest_end_date=BACKTEST_END_DATE,\n",
        "        deterministic=True\n",
        "    )\n",
        "\n",
        "    # --- Final Status ---\n",
        "    if results is not None and performance_metrics is not None and 'error' not in performance_metrics:\n",
        "        print(\"\\nBacktest finished successfully.\")\n",
        "        model_filename_base = os.path.splitext(os.path.basename(MODEL_PATH))[0]\n",
        "        print(f\"Results saved with prefix: backtest_{model_filename_base}_{BACKTEST_START_DATE}_to_{BACKTEST_END_DATE}\")\n",
        "    else:\n",
        "        print(\"\\nBacktest failed or encountered errors.\")\n",
        "        if performance_metrics and 'error' in performance_metrics:\n",
        "            print(f\"Error details: {performance_metrics['error']}\")\n",
        "        elif results is None:\n",
        "             print(\"Backtest function returned None, indicating failure during setup.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9TALgk7FSxsI",
        "outputId": "59463efd-1f13-4cb7-e2da-8d42b286df64"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Backtest ---\n",
            "Data: /content/indian_stock_data.csv\n",
            "Model: /content/best_optuna_ppo_model.zip\n",
            "Period: 2015-01-01 to 2023-12-31\n",
            "Loading and preparing data...\n",
            "Filtering data to include only the 8 tickers the loaded model expects (based on error).\n",
            "Expected training tickers: ['ADANIENT.NS', 'HDFCBANK.NS', 'ICICIBANK.NS', 'INFY.NS', 'RELIANCE.NS', 'SBIN.NS', 'TATAMOTORS.NS', 'TCS.NS']\n",
            "Data shape after filtering by training tickers: (15188, 18)\n",
            "DEBUG: df_backtest shape after all filtering: (5420, 18)\n",
            "DEBUG: Unique tickers in df_backtest: ['ADANIENT.NS' 'HDFCBANK.NS' 'ICICIBANK.NS' 'INFY.NS' 'RELIANCE.NS'\n",
            " 'SBIN.NS' 'TATAMOTORS.NS' 'TCS.NS']\n",
            "Backtest data prepared. Shape: (5420, 18), Date range: 2015-01-02 to 2017-10-06\n",
            "Index reset based on date groups. Index range: 0 to 677\n",
            "\n",
            "Loading model (PPO)...\n",
            "Model loaded successfully.\n",
            "DEBUG: Model's expected observation space: Box(-inf, inf, (97,), float32)\n",
            "\n",
            "Instantiating environment...\n",
            "DEBUG: stock_dim calculated from df_backtest: 8\n",
            "\n",
            "DEBUG: === Parameters Passed to Env Init ===\n",
            "  stock_dim: 8\n",
            "  num_indicators: 10\n",
            "  state_space (calculated for init): 97\n",
            "  action_space (passed to init): 8\n",
            "  df shape: (5420, 18)\n",
            "=========================================\n",
            "\n",
            "\n",
            "DEBUG: === Environment Spaces After Init ===\n",
            "  env.stock_dim: 8\n",
            "  env.state_space (from env object): 97\n",
            "  env.observation_space (from env object): Box(-inf, inf, (97,), float32)\n",
            "  env.action_space (from env object): Box(-1.0, 1.0, (8,), float32)\n",
            "=======================================\n",
            "\n",
            "Verifying environment and model spaces...\n",
            "Space verification successful.\n",
            "\n",
            "Environment instantiated successfully:\n",
            "  Stock Dimension: 8\n",
            "  State Space Size (Declared): 97\n",
            "  Action Space Size (Declared): 8\n",
            "  Observation Space (Env): Box(-inf, inf, (97,), float32)\n",
            "  Action Space (Env): Box(-1.0, 1.0, (8,), float32)\n",
            "  Indicators: ['volume', 'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'turbulence']\n",
            "  Risk Indicator Col: turbulence\n",
            "  Turbulence Threshold: 100.0\n",
            "  HMAX: 108\n",
            "  Reward Weights (T/D/C/R/Ret): 0.4014 / 2.9068 / 4.9948 / 2.9474 / 4.8624\n",
            "\n",
            "Starting simulation loop...\n",
            "\n",
            "DEBUG: === Observation After First Reset ===\n",
            "  obs type: <class 'numpy.ndarray'>\n",
            "  obs shape: (97,)\n",
            "  obs dtype: float32\n",
            "========================================\n",
            "\n",
            "Expecting approx 678 steps for the backtest period.\n",
            "  Step: 1/678, Date: 2015-01-05, Portfolio: $99,059.81, Reward: -0.0000\n",
            "Day: 20, Date: 2015-02-02 00:00:00, Portfolio: 111,902.40, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 40, Date: 2015-03-03 00:00:00, Portfolio: 112,062.16, Reward: -0.0000, StepCost: 0.29\n",
            "Day: 60, Date: 2015-04-01 00:00:00, Portfolio: 106,881.08, Reward: -0.0000, StepCost: 0.26\n",
            "Day: 80, Date: 2015-05-06 00:00:00, Portfolio: 100,421.06, Reward: -0.0000, StepCost: 0.00\n",
            "Turbulence Alert! Day 100 (276.30 > 100.0). Selling all assets.\n",
            "Day: 100, Date: 2015-06-03 00:00:00, Portfolio: 104,250.84, Reward: -0.0008, StepCost: 104.79\n",
            "  Step: 101/678, Date: 2015-06-04, Portfolio: $105,116.66, Reward: -0.0000\n",
            "Day: 120, Date: 2015-07-01 00:00:00, Portfolio: 111,031.81, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 140, Date: 2015-07-29 00:00:00, Portfolio: 115,599.29, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 160, Date: 2015-08-26 00:00:00, Portfolio: 105,736.02, Reward: -0.0000, StepCost: 0.36\n",
            "Day: 180, Date: 2015-09-24 00:00:00, Portfolio: 109,658.10, Reward: -0.0000, StepCost: 0.23\n",
            "Day: 200, Date: 2015-10-27 00:00:00, Portfolio: 115,830.73, Reward: 0.0000, StepCost: 0.24\n",
            "  Step: 201/678, Date: 2015-10-28, Portfolio: $115,882.56, Reward: -0.0000\n",
            "Day: 220, Date: 2015-11-27 00:00:00, Portfolio: 112,514.21, Reward: -0.0000, StepCost: 0.22\n",
            "Day: 240, Date: 2015-12-28 00:00:00, Portfolio: 112,292.90, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 260, Date: 2016-01-27 00:00:00, Portfolio: 107,968.06, Reward: -0.0000, StepCost: 0.20\n",
            "Day: 280, Date: 2016-02-24 00:00:00, Portfolio: 99,019.83, Reward: -0.0000, StepCost: 0.32\n",
            "Day: 300, Date: 2016-03-28 00:00:00, Portfolio: 109,196.90, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 301/678, Date: 2016-03-29, Portfolio: $109,851.59, Reward: -0.0000\n",
            "Day: 320, Date: 2016-04-28 00:00:00, Portfolio: 116,088.47, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 340, Date: 2016-05-26 00:00:00, Portfolio: 123,296.38, Reward: 0.0000, StepCost: 0.00\n",
            "Day: 360, Date: 2016-06-23 00:00:00, Portfolio: 124,021.30, Reward: 0.0000, StepCost: 0.00\n",
            "Day: 380, Date: 2016-07-22 00:00:00, Portfolio: 129,302.66, Reward: 0.0000, StepCost: 0.00\n",
            "Day: 400, Date: 2016-08-23 00:00:00, Portfolio: 131,469.98, Reward: -0.0000, StepCost: 0.32\n",
            "  Step: 401/678, Date: 2016-08-24, Portfolio: $132,554.34, Reward: 0.0000\n",
            "Day: 420, Date: 2016-09-22 00:00:00, Portfolio: 137,277.91, Reward: 0.0000, StepCost: 0.00\n",
            "Day: 440, Date: 2016-10-24 00:00:00, Portfolio: 132,732.73, Reward: -0.0000, StepCost: 0.23\n",
            "Day: 460, Date: 2016-11-23 00:00:00, Portfolio: 124,473.56, Reward: -0.0000, StepCost: 0.23\n",
            "Day: 480, Date: 2016-12-21 00:00:00, Portfolio: 123,974.91, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 500, Date: 2017-01-18 00:00:00, Portfolio: 130,535.18, Reward: -0.0000, StepCost: 0.22\n",
            "  Step: 501/678, Date: 2017-01-19, Portfolio: $129,874.90, Reward: -0.0000\n",
            "Day: 520, Date: 2017-02-16 00:00:00, Portfolio: 139,468.16, Reward: 0.0000, StepCost: 0.30\n",
            "Turbulence Alert! Day 524 (117.78 > 100.0). Selling all assets.\n",
            "Day: 540, Date: 2017-03-20 00:00:00, Portfolio: 152,251.92, Reward: 0.0000, StepCost: 0.00\n",
            "Day: 560, Date: 2017-04-19 00:00:00, Portfolio: 153,622.23, Reward: -0.0000, StepCost: 0.27\n",
            "Day: 580, Date: 2017-05-18 00:00:00, Portfolio: 165,079.27, Reward: -0.0000, StepCost: 0.27\n",
            "Day: 600, Date: 2017-06-15 00:00:00, Portfolio: 176,445.28, Reward: -0.0000, StepCost: 0.29\n",
            "  Step: 601/678, Date: 2017-06-16, Portfolio: $176,964.28, Reward: -0.0000\n",
            "Day: 620, Date: 2017-07-14 00:00:00, Portfolio: 179,273.36, Reward: -0.0000, StepCost: 0.28\n",
            "Day: 640, Date: 2017-08-11 00:00:00, Portfolio: 186,627.34, Reward: -0.0000, StepCost: 0.50\n",
            "Day: 660, Date: 2017-09-12 00:00:00, Portfolio: 195,805.14, Reward: 0.0000, StepCost: 0.00\n",
            "DEBUG: State Length Mismatch in step!\n",
            "  Day: 677, Date: 2017-10-06 00:00:00\n",
            "  Expected state_space: 97\n",
            "  Actual state length: 53\n",
            "\n",
            "!!! Error during simulation loop: State length mismatch after step: Expected 97, got 53\n",
            "\n",
            "Backtest failed or encountered errors.\n",
            "Error details: Simulation error: State length mismatch after step: Expected 97, got 53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-16-f88d97c20470>\", line 876, in run_backtest\n",
            "    obs, reward, terminated, truncated, info_step = env.step(action)\n",
            "                                                    ^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-16-f88d97c20470>\", line 478, in step\n",
            "    raise AssertionError(f\"State length mismatch after step: Expected {self.state_space}, got {len(self.state)}\")\n",
            "AssertionError: State length mismatch after step: Expected 97, got 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Backtesting Function (with Debug prints and FFill) ---\n",
        "def run_backtest(\n",
        "    data_path: str,\n",
        "    model_path: str,\n",
        "    env_config: dict, # Dictionary with ALL required env init args derived from hardcoded vars\n",
        "    backtest_start_date: str,\n",
        "    backtest_end_date: str,\n",
        "    deterministic: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs a backtest for a trained RL agent using the provided StockTradingEnv.\n",
        "    Includes debug prints and forward filling for missing data.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Backtest ---\")\n",
        "    print(f\"Data: {data_path}\")\n",
        "    print(f\"Model: {model_path}\")\n",
        "    print(f\"Period: {backtest_start_date} to {backtest_end_date}\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    print(\"Loading and preparing data...\")\n",
        "    try:\n",
        "        if data_path.endswith('.csv'):\n",
        "            df_full = pd.read_csv(data_path)\n",
        "        elif data_path.endswith('.parquet'):\n",
        "            df_full = pd.read_parquet(data_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported data file format: {data_path}\")\n",
        "\n",
        "        # --- Preprocessing & Basic Filtering ---\n",
        "        if 'date' in df_full.columns:\n",
        "             df_full['date'] = pd.to_datetime(df_full['date'])\n",
        "        else:\n",
        "            print(\"Error: 'date' column not found in the data.\")\n",
        "            return None, None\n",
        "\n",
        "        # --- Filter by Training Tickers FIRST ---\n",
        "        TRAINING_TICKERS = ['ADANIENT.NS', 'HDFCBANK.NS', 'ICICIBANK.NS', 'INFY.NS', 'RELIANCE.NS', 'SBIN.NS', 'TATAMOTORS.NS', 'TCS.NS']\n",
        "        print(f\"Filtering data to include only the {len(TRAINING_TICKERS)} tickers the loaded model expects.\")\n",
        "        print(f\"Expected training tickers: {TRAINING_TICKERS}\")\n",
        "        df_full = df_full[df_full['tic'].isin(TRAINING_TICKERS)].copy()\n",
        "        if df_full.empty:\n",
        "            print(f\"Error: No data found for the specified {len(TRAINING_TICKERS)} tickers in {data_path}.\")\n",
        "            return None, None\n",
        "        print(f\"Data shape after filtering by training tickers: {df_full.shape}\")\n",
        "\n",
        "        # --- Filter by Date ---\n",
        "        df_backtest = df_full[\n",
        "            (df_full['date'] >= backtest_start_date) &\n",
        "            (df_full['date'] <= backtest_end_date)\n",
        "        ].copy()\n",
        "        if df_backtest.empty:\n",
        "            print(\"Error: No data available for the specified backtest period after filtering by tickers.\")\n",
        "            return None, None\n",
        "        print(f\"Data shape after filtering by date: {df_backtest.shape}\")\n",
        "\n",
        "        # --- >>> HANDLE MISSING DATA with Forward Fill <<< ---\n",
        "        print(\"Attempting to forward fill missing data points within each ticker group...\")\n",
        "        # We need a full date range for the backtest period to ensure ffill works across gaps\n",
        "        # Create a multi-index with all dates and all training tickers\n",
        "        all_dates = pd.date_range(start=backtest_start_date, end=backtest_end_date, freq='B') # Use business days or daily ('D')\n",
        "        multi_index = pd.MultiIndex.from_product([all_dates, TRAINING_TICKERS], names=['date', 'tic'])\n",
        "        # Reindex the dataframe to this full index, this will introduce NaNs where data was missing\n",
        "        df_backtest_reindexed = df_backtest.set_index(['date', 'tic']).reindex(multi_index)\n",
        "\n",
        "        # Now group by ticker (level 1 of multi-index) and forward fill\n",
        "        df_backtest_filled = df_backtest_reindexed.groupby(level='tic').ffill()\n",
        "\n",
        "        # Optional: Handle NaNs remaining at the very beginning of a ticker's history\n",
        "        # Example: fill remaining NaNs with 0 (use cautiously, might be better to drop)\n",
        "        # df_backtest_filled.fillna(0, inplace=True)\n",
        "        # More robust: Drop any dates where *any* ticker still has NaN after ffill\n",
        "        # This usually means data wasn't available at the start of the backtest period for that ticker\n",
        "        df_backtest_filled.dropna(inplace=True)\n",
        "        print(f\"Forward fill complete. Shape after ffill and dropna: {df_backtest_filled.shape}\")\n",
        "\n",
        "        # Reset index to prepare for the environment\n",
        "        df_backtest = df_backtest_filled.reset_index()\n",
        "        # --- >>> END FORWARD FILL BLOCK <<< ---\n",
        "\n",
        "\n",
        "        # --- Prepare Index for Environment ---\n",
        "        # Ensure data is sorted correctly for grouping and env stepping\n",
        "        df_backtest.sort_values(by=['date', 'tic'], inplace=True)\n",
        "\n",
        "        # Verify data completeness after processing\n",
        "        rows_per_day = df_backtest.groupby('date').size()\n",
        "        incomplete_days = rows_per_day[rows_per_day != len(TRAINING_TICKERS)]\n",
        "        if not incomplete_days.empty:\n",
        "            print(f\"FATAL ERROR: After processing, some days still have incomplete data for the {len(TRAINING_TICKERS)} tickers:\")\n",
        "            print(incomplete_days.head())\n",
        "            # This shouldn't happen after reindexing, ffill, and dropna unless the dropna removed entire days\n",
        "            return None, None\n",
        "\n",
        "        # Create the 'date_id' index for the environment\n",
        "        df_backtest['date_id'] = df_backtest.groupby('date').ngroup()\n",
        "        df_backtest.set_index('date_id', inplace=True)\n",
        "\n",
        "\n",
        "        # --- Final Data Checks ---\n",
        "        print(f\"DEBUG: df_backtest shape after all processing: {df_backtest.shape}\")\n",
        "        print(f\"DEBUG: Unique tickers in df_backtest: {df_backtest['tic'].unique()}\")\n",
        "        assert set(df_backtest['tic'].unique()) == set(TRAINING_TICKERS), \"Tickers in final df don't match training tickers\"\n",
        "        assert len(df_backtest['tic'].unique()) == len(TRAINING_TICKERS), \"Final stock_dim doesn't match expected\"\n",
        "\n",
        "\n",
        "        # --- Sanity Check: Ensure required columns are present ---\n",
        "        required_cols = set(env_config.get('tech_indicator_list', []))\n",
        "        required_cols.update(['close', 'tic', 'date'])\n",
        "        risk_col = env_config.get('risk_indicator_col', None)\n",
        "        if risk_col and risk_col not in required_cols: required_cols.add(risk_col)\n",
        "        missing_cols = required_cols - set(df_backtest.columns)\n",
        "        if missing_cols:\n",
        "            print(f\"Error: Missing required columns in backtest data after processing: {missing_cols}\")\n",
        "            return None, None\n",
        "\n",
        "        print(f\"Backtest data prepared. Final Shape: {df_backtest.shape}, Date range: {df_backtest['date'].min().date()} to {df_backtest['date'].max().date()}\")\n",
        "        print(f\"Index reset based on date groups. Index range: {df_backtest.index.min()} to {df_backtest.index.max()}\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Data file not found at {data_path}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or preprocessing data: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "    # 2. Load Model\n",
        "    # ... (Keep model loading and DEBUG print) ...\n",
        "    print(f\"\\nLoading model (PPO)...\")\n",
        "    try:\n",
        "        model = PPO.load(model_path)\n",
        "        print(\"Model loaded successfully.\")\n",
        "        # --- ADD DEBUG PRINT FOR MODEL'S EXPECTED SPACE ---\n",
        "        print(f\"DEBUG: Model's expected observation space: {model.observation_space}\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Model file not found at {model_path}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    # 3. Instantiate Environment with Backtest Data and Config\n",
        "    # ... (Keep env instantiation, DEBUG prints, and assertions) ...\n",
        "    print(\"\\nInstantiating environment...\")\n",
        "    try:\n",
        "        env_kwargs = env_config.copy()\n",
        "        env_kwargs['df'] = df_backtest # Use the processed df_backtest\n",
        "\n",
        "        # --- Calculate dynamic parameters ---\n",
        "        stock_dim = len(df_backtest[\"tic\"].unique()) # Should be 8 now\n",
        "        # --- ADD DEBUG PRINT FOR STOCK_DIM ---\n",
        "        print(f\"DEBUG: stock_dim calculated from final df_backtest: {stock_dim}\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "        if stock_dim != len(TRAINING_TICKERS):\n",
        "             print(f\"FATAL ERROR: stock_dim ({stock_dim}) does not match expected ({len(TRAINING_TICKERS)}) after processing.\")\n",
        "             return None, None\n",
        "\n",
        "        max_price = df_backtest['close'].max()\n",
        "        hmax = int(env_kwargs['initial_amount'] / (max_price * stock_dim * 0.1)) if max_price > 0 else 1\n",
        "\n",
        "        env_kwargs['stock_dim'] = stock_dim\n",
        "        env_kwargs['hmax'] = hmax\n",
        "        env_kwargs['num_stock_shares'] = [0] * stock_dim\n",
        "        base_buy_cost = env_kwargs.get('buy_cost_pct', [0.001])[0]\n",
        "        base_sell_cost = env_kwargs.get('sell_cost_pct', [0.001])[0]\n",
        "        env_kwargs['buy_cost_pct'] = [base_buy_cost] * stock_dim\n",
        "        env_kwargs['sell_cost_pct'] = [base_sell_cost] * stock_dim\n",
        "\n",
        "        # --- Calculate state_space ---\n",
        "        num_indicators = len(env_kwargs['tech_indicator_list'])\n",
        "        env_kwargs['state_space'] = 1 + stock_dim + stock_dim + stock_dim * num_indicators # Should be 97\n",
        "        env_kwargs['action_space'] = stock_dim # Action space size indicator\n",
        "\n",
        "        # Env setup for backtesting mode\n",
        "        env_kwargs['make_plots'] = False\n",
        "        env_kwargs['print_verbosity'] = env_kwargs.get('print_verbosity', 0)\n",
        "        env_kwargs['initial'] = True\n",
        "        env_kwargs['day'] = 0\n",
        "        env_kwargs['previous_state'] = []\n",
        "        env_kwargs['model_name'] = os.path.splitext(os.path.basename(model_path))[0]\n",
        "        env_kwargs['mode'] = \"backtest\"\n",
        "        env_kwargs['iteration'] = f\"{backtest_start_date}_to_{backtest_end_date}\"\n",
        "\n",
        "        # --- ADD DEBUG PRINT BEFORE ENV INIT ---\n",
        "        print(f\"\\nDEBUG: === Parameters Passed to Env Init ===\")\n",
        "        print(f\"  stock_dim: {env_kwargs['stock_dim']}\")\n",
        "        print(f\"  num_indicators: {num_indicators}\")\n",
        "        print(f\"  state_space (calculated for init): {env_kwargs['state_space']}\")\n",
        "        print(f\"  action_space (passed to init): {env_kwargs['action_space']}\")\n",
        "        print(f\"  df shape: {env_kwargs['df'].shape}\")\n",
        "        print(f\"=========================================\\n\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "\n",
        "        env = StockTradingEnv(**env_kwargs)\n",
        "\n",
        "        # --- ADD DEBUG PRINT AFTER ENV INIT ---\n",
        "        print(f\"\\nDEBUG: === Environment Spaces After Init ===\")\n",
        "        print(f\"  env.stock_dim: {env.stock_dim}\")\n",
        "        print(f\"  env.state_space (from env object): {env.state_space}\")\n",
        "        print(f\"  env.observation_space (from env object): {env.observation_space}\")\n",
        "        print(f\"  env.action_space (from env object): {env.action_space}\")\n",
        "        print(f\"=======================================\\n\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "\n",
        "        # --- Verify Spaces ---\n",
        "        print(\"Verifying environment and model spaces...\")\n",
        "        # ... (keep assertions) ...\n",
        "        assert env.observation_space.shape == model.observation_space.shape, \\\n",
        "            f\"Observation space shape mismatch! Env: {env.observation_space.shape}, Model: {model.observation_space.shape}\"\n",
        "        assert env.action_space.shape == model.action_space.shape, \\\n",
        "            f\"Action space shape mismatch! Env: {env.action_space.shape}, Model: {model.action_space.shape}\"\n",
        "        print(\"Space verification successful.\")\n",
        "\n",
        "        print(\"\\nEnvironment instantiated successfully:\")\n",
        "        # ... (keep success prints) ...\n",
        "\n",
        "    except AssertionError as e:\n",
        "        print(f\"\\n!!! Error: Environment space mismatch during verification: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error instantiating environment: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    # 4. Run Simulation Loop\n",
        "    # ... (Keep simulation loop, DEBUG print after reset, and error handling) ...\n",
        "    print(\"\\nStarting simulation loop...\")\n",
        "    try:\n",
        "        obs, info = env.reset(seed=42)\n",
        "        # --- ADD DEBUG PRINT AFTER RESET ---\n",
        "        print(f\"\\nDEBUG: === Observation After First Reset ===\")\n",
        "        print(f\"  obs type: {type(obs)}\")\n",
        "        print(f\"  obs shape: {obs.shape}\")\n",
        "        print(f\"  obs dtype: {obs.dtype}\")\n",
        "        print(f\"========================================\\n\")\n",
        "        # --- END DEBUG PRINT ---\n",
        "\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        step_count = 0\n",
        "        num_unique_days = len(df_backtest.index.unique())\n",
        "        print(f\"Expecting approx {num_unique_days} steps for the backtest period.\")\n",
        "\n",
        "        while not (terminated or truncated):\n",
        "            # Check observation shape right before prediction\n",
        "            if obs.shape != model.observation_space.shape:\n",
        "                 print(f\"!!! ERROR: Observation shape mismatch right before model.predict()!\")\n",
        "                 print(f\"    Step: {step_count}, Env Day: {env.day}\")\n",
        "                 print(f\"    Obs shape: {obs.shape}\")\n",
        "                 print(f\"    Model expected shape: {model.observation_space.shape}\")\n",
        "                 raise ValueError(f\"Internal shape mismatch detected before prediction step {step_count}.\")\n",
        "\n",
        "            action, _states = model.predict(obs, deterministic=deterministic)\n",
        "            obs, reward, terminated, truncated, info_step = env.step(action) # Error occurred inside here previously\n",
        "            done = terminated or truncated\n",
        "\n",
        "            if step_count % 100 == 0 or done:\n",
        "                current_val = env.asset_memory[-1] if env.asset_memory else env.initial_amount\n",
        "                current_date_str = env.date_memory[-1].strftime('%Y-%m-%d') if env.date_memory else \"N/A\"\n",
        "                print(f\"  Step: {env.day}/{num_unique_days}, Date: {current_date_str}, Portfolio: ${current_val:,.2f}, Reward: {reward:.4f}\")\n",
        "\n",
        "            step_count += 1\n",
        "\n",
        "            if done:\n",
        "                print(f\"Simulation loop finished. Terminated: {terminated}, Truncated: {truncated}\")\n",
        "                break\n",
        "\n",
        "            # Safety break\n",
        "            max_steps = num_unique_days * 1.1 + 10\n",
        "            if step_count > max_steps and num_unique_days > 0:\n",
        "                 print(f\"Warning: Simulation loop exceeded expected length ({num_unique_days}). Breaking at step {step_count}.\")\n",
        "                 break\n",
        "            elif step_count > 60000:\n",
        "                 print(f\"Warning: Simulation loop exceeded 60,000 iterations. Breaking.\")\n",
        "                 break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error during simulation loop: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        results_df = env.save_asset_memory() if 'env' in locals() and hasattr(env, 'save_asset_memory') else pd.DataFrame()\n",
        "        return results_df, {\"error\": f\"Simulation error: {e}\"}\n",
        "\n",
        "\n",
        "    # 5. Get Results & Calculate Metrics\n",
        "    print(\"\\nCalculating performance metrics...\")\n",
        "    try:\n",
        "        results_df = env.save_asset_memory() # Method defined in the pasted class\n",
        "\n",
        "        if results_df.empty or len(results_df) <= 1:\n",
        "            print(\"Error: Not enough history recorded by the environment to calculate metrics.\")\n",
        "            # Return empty results if calculation isn't possible\n",
        "            return pd.DataFrame(), {\"error\": \"Insufficient data for metrics\"}\n",
        "\n",
        "        # results_df index should already be 'date' from save_asset_memory\n",
        "        if not isinstance(results_df.index, pd.DatetimeIndex):\n",
        "             print(\"Warning: Results DataFrame index is not DatetimeIndex. Attempting conversion.\")\n",
        "             try:\n",
        "                 results_df.index = pd.to_datetime(results_df.index)\n",
        "                 results_df.sort_index(inplace=True)\n",
        "             except Exception as e:\n",
        "                 print(f\"Error converting index to DatetimeIndex: {e}. Metrics requiring time series may fail.\")\n",
        "                 # Continue without datetime index if conversion fails\n",
        "\n",
        "\n",
        "        metrics = {}\n",
        "        portfolio_values = results_df['account_value']\n",
        "        initial_portfolio_value = portfolio_values.iloc[0]\n",
        "        final_portfolio_value = portfolio_values.iloc[-1]\n",
        "\n",
        "        # Basic metrics calculation\n",
        "        metrics['Start Date'] = results_df.index[0].strftime('%Y-%m-%d') if isinstance(results_df.index, pd.DatetimeIndex) else str(results_df.index[0])\n",
        "        metrics['End Date'] = results_df.index[-1].strftime('%Y-%m-%d') if isinstance(results_df.index, pd.DatetimeIndex) else str(results_df.index[-1])\n",
        "        metrics['Initial Portfolio Value ($)'] = initial_portfolio_value\n",
        "        metrics['Final Portfolio Value ($)'] = final_portfolio_value\n",
        "        metrics['Total Return (%)'] = ((final_portfolio_value - initial_portfolio_value) / initial_portfolio_value) * 100 if initial_portfolio_value != 0 else 0\n",
        "        metrics['Total Steps'] = step_count -1 # env.day ends one step ahead\n",
        "        metrics['Total Trades'] = env.trades\n",
        "        metrics['Total Transaction Cost ($)'] = env.cost\n",
        "\n",
        "        # Time-series based metrics\n",
        "        returns = portfolio_values.pct_change().dropna()\n",
        "        returns.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "        duration_years = np.nan\n",
        "        if isinstance(results_df.index, pd.DatetimeIndex) and len(results_df.index) > 1:\n",
        "             duration_years = (results_df.index[-1] - results_df.index[0]).days / 365.25\n",
        "\n",
        "        if not returns.empty and len(returns) > 1:\n",
        "            std_dev = returns.std()\n",
        "            metrics['Volatility (Ann.) (%)'] = (std_dev * np.sqrt(252)) * 100 if std_dev > 0 else 0\n",
        "            metrics['Sharpe Ratio (Ann.)'] = (returns.mean() / std_dev) * np.sqrt(252) if std_dev > 0 else 0\n",
        "\n",
        "            rolling_max = portfolio_values.cummax()\n",
        "            daily_drawdown = portfolio_values / rolling_max - 1.0\n",
        "            max_drawdown = daily_drawdown.min()\n",
        "            metrics['Max Drawdown (%)'] = max_drawdown * 100\n",
        "\n",
        "            annualized_return = 0\n",
        "            if duration_years > 0 and initial_portfolio_value != 0:\n",
        "                 annualized_return = ((final_portfolio_value / initial_portfolio_value) ** (1 / duration_years)) - 1\n",
        "            metrics['Annualized Return (%)'] = annualized_return * 100\n",
        "            metrics['Calmar Ratio'] = (annualized_return / abs(max_drawdown)) if max_drawdown < -1e-9 else np.nan # Avoid division by zero\n",
        "\n",
        "\n",
        "            # Quantstats calculation (requires DatetimeIndex)\n",
        "            if QUANTSTATS_AVAILABLE and isinstance(results_df.index, pd.DatetimeIndex):\n",
        "                try:\n",
        "                    qs_returns = returns.copy()\n",
        "                    qs_returns.name = \"Strategy\"\n",
        "                    print(\"Calculating extended metrics using quantstats...\")\n",
        "                    try:\n",
        "                         qs_metrics_dict = quantstats.reports.metrics(qs_returns, mode='basic', display=False).iloc[0].to_dict()\n",
        "                         qs_metrics_dict = {k.replace(' [%]', '').replace(' (%)','').strip(): v for k, v in qs_metrics_dict.items()}\n",
        "                         metrics.update(qs_metrics_dict)\n",
        "                         print(\"Quantstats basic metrics calculated.\")\n",
        "                    except Exception as qs_basic_e:\n",
        "                         print(f\"Warning: quantstats basic calculation failed: {qs_basic_e}. Trying simple stats.\")\n",
        "                         try:\n",
        "                             metrics['QS Sharpe'] = quantstats.stats.sharpe(qs_returns, annualize=True)\n",
        "                             metrics['QS Sortino'] = quantstats.stats.sortino(qs_returns, annualize=True)\n",
        "                             metrics['QS Max Drawdown'] = quantstats.stats.max_drawdown(qs_returns) * 100\n",
        "                             metrics['QS Volatility (Ann.)'] = quantstats.stats.volatility(qs_returns, annualize=True) * 100\n",
        "                             print(\"Quantstats simple metrics calculated.\")\n",
        "                         except Exception as qs_simple_e:\n",
        "                             print(f\"Warning: quantstats simple calculation also failed: {qs_simple_e}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: quantstats calculation failed: {e}\")\n",
        "            elif QUANTSTATS_AVAILABLE:\n",
        "                 print(\"Warning: Index is not DatetimeIndex. Skipping quantstats.\")\n",
        "\n",
        "        else: # Not enough data for time-series metrics\n",
        "            print(\"Warning: Could not calculate performance ratios (empty/single-point returns series).\")\n",
        "            metrics.update({\n",
        "                'Volatility (Ann.) (%)': 0, 'Sharpe Ratio (Ann.)': 0,\n",
        "                'Max Drawdown (%)': 0,\n",
        "                'Annualized Return (%)': metrics.get('Total Return (%)', 0) if duration_years <= 0 else 0,\n",
        "                'Calmar Ratio': np.nan\n",
        "            })\n",
        "\n",
        "        print(\"\\n--- Backtest Metrics Summary ---\")\n",
        "        key_metrics_to_print = [\n",
        "            'Initial Portfolio Value ($)', 'Final Portfolio Value ($)', 'Total Return (%)',\n",
        "            'Annualized Return (%)', 'Sharpe Ratio (Ann.)', 'Max Drawdown (%)',\n",
        "            'Volatility (Ann.) (%)', 'Calmar Ratio', 'Total Trades', 'Total Transaction Cost ($)'\n",
        "        ]\n",
        "        qs_keys = ['Sharpe', 'Sortino', 'Max Drawdown', 'Volatility (ann.)', 'Avg. Drawdown', 'Win Rate', 'Best Day', 'Worst Day', 'Avg. Trade', 'Profit Factor']\n",
        "        key_metrics_to_print.extend([k for k in qs_keys if k in metrics and k not in key_metrics_to_print]) # Add unique QS keys\n",
        "\n",
        "        for key in key_metrics_to_print:\n",
        "             if key in metrics:\n",
        "                 value = metrics[key]\n",
        "                 try:\n",
        "                     if pd.isna(value): print(f\"  {key}: NaN\")\n",
        "                     else: print(f\"  {key}: {float(value):,.4f}\")\n",
        "                 except (ValueError, TypeError, OverflowError):\n",
        "                     print(f\"  {key}: {value}\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error calculating or displaying metrics: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        metrics = {\"error\": f\"Metrics calculation error: {e}\"}\n",
        "        # Try to return results_df even if metrics fail\n",
        "        results_df = env.save_asset_memory() if 'env' in locals() and hasattr(env, 'save_asset_memory') else pd.DataFrame()\n",
        "        return results_df, metrics\n",
        "\n",
        "    # 6. Report/Visualize and Save Outputs\n",
        "    print(\"\\nGenerating plot and saving results...\")\n",
        "    try:\n",
        "        model_filename_base = os.path.splitext(os.path.basename(model_path))[0]\n",
        "        output_prefix = f\"backtest_{model_filename_base}_{backtest_start_date}_to_{backtest_end_date}\"\n",
        "\n",
        "        # --- Plot Portfolio Value ---\n",
        "        if not portfolio_values.empty:\n",
        "             plt.figure(figsize=(12, 6))\n",
        "             portfolio_values.plot(title=f'Portfolio Value Over Time\\n({backtest_start_date} to {backtest_end_date})')\n",
        "             plt.xlabel(\"Date\")\n",
        "             plt.ylabel(\"Portfolio Value ($)\")\n",
        "             plt.grid(True)\n",
        "             plt.tight_layout()\n",
        "             plot_filename = f'{output_prefix}_portfolio_value.png'\n",
        "             plt.savefig(plot_filename)\n",
        "             print(f\"Saved portfolio value plot to: {plot_filename}\")\n",
        "             plt.close()\n",
        "        else:\n",
        "             print(\"Skipping plot generation: No portfolio values.\")\n",
        "\n",
        "\n",
        "        # --- Save Results CSV ---\n",
        "        results_csv_filename = f'{output_prefix}_results.csv'\n",
        "        if not results_df.empty:\n",
        "             results_df.reset_index().to_csv(results_csv_filename, index=False)\n",
        "             print(f\"Saved detailed results (account value) to: {results_csv_filename}\")\n",
        "        else:\n",
        "             print(\"Skipping results CSV saving: Results DataFrame is empty.\")\n",
        "\n",
        "        # --- Save Metrics JSON ---\n",
        "        metrics_json_filename = f'{output_prefix}_metrics.json'\n",
        "        serializable_metrics = {}\n",
        "        for k, v in metrics.items():\n",
        "            if isinstance(v, (np.integer, np.int64)): serializable_metrics[k] = int(v)\n",
        "            elif isinstance(v, (np.floating, np.float64)): serializable_metrics[k] = float(v) if not pd.isna(v) else None\n",
        "            elif isinstance(v, (np.ndarray,)): serializable_metrics[k] = v.tolist()\n",
        "            elif isinstance(v, (pd.Timestamp)): serializable_metrics[k] = v.strftime('%Y-%m-%d')\n",
        "            elif pd.isna(v): serializable_metrics[k] = None\n",
        "            else: serializable_metrics[k] = v\n",
        "\n",
        "        with open(metrics_json_filename, 'w') as f:\n",
        "            json.dump(serializable_metrics, f, indent=4)\n",
        "        print(f\"Saved performance metrics to: {metrics_json_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n!!! Error during plotting or saving files: {e}\")\n",
        "\n",
        "    if hasattr(env, 'close'):\n",
        "        env.close()\n",
        "\n",
        "    return results_df, metrics    # --- Return ---\n",
        "    if 'env' in locals() and hasattr(env, 'close'): env.close()\n",
        "    return results_df, metrics\n",
        "\n",
        "\n",
        "# --- Main Execution Block (`if __name__ == \"__main__\":`) ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # <<< --- PASTE YOUR StockTradingEnv CLASS DEFINITION ABOVE --- <<<\n",
        "\n",
        "    # <<< --- CHANGE THESE VALUES --- <<<\n",
        "    # ... (Keep your main block configuration) ...\n",
        "    DATA_PATH = \"/content/indian_stock_data.csv\"\n",
        "    MODEL_PATH = \"/content/best_optuna_ppo_model.zip\"\n",
        "    BACKTEST_START_DATE = \"2015-01-01\"\n",
        "    BACKTEST_END_DATE = \"2023-12-31\"\n",
        "    INITIAL_AMOUNT = 100000\n",
        "    TURBULENCE_THRESHOLD = 100.0\n",
        "    REWARD_SCALING = 1e-4\n",
        "    BUY_COST = 0.001\n",
        "    SELL_COST = 0.001\n",
        "    INDICATORS = [\"volume\", \"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\", \"turbulence\"]\n",
        "    RISK_INDICATOR = \"turbulence\"\n",
        "    W_TREYNOR = 0.4013949773199673\n",
        "    W_DRAWDOWN = 2.9068009015669793\n",
        "    W_COST = 4.994821708372366\n",
        "    W_RISK = 2.947383762136368\n",
        "    W_RETURN = 4.862429692924584\n",
        "\n",
        "    # --- Prepare Environment Configuration Dictionary ---\n",
        "    env_configuration = {\n",
        "        \"initial_amount\": INITIAL_AMOUNT,\n",
        "        \"reward_scaling\": REWARD_SCALING,\n",
        "        \"tech_indicator_list\": INDICATORS,\n",
        "        \"turbulence_threshold\": TURBULENCE_THRESHOLD,\n",
        "        \"risk_indicator_col\": RISK_INDICATOR,\n",
        "        \"treynor_rate_learn\": W_TREYNOR,\n",
        "        \"drawdown_component_learn\": W_DRAWDOWN,\n",
        "        \"cost_component_learn\": W_COST,\n",
        "        \"risk_component_learn\": W_RISK,\n",
        "        \"return_component_learn\": W_RETURN,\n",
        "        \"buy_cost_pct\": [BUY_COST],\n",
        "        \"sell_cost_pct\": [SELL_COST],\n",
        "        \"print_verbosity\": 1,\n",
        "    }\n",
        "\n",
        "    # --- Run the Backtest ---\n",
        "    results, performance_metrics = run_backtest(\n",
        "        data_path=DATA_PATH,\n",
        "        model_path=MODEL_PATH,\n",
        "        env_config=env_configuration,\n",
        "        backtest_start_date=BACKTEST_START_DATE,\n",
        "        backtest_end_date=BACKTEST_END_DATE,\n",
        "        deterministic=True\n",
        "    )\n",
        "\n",
        "    # --- Final Status ---\n",
        "    # ... (Keep final status printing) ...\n",
        "    if results is not None and performance_metrics is not None and 'error' not in performance_metrics:\n",
        "        print(\"\\nBacktest finished successfully.\")\n",
        "        model_filename_base = os.path.splitext(os.path.basename(MODEL_PATH))[0]\n",
        "        print(f\"Results saved with prefix: backtest_{model_filename_base}_{BACKTEST_START_DATE}_to_{BACKTEST_END_DATE}\")\n",
        "    else:\n",
        "        print(\"\\nBacktest failed or encountered errors.\")\n",
        "        if performance_metrics and 'error' in performance_metrics:\n",
        "            print(f\"Error details: {performance_metrics['error']}\")\n",
        "        elif results is None:\n",
        "             print(\"Backtest function returned None, indicating failure during setup.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Htyg2r1nYRr1",
        "outputId": "c0ae940c-7cf5-4c01-f85f-9f78bf67f61e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Backtest ---\n",
            "Data: /content/indian_stock_data.csv\n",
            "Model: /content/best_optuna_ppo_model.zip\n",
            "Period: 2015-01-01 to 2023-12-31\n",
            "Loading and preparing data...\n",
            "Filtering data to include only the 8 tickers the loaded model expects.\n",
            "Expected training tickers: ['ADANIENT.NS', 'HDFCBANK.NS', 'ICICIBANK.NS', 'INFY.NS', 'RELIANCE.NS', 'SBIN.NS', 'TATAMOTORS.NS', 'TCS.NS']\n",
            "Data shape after filtering by training tickers: (15188, 18)\n",
            "Data shape after filtering by date: (5420, 18)\n",
            "Attempting to forward fill missing data points within each ticker group...\n",
            "Forward fill complete. Shape after ffill and dropna: (18768, 16)\n",
            "DEBUG: df_backtest shape after all processing: (18768, 18)\n",
            "DEBUG: Unique tickers in df_backtest: ['ADANIENT.NS' 'HDFCBANK.NS' 'ICICIBANK.NS' 'INFY.NS' 'RELIANCE.NS'\n",
            " 'SBIN.NS' 'TATAMOTORS.NS' 'TCS.NS']\n",
            "Backtest data prepared. Final Shape: (18768, 18), Date range: 2015-01-02 to 2023-12-29\n",
            "Index reset based on date groups. Index range: 0 to 2345\n",
            "\n",
            "Loading model (PPO)...\n",
            "Model loaded successfully.\n",
            "DEBUG: Model's expected observation space: Box(-inf, inf, (97,), float32)\n",
            "\n",
            "Instantiating environment...\n",
            "DEBUG: stock_dim calculated from final df_backtest: 8\n",
            "\n",
            "DEBUG: === Parameters Passed to Env Init ===\n",
            "  stock_dim: 8\n",
            "  num_indicators: 10\n",
            "  state_space (calculated for init): 97\n",
            "  action_space (passed to init): 8\n",
            "  df shape: (18768, 18)\n",
            "=========================================\n",
            "\n",
            "\n",
            "DEBUG: === Environment Spaces After Init ===\n",
            "  env.stock_dim: 8\n",
            "  env.state_space (from env object): 97\n",
            "  env.observation_space (from env object): Box(-inf, inf, (97,), float32)\n",
            "  env.action_space (from env object): Box(-1.0, 1.0, (8,), float32)\n",
            "=======================================\n",
            "\n",
            "Verifying environment and model spaces...\n",
            "Space verification successful.\n",
            "\n",
            "Environment instantiated successfully:\n",
            "\n",
            "Starting simulation loop...\n",
            "\n",
            "DEBUG: === Observation After First Reset ===\n",
            "  obs type: <class 'numpy.ndarray'>\n",
            "  obs shape: (97,)\n",
            "  obs dtype: float32\n",
            "========================================\n",
            "\n",
            "Expecting approx 2346 steps for the backtest period.\n",
            "  Step: 1/2346, Date: 2015-01-05, Portfolio: $99,059.81, Reward: -0.0000\n",
            "Day: 20, Date: 2015-01-30 00:00:00, Portfolio: 111,464.05, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 40, Date: 2015-02-27 00:00:00, Portfolio: 109,035.82, Reward: -0.0000, StepCost: 0.27\n",
            "Day: 60, Date: 2015-03-27 00:00:00, Portfolio: 104,965.78, Reward: -0.0000, StepCost: 0.25\n",
            "Day: 80, Date: 2015-04-24 00:00:00, Portfolio: 104,121.91, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 100, Date: 2015-05-22 00:00:00, Portfolio: 105,961.79, Reward: -0.0000, StepCost: 0.26\n",
            "  Step: 101/2346, Date: 2015-05-25, Portfolio: $105,881.76, Reward: -0.0000\n",
            "Turbulence Alert! Day 108 (276.30 > 100.0). Selling all assets.\n",
            "Day: 120, Date: 2015-06-19 00:00:00, Portfolio: 106,725.04, Reward: -0.0000, StepCost: 0.26\n",
            "Day: 140, Date: 2015-07-17 00:00:00, Portfolio: 115,828.30, Reward: -0.0000, StepCost: 0.68\n",
            "Day: 160, Date: 2015-08-14 00:00:00, Portfolio: 114,910.33, Reward: 0.0000, StepCost: 0.25\n",
            "Day: 180, Date: 2015-09-11 00:00:00, Portfolio: 105,423.91, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 200, Date: 2015-10-09 00:00:00, Portfolio: 113,265.34, Reward: -0.0000, StepCost: 0.36\n",
            "  Step: 201/2346, Date: 2015-10-12, Portfolio: $112,683.40, Reward: -0.0000\n",
            "Day: 220, Date: 2015-11-06 00:00:00, Portfolio: 112,677.71, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 240, Date: 2015-12-04 00:00:00, Portfolio: 110,383.92, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 260, Date: 2016-01-01 00:00:00, Portfolio: 112,801.88, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 280, Date: 2016-01-29 00:00:00, Portfolio: 109,443.68, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 300, Date: 2016-02-26 00:00:00, Portfolio: 100,204.16, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 301/2346, Date: 2016-02-29, Portfolio: $101,331.66, Reward: -0.0000\n",
            "Day: 320, Date: 2016-03-25 00:00:00, Portfolio: 109,389.14, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 340, Date: 2016-04-22 00:00:00, Portfolio: 113,823.09, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 360, Date: 2016-05-20 00:00:00, Portfolio: 118,891.91, Reward: -0.0000, StepCost: 0.19\n",
            "Day: 380, Date: 2016-06-17 00:00:00, Portfolio: 121,932.94, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 400, Date: 2016-07-15 00:00:00, Portfolio: 128,558.62, Reward: 0.0000, StepCost: 0.00\n",
            "  Step: 401/2346, Date: 2016-07-18, Portfolio: $128,952.02, Reward: 0.0000\n",
            "Day: 420, Date: 2016-08-12 00:00:00, Portfolio: 129,043.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 440, Date: 2016-09-09 00:00:00, Portfolio: 135,550.00, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 460, Date: 2016-10-07 00:00:00, Portfolio: 134,519.50, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 480, Date: 2016-11-04 00:00:00, Portfolio: 130,648.06, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 500, Date: 2016-12-02 00:00:00, Portfolio: 124,929.09, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 501/2346, Date: 2016-12-05, Portfolio: $125,688.66, Reward: -0.0000\n",
            "Day: 520, Date: 2016-12-30 00:00:00, Portfolio: 126,716.59, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 540, Date: 2017-01-27 00:00:00, Portfolio: 135,700.12, Reward: -0.0000, StepCost: 0.00\n",
            "Turbulence Alert! Day 558 (117.78 > 100.0). Selling all assets.\n",
            "Day: 560, Date: 2017-02-24 00:00:00, Portfolio: 147,838.84, Reward: -0.0000, StepCost: 0.50\n",
            "Day: 580, Date: 2017-03-24 00:00:00, Portfolio: 151,005.00, Reward: -0.0000, StepCost: 0.23\n",
            "Day: 600, Date: 2017-04-21 00:00:00, Portfolio: 158,650.44, Reward: 0.0000, StepCost: 0.23\n",
            "  Step: 601/2346, Date: 2017-04-24, Portfolio: $162,503.14, Reward: 0.0000\n",
            "Day: 620, Date: 2017-05-19 00:00:00, Portfolio: 165,516.89, Reward: -0.0000, StepCost: 0.26\n",
            "Day: 640, Date: 2017-06-16 00:00:00, Portfolio: 176,964.28, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 660, Date: 2017-07-14 00:00:00, Portfolio: 179,273.36, Reward: -0.0000, StepCost: 0.28\n",
            "Day: 680, Date: 2017-08-11 00:00:00, Portfolio: 186,627.34, Reward: -0.0000, StepCost: 0.50\n",
            "Day: 700, Date: 2017-09-08 00:00:00, Portfolio: 190,745.50, Reward: 0.0000, StepCost: 0.28\n",
            "  Step: 701/2346, Date: 2017-09-11, Portfolio: $194,544.16, Reward: 0.0000\n",
            "Day: 720, Date: 2017-10-06 00:00:00, Portfolio: 192,050.75, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 740, Date: 2017-11-03 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 760, Date: 2017-12-01 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 780, Date: 2017-12-29 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 800, Date: 2018-01-26 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 801/2346, Date: 2018-01-29, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 820, Date: 2018-02-23 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 840, Date: 2018-03-23 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 860, Date: 2018-04-20 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 880, Date: 2018-05-18 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 900, Date: 2018-06-15 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 901/2346, Date: 2018-06-18, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 920, Date: 2018-07-13 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 940, Date: 2018-08-10 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 960, Date: 2018-09-07 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 980, Date: 2018-10-05 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1000, Date: 2018-11-02 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1001/2346, Date: 2018-11-05, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1020, Date: 2018-11-30 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1040, Date: 2018-12-28 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1060, Date: 2019-01-25 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1080, Date: 2019-02-22 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1100, Date: 2019-03-22 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1101/2346, Date: 2019-03-25, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1120, Date: 2019-04-19 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1140, Date: 2019-05-17 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1160, Date: 2019-06-14 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1180, Date: 2019-07-12 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1200, Date: 2019-08-09 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1201/2346, Date: 2019-08-12, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1220, Date: 2019-09-06 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1240, Date: 2019-10-04 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1260, Date: 2019-11-01 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1280, Date: 2019-11-29 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1300, Date: 2019-12-27 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1301/2346, Date: 2019-12-30, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1320, Date: 2020-01-24 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1340, Date: 2020-02-21 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1360, Date: 2020-03-20 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1380, Date: 2020-04-17 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1400, Date: 2020-05-15 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1401/2346, Date: 2020-05-18, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1420, Date: 2020-06-12 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1440, Date: 2020-07-10 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1460, Date: 2020-08-07 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1480, Date: 2020-09-04 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1500, Date: 2020-10-02 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1501/2346, Date: 2020-10-05, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1520, Date: 2020-10-30 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1540, Date: 2020-11-27 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1560, Date: 2020-12-25 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1580, Date: 2021-01-22 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1600, Date: 2021-02-19 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1601/2346, Date: 2021-02-22, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1620, Date: 2021-03-19 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1640, Date: 2021-04-16 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1660, Date: 2021-05-14 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1680, Date: 2021-06-11 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1700, Date: 2021-07-09 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1701/2346, Date: 2021-07-12, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1720, Date: 2021-08-06 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1740, Date: 2021-09-03 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1760, Date: 2021-10-01 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1780, Date: 2021-10-29 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1800, Date: 2021-11-26 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1801/2346, Date: 2021-11-29, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1820, Date: 2021-12-24 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1840, Date: 2022-01-21 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1860, Date: 2022-02-18 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1880, Date: 2022-03-18 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1900, Date: 2022-04-15 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 1901/2346, Date: 2022-04-18, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 1920, Date: 2022-05-13 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1940, Date: 2022-06-10 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1960, Date: 2022-07-08 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 1980, Date: 2022-08-05 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2000, Date: 2022-09-02 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 2001/2346, Date: 2022-09-05, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 2020, Date: 2022-09-30 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2040, Date: 2022-10-28 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2060, Date: 2022-11-25 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2080, Date: 2022-12-23 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2100, Date: 2023-01-20 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 2101/2346, Date: 2023-01-23, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 2120, Date: 2023-02-17 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2140, Date: 2023-03-17 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2160, Date: 2023-04-14 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2180, Date: 2023-05-12 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2200, Date: 2023-06-09 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 2201/2346, Date: 2023-06-12, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 2220, Date: 2023-07-07 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2240, Date: 2023-08-04 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2260, Date: 2023-09-01 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2280, Date: 2023-09-29 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2300, Date: 2023-10-27 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "  Step: 2301/2346, Date: 2023-10-30, Portfolio: $192,050.48, Reward: -0.0000\n",
            "Day: 2320, Date: 2023-11-24 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "Day: 2340, Date: 2023-12-22 00:00:00, Portfolio: 192,050.48, Reward: -0.0000, StepCost: 0.00\n",
            "------------------------------\n",
            "EPISODE END - Day: 2345\n",
            "Beginning Portfolio Value: 100,000.00\n",
            "End Portfolio Value: 192,050.48\n",
            "Total Return: 92.05%\n",
            "Total Trades: 293\n",
            "Total Transaction Costs: $679.53\n",
            "Sharpe Ratio (Approx. Annualized): 0.850\n",
            "Max Drawdown: -15.49%\n",
            "------------------------------\n",
            "  Step: 2345/2346, Date: 2023-12-29, Portfolio: $192,050.48, Reward: 0.0000\n",
            "Simulation loop finished. Terminated: True, Truncated: False\n",
            "\n",
            "Calculating performance metrics...\n",
            "Calculating extended metrics using quantstats...\n",
            "Quantstats basic metrics calculated.\n",
            "\n",
            "--- Backtest Metrics Summary ---\n",
            "  Initial Portfolio Value ($): 100,000.0000\n",
            "  Final Portfolio Value ($): 192,050.4844\n",
            "  Total Return (%): 92.0505\n",
            "  Annualized Return (%): 7.5304\n",
            "  Sharpe Ratio (Ann.): 0.8504\n",
            "  Max Drawdown (%): -15.4915\n",
            "  Volatility (Ann.) (%): 8.6905\n",
            "  Calmar Ratio: 0.4861\n",
            "  Total Trades: 293.0000\n",
            "  Total Transaction Cost ($): 679.5292\n",
            "-----------------------------\n",
            "\n",
            "Generating plot and saving results...\n",
            "Saved portfolio value plot to: backtest_best_optuna_ppo_model_2015-01-01_to_2023-12-31_portfolio_value.png\n",
            "Saved detailed results (account value) to: backtest_best_optuna_ppo_model_2015-01-01_to_2023-12-31_results.csv\n",
            "Saved performance metrics to: backtest_best_optuna_ppo_model_2015-01-01_to_2023-12-31_metrics.json\n",
            "\n",
            "Backtest finished successfully.\n",
            "Results saved with prefix: backtest_best_optuna_ppo_model_2015-01-01_to_2023-12-31\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}